{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi step model (simple encoder-decoder)\n",
    "\n",
    "In this notebook, we demonstrate how to:\n",
    "- prepare time series data for training a RNN forecasting model\n",
    "- get data in the required shape for the keras API\n",
    "- implement a RNN model in keras to predict the next 3 steps ahead (time *t+1* to *t+3*) in the time series. This model uses a simple encoder decoder approach in which the final hidden state of the encoder is replicated across each time step of the decoder. \n",
    "- enable early stopping to reduce the likelihood of model overfitting\n",
    "- evaluate the model on a test dataset\n",
    "\n",
    "The data in this example is taken from the GEFCom2014 forecasting competition<sup>1</sup>. It consists of 3 years of hourly electricity load and temperature values between 2012 and 2014. The task is to forecast future values of electricity load.\n",
    "\n",
    "<sup>1</sup>Tao Hong, Pierre Pinson, Shu Fan, Hamidreza Zareipour, Alberto Troccoli and Rob J. Hyndman, \"Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond\", International Journal of Forecasting, vol.32, no.3, pp 896-913, July-September, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from collections import UserDict\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "from common.utils import load_data, mape, TimeSeriesTensor, create_evaluation_df\n",
    "\n",
    "pd.options.display.float_format = '{:,.20f}'.format\n",
    "np.set_printoptions(precision=20)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-01 14:00:00</th>\n",
       "      <td>0.00000000487484591404</td>\n",
       "      <td>0.00000387243926525000</td>\n",
       "      <td>5,153.67019652999988466036</td>\n",
       "      <td>309.37500000000000000000</td>\n",
       "      <td>-0.00000000826677291570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 16:00:00</th>\n",
       "      <td>0.00000000491699052668</td>\n",
       "      <td>0.00000384263694286000</td>\n",
       "      <td>5,153.66918755000006058253</td>\n",
       "      <td>310.12500000000000000000</td>\n",
       "      <td>-0.00000000835070498324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 18:00:00</th>\n",
       "      <td>0.00000000487484591404</td>\n",
       "      <td>0.00000376440584660000</td>\n",
       "      <td>5,153.66988753999976324849</td>\n",
       "      <td>308.62500000000000000000</td>\n",
       "      <td>-0.00000000838070623291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 20:00:00</th>\n",
       "      <td>0.00000000487520307178</td>\n",
       "      <td>0.00000389851629734000</td>\n",
       "      <td>5,153.67030524999972840305</td>\n",
       "      <td>309.37500000000000000000</td>\n",
       "      <td>-0.00000000849213944598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 22:00:00</th>\n",
       "      <td>0.00000000475305512668</td>\n",
       "      <td>0.00000398606061935000</td>\n",
       "      <td>5,153.67324066000037419144</td>\n",
       "      <td>307.43750000000000000000</td>\n",
       "      <td>-0.00000000843142263117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-01 14:00:00 0.00000000487484591404 0.00000387243926525000   \n",
       "2017-11-01 16:00:00 0.00000000491699052668 0.00000384263694286000   \n",
       "2017-11-01 18:00:00 0.00000000487484591404 0.00000376440584660000   \n",
       "2017-11-01 20:00:00 0.00000000487520307178 0.00000389851629734000   \n",
       "2017-11-01 22:00:00 0.00000000475305512668 0.00000398606061935000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-01 14:00:00 5,153.67019652999988466036 309.37500000000000000000   \n",
       "2017-11-01 16:00:00 5,153.66918755000006058253 310.12500000000000000000   \n",
       "2017-11-01 18:00:00 5,153.66988753999976324849 308.62500000000000000000   \n",
       "2017-11-01 20:00:00 5,153.67030524999972840305 309.37500000000000000000   \n",
       "2017-11-01 22:00:00 5,153.67324066000037419144 307.43750000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-01 14:00:00 -0.00000000826677291570  \n",
       "2017-11-01 16:00:00 -0.00000000835070498324  \n",
       "2017-11-01 18:00:00 -0.00000000838070623291  \n",
       "2017-11-01 20:00:00 -0.00000000849213944598  \n",
       "2017-11-01 22:00:00 -0.00000000843142263117  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Cleaned1.csv\" , parse_dates = True)\n",
    "a = pd.to_datetime(df['Epoch_Time_of_Clock'])\n",
    "print(type(a[0]))\n",
    "df = df.drop(['Unnamed: 0', 'Unnamed: 0.1'  ,'e' ,'PRN','SV_Clock_Bias', 'SV_Clock_Drift', 'SV_Clock_Drift_Rate', 'IODE', 'Crs',\n",
    "       'OMEGA', 'i0', 'Cuc','Toe', 'Cic', 'omega',\n",
    "       'Cis', 'M0', 'I_dot', 'Codes', 'GPS_week',\n",
    "       'L2_P_Data_flag', 'SV_accuracy', 'SV_health', 'Tgd', 'IODC', 'T_Tx',\n",
    "       'Fit_Interval' ,'Epoch_Time_of_Clock' ],axis =1 )\n",
    "df.head()\n",
    "#df = df.set_index(['Epoch_Time_of_Clock'])\n",
    "df = df.set_index(a)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'OMEGA_dot'\n",
    "sat_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.iloc[5 : , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter number of entries per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "2017-11-25 12:00:00 2017-11-21 12:00:00\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "entry = 6\n",
    "print(df.shape[0])\n",
    "no_of_entries = df.shape[0]//entry\n",
    "valid = (no_of_entries * 70)//100\n",
    "test = (no_of_entries * 85)//100\n",
    "indexes = df.index\n",
    "#print(valid , test , indexes)\n",
    "valid_start_dt = indexes[int(valid)*int(entry)] \n",
    "test_start_dt = indexes [int(test)*int(entry)] \n",
    "test_start_dt = str(test_start_dt)\n",
    "valid_start_dt = str(valid_start_dt)\n",
    "print(test_start_dt,valid_start_dt)\n",
    "print(type(test_start_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter lag and no. of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"total = len(df)\n",
    "t = total*70/100\n",
    "t = round(t)\n",
    "indexes = df.index\n",
    "valid_start_dt = str(indexes[t])\n",
    "t = total*85/100\n",
    "t = round(t)\n",
    "test_start_dt = str(indexes[t])\n",
    "print(valid_start_dt , test_start_dt)\n",
    "\"\"\"\n",
    "T = 6\n",
    "HORIZON = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set containing only the model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 12:00:00</th>\n",
       "      <td>0.00000000491949063082</td>\n",
       "      <td>0.00000451132655144000</td>\n",
       "      <td>5,153.67212868000024172943</td>\n",
       "      <td>297.03125000000000000000</td>\n",
       "      <td>-0.00000000839749264642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 14:00:00</th>\n",
       "      <td>0.00000000485198781905</td>\n",
       "      <td>0.00000493414700031000</td>\n",
       "      <td>5,153.66936874000020907260</td>\n",
       "      <td>288.65625000000000000000</td>\n",
       "      <td>-0.00000000818891252965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 16:00:00</th>\n",
       "      <td>0.00000000489056085435</td>\n",
       "      <td>0.00000489875674248000</td>\n",
       "      <td>5,153.66863631999967765296</td>\n",
       "      <td>289.53125000000000000000</td>\n",
       "      <td>-0.00000000828213069827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 18:00:00</th>\n",
       "      <td>0.00000000486627412842</td>\n",
       "      <td>0.00000469386577606000</td>\n",
       "      <td>5,153.66860771000028762501</td>\n",
       "      <td>290.93750000000000000000</td>\n",
       "      <td>-0.00000000832034657583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 20:00:00</th>\n",
       "      <td>0.00000000486484549748</td>\n",
       "      <td>0.00000475533306599000</td>\n",
       "      <td>5,153.66959381000015127938</td>\n",
       "      <td>293.37500000000000000000</td>\n",
       "      <td>-0.00000000844856620241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-02 12:00:00 0.00000000491949063082 0.00000451132655144000   \n",
       "2017-11-02 14:00:00 0.00000000485198781905 0.00000493414700031000   \n",
       "2017-11-02 16:00:00 0.00000000489056085435 0.00000489875674248000   \n",
       "2017-11-02 18:00:00 0.00000000486627412842 0.00000469386577606000   \n",
       "2017-11-02 20:00:00 0.00000000486484549748 0.00000475533306599000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-02 12:00:00 5,153.67212868000024172943 297.03125000000000000000   \n",
       "2017-11-02 14:00:00 5,153.66936874000020907260 288.65625000000000000000   \n",
       "2017-11-02 16:00:00 5,153.66863631999967765296 289.53125000000000000000   \n",
       "2017-11-02 18:00:00 5,153.66860771000028762501 290.93750000000000000000   \n",
       "2017-11-02 20:00:00 5,153.66959381000015127938 293.37500000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-02 12:00:00 -0.00000000839749264642  \n",
       "2017-11-02 14:00:00 -0.00000000818891252965  \n",
       "2017-11-02 16:00:00 -0.00000000828213069827  \n",
       "2017-11-02 18:00:00 -0.00000000832034657583  \n",
       "2017-11-02 20:00:00 -0.00000000844856620241  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.copy()[df.index < valid_start_dt][['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot' ]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-20 12:00:00</th>\n",
       "      <td>0.00000000421588989445</td>\n",
       "      <td>0.00001104921102520000</td>\n",
       "      <td>5,153.67980194000028859591</td>\n",
       "      <td>169.65625000000000000000</td>\n",
       "      <td>-0.00000000761960310134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 14:00:00</th>\n",
       "      <td>0.00000000416088760338</td>\n",
       "      <td>0.00001117587089540000</td>\n",
       "      <td>5,153.68068503999984386610</td>\n",
       "      <td>168.31250000000000000000</td>\n",
       "      <td>-0.00000000760888836931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 16:00:00</th>\n",
       "      <td>0.00000000420196074282</td>\n",
       "      <td>0.00001054815948010000</td>\n",
       "      <td>5,153.67795372000000497792</td>\n",
       "      <td>179.53125000000000000000</td>\n",
       "      <td>-0.00000000763460372618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 18:00:00</th>\n",
       "      <td>0.00000000418624580251</td>\n",
       "      <td>0.00001023523509500000</td>\n",
       "      <td>5,153.68110084999989339849</td>\n",
       "      <td>187.56250000000000000000</td>\n",
       "      <td>-0.00000000780496796539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 20:00:00</th>\n",
       "      <td>0.00000000416624496940</td>\n",
       "      <td>0.00001030042767520000</td>\n",
       "      <td>5,153.67985152999972342514</td>\n",
       "      <td>188.25000000000000000000</td>\n",
       "      <td>-0.00000000778639576321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 22:00:00</th>\n",
       "      <td>0.00000000407731269358</td>\n",
       "      <td>0.00001066923141480000</td>\n",
       "      <td>5,153.68220519999977113912</td>\n",
       "      <td>178.34375000000000000000</td>\n",
       "      <td>-0.00000000775568019807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-20 12:00:00 0.00000000421588989445 0.00001104921102520000   \n",
       "2017-11-20 14:00:00 0.00000000416088760338 0.00001117587089540000   \n",
       "2017-11-20 16:00:00 0.00000000420196074282 0.00001054815948010000   \n",
       "2017-11-20 18:00:00 0.00000000418624580251 0.00001023523509500000   \n",
       "2017-11-20 20:00:00 0.00000000416624496940 0.00001030042767520000   \n",
       "2017-11-20 22:00:00 0.00000000407731269358 0.00001066923141480000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-20 12:00:00 5,153.67980194000028859591 169.65625000000000000000   \n",
       "2017-11-20 14:00:00 5,153.68068503999984386610 168.31250000000000000000   \n",
       "2017-11-20 16:00:00 5,153.67795372000000497792 179.53125000000000000000   \n",
       "2017-11-20 18:00:00 5,153.68110084999989339849 187.56250000000000000000   \n",
       "2017-11-20 20:00:00 5,153.67985152999972342514 188.25000000000000000000   \n",
       "2017-11-20 22:00:00 5,153.68220519999977113912 178.34375000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-20 12:00:00 -0.00000000761960310134  \n",
       "2017-11-20 14:00:00 -0.00000000760888836931  \n",
       "2017-11-20 16:00:00 -0.00000000763460372618  \n",
       "2017-11-20 18:00:00 -0.00000000780496796539  \n",
       "2017-11-20 20:00:00 -0.00000000778639576321  \n",
       "2017-11-20 22:00:00 -0.00000000775568019807  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data to be in range (0, 1). This transformation should be calibrated on the training set only. This is to prevent information from the validation or test sets leaking into the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter variable to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "y_scalar = StandardScaler()\n",
    "y_scalar.fit(train[[var_name]])\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "train[['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']] = X_scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the TimeSeriesTensor convenience class to:\n",
    "1. Shift the values of the time series to create a Pandas dataframe containing all the data for a single training example\n",
    "2. Discard any samples with missing values\n",
    "3. Transform this Pandas dataframe into a numpy array of shape (samples, time steps, features) for input into Keras\n",
    "\n",
    "The class takes the following parameters:\n",
    "\n",
    "- **dataset**: original time series\n",
    "- **H**: the forecast horizon\n",
    "- **tensor_structure**: a dictionary discribing the tensor structure in the form { 'tensor_name' : (range(max_backward_shift, max_forward_shift), [feature, feature, ...] ) }\n",
    "- **freq**: time series frequency\n",
    "- **drop_incomplete**: (Boolean) whether to drop incomplete samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_structure = {'X':(range(-T+1, 1), ['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'])}\n",
    "train_inputs = TimeSeriesTensor(train, var_name, HORIZON, {'X':(range(-T+1, 1), ['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'])} ,freq = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_inputs.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct validation set (keeping T hours from the training set in order to construct initial features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Del_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crc</th>\n",
       "      <th colspan=\"6\" halign=\"left\">OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-21 22:00:00</th>\n",
       "      <td>1.68158109707269565192</td>\n",
       "      <td>1.65430993250853264342</td>\n",
       "      <td>1.54362108807462417026</td>\n",
       "      <td>0.73992382634079278958</td>\n",
       "      <td>0.81050801697216345865</td>\n",
       "      <td>0.92600941984800633211</td>\n",
       "      <td>-1.43868358391139095076</td>\n",
       "      <td>-1.63409748789003583802</td>\n",
       "      <td>-1.43067481735893009542</td>\n",
       "      <td>-1.41305553091661639797</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.11991269150023331491</td>\n",
       "      <td>-0.91234314935873250807</td>\n",
       "      <td>-0.84113806370501376097</td>\n",
       "      <td>-1.00974633256429102701</td>\n",
       "      <td>1.82756203682228957064</td>\n",
       "      <td>1.83397878144146564416</td>\n",
       "      <td>1.71687319238838842494</td>\n",
       "      <td>0.90996755834495401949</td>\n",
       "      <td>0.99178105208235334267</td>\n",
       "      <td>1.12492850259357979326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 12:00:00</th>\n",
       "      <td>1.65430993250853264342</td>\n",
       "      <td>1.54362108807462417026</td>\n",
       "      <td>0.73992382634079278958</td>\n",
       "      <td>0.81050801697216345865</td>\n",
       "      <td>0.92600941984800633211</td>\n",
       "      <td>1.35272293608057303516</td>\n",
       "      <td>-1.63409748789003583802</td>\n",
       "      <td>-1.43067481735893009542</td>\n",
       "      <td>-1.41305553091661639797</td>\n",
       "      <td>-1.54119579584563992647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.91234314935873250807</td>\n",
       "      <td>-0.84113806370501376097</td>\n",
       "      <td>-1.00974633256429102701</td>\n",
       "      <td>-1.06953173466977191630</td>\n",
       "      <td>1.83397878144146564416</td>\n",
       "      <td>1.71687319238838842494</td>\n",
       "      <td>0.90996755834495401949</td>\n",
       "      <td>0.99178105208235334267</td>\n",
       "      <td>1.12492850259357979326</td>\n",
       "      <td>1.68158109707269565192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 14:00:00</th>\n",
       "      <td>1.54362108807462417026</td>\n",
       "      <td>0.73992382634079278958</td>\n",
       "      <td>0.81050801697216345865</td>\n",
       "      <td>0.92600941984800633211</td>\n",
       "      <td>1.35272293608057303516</td>\n",
       "      <td>1.29336804851031295094</td>\n",
       "      <td>-1.43067481735893009542</td>\n",
       "      <td>-1.41305553091661639797</td>\n",
       "      <td>-1.54119579584563992647</td>\n",
       "      <td>-1.89037801770324032091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84113806370501376097</td>\n",
       "      <td>-1.00974633256429102701</td>\n",
       "      <td>-1.06953173466977191630</td>\n",
       "      <td>-1.19581999979146158530</td>\n",
       "      <td>1.71687319238838842494</td>\n",
       "      <td>0.90996755834495401949</td>\n",
       "      <td>0.99178105208235334267</td>\n",
       "      <td>1.12492850259357979326</td>\n",
       "      <td>1.68158109707269565192</td>\n",
       "      <td>1.65430993250853264342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 16:00:00</th>\n",
       "      <td>0.73992382634079278958</td>\n",
       "      <td>0.81050801697216345865</td>\n",
       "      <td>0.92600941984800633211</td>\n",
       "      <td>1.35272293608057303516</td>\n",
       "      <td>1.29336804851031295094</td>\n",
       "      <td>1.19872106557945667937</td>\n",
       "      <td>-1.41305553091661639797</td>\n",
       "      <td>-1.54119579584563992647</td>\n",
       "      <td>-1.89037801770324032091</td>\n",
       "      <td>-1.48673618322613831921</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00974633256429102701</td>\n",
       "      <td>-1.06953173466977191630</td>\n",
       "      <td>-1.19581999979146158530</td>\n",
       "      <td>-0.94996093045881035977</td>\n",
       "      <td>0.90996755834495401949</td>\n",
       "      <td>0.99178105208235334267</td>\n",
       "      <td>1.12492850259357979326</td>\n",
       "      <td>1.68158109707269565192</td>\n",
       "      <td>1.65430993250853264342</td>\n",
       "      <td>1.54362108807462417026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 18:00:00</th>\n",
       "      <td>0.81050801697216345865</td>\n",
       "      <td>0.92600941984800633211</td>\n",
       "      <td>1.35272293608057303516</td>\n",
       "      <td>1.29336804851031295094</td>\n",
       "      <td>1.19872106557945667937</td>\n",
       "      <td>0.43994101604517188431</td>\n",
       "      <td>-1.54119579584563992647</td>\n",
       "      <td>-1.89037801770324032091</td>\n",
       "      <td>-1.48673618322613831921</td>\n",
       "      <td>-1.61807995478512123277</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.06953173466977191630</td>\n",
       "      <td>-1.19581999979146158530</td>\n",
       "      <td>-0.94996093045881035977</td>\n",
       "      <td>-0.73701741958872701854</td>\n",
       "      <td>0.99178105208235334267</td>\n",
       "      <td>1.12492850259357979326</td>\n",
       "      <td>1.68158109707269565192</td>\n",
       "      <td>1.65430993250853264342</td>\n",
       "      <td>1.54362108807462417026</td>\n",
       "      <td>0.73992382634079278958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                              target                         \\\n",
       "feature                                  y                          \n",
       "time step                              t+1                    t+2   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-21 22:00:00 1.68158109707269565192 1.65430993250853264342   \n",
       "2017-11-22 12:00:00 1.65430993250853264342 1.54362108807462417026   \n",
       "2017-11-22 14:00:00 1.54362108807462417026 0.73992382634079278958   \n",
       "2017-11-22 16:00:00 0.73992382634079278958 0.81050801697216345865   \n",
       "2017-11-22 18:00:00 0.81050801697216345865 0.92600941984800633211   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+3                    t+4   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-21 22:00:00 1.54362108807462417026 0.73992382634079278958   \n",
       "2017-11-22 12:00:00 0.73992382634079278958 0.81050801697216345865   \n",
       "2017-11-22 14:00:00 0.81050801697216345865 0.92600941984800633211   \n",
       "2017-11-22 16:00:00 0.92600941984800633211 1.35272293608057303516   \n",
       "2017-11-22 18:00:00 1.35272293608057303516 1.29336804851031295094   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+5                    t+6   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-21 22:00:00 0.81050801697216345865 0.92600941984800633211   \n",
       "2017-11-22 12:00:00 0.92600941984800633211 1.35272293608057303516   \n",
       "2017-11-22 14:00:00 1.35272293608057303516 1.29336804851031295094   \n",
       "2017-11-22 16:00:00 1.29336804851031295094 1.19872106557945667937   \n",
       "2017-11-22 18:00:00 1.19872106557945667937 0.43994101604517188431   \n",
       "\n",
       "tensor                                    X                          \\\n",
       "feature                               Del_n                           \n",
       "time step                               t-5                     t-4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-21 22:00:00 -1.43868358391139095076 -1.63409748789003583802   \n",
       "2017-11-22 12:00:00 -1.63409748789003583802 -1.43067481735893009542   \n",
       "2017-11-22 14:00:00 -1.43067481735893009542 -1.41305553091661639797   \n",
       "2017-11-22 16:00:00 -1.41305553091661639797 -1.54119579584563992647   \n",
       "2017-11-22 18:00:00 -1.54119579584563992647 -1.89037801770324032091   \n",
       "\n",
       "tensor                                                               ...  \\\n",
       "feature                                                              ...   \n",
       "time step                               t-3                     t-2  ...   \n",
       "Epoch_Time_of_Clock                                                  ...   \n",
       "2017-11-21 22:00:00 -1.43067481735893009542 -1.41305553091661639797  ...   \n",
       "2017-11-22 12:00:00 -1.41305553091661639797 -1.54119579584563992647  ...   \n",
       "2017-11-22 14:00:00 -1.54119579584563992647 -1.89037801770324032091  ...   \n",
       "2017-11-22 16:00:00 -1.89037801770324032091 -1.48673618322613831921  ...   \n",
       "2017-11-22 18:00:00 -1.48673618322613831921 -1.61807995478512123277  ...   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                 Crc                           \n",
       "time step                               t-3                     t-2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-21 22:00:00 -1.11991269150023331491 -0.91234314935873250807   \n",
       "2017-11-22 12:00:00 -0.91234314935873250807 -0.84113806370501376097   \n",
       "2017-11-22 14:00:00 -0.84113806370501376097 -1.00974633256429102701   \n",
       "2017-11-22 16:00:00 -1.00974633256429102701 -1.06953173466977191630   \n",
       "2017-11-22 18:00:00 -1.06953173466977191630 -1.19581999979146158530   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t-1                       t   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-21 22:00:00 -0.84113806370501376097 -1.00974633256429102701   \n",
       "2017-11-22 12:00:00 -1.00974633256429102701 -1.06953173466977191630   \n",
       "2017-11-22 14:00:00 -1.06953173466977191630 -1.19581999979146158530   \n",
       "2017-11-22 16:00:00 -1.19581999979146158530 -0.94996093045881035977   \n",
       "2017-11-22 18:00:00 -0.94996093045881035977 -0.73701741958872701854   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                          OMEGA_dot                          \n",
       "time step                              t-5                    t-4   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-21 22:00:00 1.82756203682228957064 1.83397878144146564416   \n",
       "2017-11-22 12:00:00 1.83397878144146564416 1.71687319238838842494   \n",
       "2017-11-22 14:00:00 1.71687319238838842494 0.90996755834495401949   \n",
       "2017-11-22 16:00:00 0.90996755834495401949 0.99178105208235334267   \n",
       "2017-11-22 18:00:00 0.99178105208235334267 1.12492850259357979326   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-3                    t-2   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-21 22:00:00 1.71687319238838842494 0.90996755834495401949   \n",
       "2017-11-22 12:00:00 0.90996755834495401949 0.99178105208235334267   \n",
       "2017-11-22 14:00:00 0.99178105208235334267 1.12492850259357979326   \n",
       "2017-11-22 16:00:00 1.12492850259357979326 1.68158109707269565192   \n",
       "2017-11-22 18:00:00 1.68158109707269565192 1.65430993250853264342   \n",
       "\n",
       "tensor                                                             \n",
       "feature                                                            \n",
       "time step                              t-1                      t  \n",
       "Epoch_Time_of_Clock                                                \n",
       "2017-11-21 22:00:00 0.99178105208235334267 1.12492850259357979326  \n",
       "2017-11-22 12:00:00 1.12492850259357979326 1.68158109707269565192  \n",
       "2017-11-22 14:00:00 1.68158109707269565192 1.65430993250853264342  \n",
       "2017-11-22 16:00:00 1.65430993250853264342 1.54362108807462417026  \n",
       "2017-11-22 18:00:00 1.54362108807462417026 0.73992382634079278958  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back_dt = dt.datetime.strptime(valid_start_dt, '%Y-%m-%d %H:%M:%S') - dt.timedelta(hours=T-1)\n",
    "valid = df.copy()[(df.index >=look_back_dt) & (df.index < test_start_dt)][['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']]\n",
    "valid[['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']] = X_scaler.transform(valid)\n",
    "valid_inputs = TimeSeriesTensor(valid, var_name, HORIZON, tensor_structure,freq = None)\n",
    "valid_inputs.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a RNN forecasting model with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('./images/simple_encoder_decoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Flatten\n",
    "from keras.callbacks import EarlyStopping ,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(LATENT_DIM, input_shape=(T,5) ,return_sequences=True))\n",
    "model.add(LSTM(LATENT_DIM))\n",
    "model.add(RepeatVector(HORIZON))\n",
    "model.add(LSTM(LATENT_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 6, 64)             17920     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 6, 64)             33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 6, 1)              65        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 84,033\n",
      "Trainable params: 84,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = ModelCheckpoint(str(sat_var) +'_' +  var_name + '_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 103 samples, validate on 13 samples\n",
      "Epoch 1/1000\n",
      "103/103 [==============================] - 0s 866us/step - loss: 0.0136 - val_loss: 0.0590\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 0s 849us/step - loss: 0.0244 - val_loss: 0.0288\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 0s 919us/step - loss: 0.0086 - val_loss: 0.0401\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0331\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 0s 813us/step - loss: 0.0063 - val_loss: 0.0295\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0301\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0328\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0245\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 0s 918us/step - loss: 0.0129 - val_loss: 0.0311\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0302\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0377\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0246\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0296\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0220\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 0s 766us/step - loss: 0.0066 - val_loss: 0.0397\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 0s 865us/step - loss: 0.0087 - val_loss: 0.0325\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 0s 756us/step - loss: 0.0081 - val_loss: 0.0379\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 0s 815us/step - loss: 0.0067 - val_loss: 0.0273\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0390\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0517\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0441\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0371\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0330\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0272\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0319\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 0s 861us/step - loss: 0.0061 - val_loss: 0.0375\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 0s 807us/step - loss: 0.0123 - val_loss: 0.0404\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 0s 803us/step - loss: 0.0087 - val_loss: 0.0318\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 0s 789us/step - loss: 0.0048 - val_loss: 0.0371\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 0s 817us/step - loss: 0.0060 - val_loss: 0.0301\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 0s 798us/step - loss: 0.0095 - val_loss: 0.0377\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0379\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0460\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 0s 936us/step - loss: 0.0072 - val_loss: 0.0366\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0339\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0360\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0464\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 0s 955us/step - loss: 0.0070 - val_loss: 0.0296\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0361\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0351\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0334\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0310\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0379\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 0s 859us/step - loss: 0.0080 - val_loss: 0.0491\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 0s 951us/step - loss: 0.0068 - val_loss: 0.0415\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0356\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 0s 843us/step - loss: 0.0117 - val_loss: 0.0447\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0282\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0427\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0337\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0386\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0208\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 0s 943us/step - loss: 0.0047 - val_loss: 0.0338\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0273\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0473\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0429\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0082 - val_loss: 0.0359\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 0s 815us/step - loss: 0.0072 - val_loss: 0.0336\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 0s 852us/step - loss: 0.0037 - val_loss: 0.0377\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0483\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0348\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0434\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0425\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 0s 773us/step - loss: 0.0039 - val_loss: 0.0425\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 0s 692us/step - loss: 0.0083 - val_loss: 0.0529\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 0s 758us/step - loss: 0.0046 - val_loss: 0.0403\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0446\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0285\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 0s 785us/step - loss: 0.0082 - val_loss: 0.0549\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 0s 555us/step - loss: 0.0060 - val_loss: 0.0557\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 0s 763us/step - loss: 0.0081 - val_loss: 0.0407\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0046 - val_loss: 0.0335\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0043 - val_loss: 0.0404\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0338\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0355\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0268\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0055 - val_loss: 0.0401\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0372\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0432\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 0s 831us/step - loss: 0.0036 - val_loss: 0.0342\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 0s 861us/step - loss: 0.0036 - val_loss: 0.0458\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0295\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0637\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0044 - val_loss: 0.0543\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 0s 661us/step - loss: 0.0078 - val_loss: 0.0554\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 0s 656us/step - loss: 0.0080 - val_loss: 0.0376\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 0s 696us/step - loss: 0.0044 - val_loss: 0.0490\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 0s 690us/step - loss: 0.0034 - val_loss: 0.0446\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0070 - val_loss: 0.0529\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 0s 784us/step - loss: 0.0084 - val_loss: 0.0371\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0458\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0356\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0502\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0416\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 0s 904us/step - loss: 0.0034 - val_loss: 0.0573\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 0s 643us/step - loss: 0.0057 - val_loss: 0.0476\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 0s 918us/step - loss: 0.0067 - val_loss: 0.0685\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0029 - val_loss: 0.0494\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0055 - val_loss: 0.0525\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 0s 735us/step - loss: 0.0129 - val_loss: 0.0266\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0058 - val_loss: 0.0524\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0338\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0404\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0293\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 0s 787us/step - loss: 0.0037 - val_loss: 0.0362\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 0s 663us/step - loss: 0.0037 - val_loss: 0.0401\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 0s 853us/step - loss: 0.0101 - val_loss: 0.0470\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 0s 654us/step - loss: 0.0044 - val_loss: 0.0482\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 0s 722us/step - loss: 0.0031 - val_loss: 0.0711\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0052 - val_loss: 0.0732\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 0s 671us/step - loss: 0.0087 - val_loss: 0.0858\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 0s 684us/step - loss: 0.0035 - val_loss: 0.0675\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0045 - val_loss: 0.0815\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 0s 737us/step - loss: 0.0077 - val_loss: 0.0486\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 0s 732us/step - loss: 0.0060 - val_loss: 0.0545\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 0s 601us/step - loss: 0.0034 - val_loss: 0.0414\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 0s 742us/step - loss: 0.0055 - val_loss: 0.0414\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 0s 797us/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 0s 802us/step - loss: 0.0037 - val_loss: 0.0347\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 0s 726us/step - loss: 0.0041 - val_loss: 0.0414\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 0s 596us/step - loss: 0.0099 - val_loss: 0.0500\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0066 - val_loss: 0.0391\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 0s 612us/step - loss: 0.0046 - val_loss: 0.0715\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 0s 664us/step - loss: 0.0059 - val_loss: 0.0675\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 0s 639us/step - loss: 0.0065 - val_loss: 0.0772\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 0s 694us/step - loss: 0.0040 - val_loss: 0.0535\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 0s 837us/step - loss: 0.0041 - val_loss: 0.0562\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 0s 730us/step - loss: 0.0078 - val_loss: 0.0279\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0049 - val_loss: 0.0429\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 0s 760us/step - loss: 0.0031 - val_loss: 0.0363\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 0s 770us/step - loss: 0.0065 - val_loss: 0.0523\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 0s 755us/step - loss: 0.0084 - val_loss: 0.0336\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 0s 616us/step - loss: 0.0034 - val_loss: 0.0492\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 0s 726us/step - loss: 0.0047 - val_loss: 0.0600\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 0s 741us/step - loss: 0.0078 - val_loss: 0.0805\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 0s 727us/step - loss: 0.0056 - val_loss: 0.0630\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 0s 792us/step - loss: 0.0062 - val_loss: 0.0913\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0055 - val_loss: 0.0554\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 0s 584us/step - loss: 0.0039 - val_loss: 0.0628\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0033 - val_loss: 0.0364\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 0s 787us/step - loss: 0.0040 - val_loss: 0.0481\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0073 - val_loss: 0.0245\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 0s 723us/step - loss: 0.0041 - val_loss: 0.0408\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 0s 794us/step - loss: 0.0042 - val_loss: 0.0454\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 0s 632us/step - loss: 0.0084 - val_loss: 0.0531\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 0s 733us/step - loss: 0.0056 - val_loss: 0.0545\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 0s 809us/step - loss: 0.0033 - val_loss: 0.0794\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 0s 702us/step - loss: 0.0039 - val_loss: 0.0980\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 0s 817us/step - loss: 0.0084 - val_loss: 0.0854\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 0s 590us/step - loss: 0.0039 - val_loss: 0.0499\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 0s 730us/step - loss: 0.0049 - val_loss: 0.0571\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 0s 779us/step - loss: 0.0059 - val_loss: 0.0372\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 0s 743us/step - loss: 0.0041 - val_loss: 0.0509\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 0s 801us/step - loss: 0.0040 - val_loss: 0.0302\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0036 - val_loss: 0.0390\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 0s 795us/step - loss: 0.0067 - val_loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0027 - val_loss: 0.0538\n",
      "Epoch 158/1000\n",
      "103/103 [==============================] - 0s 666us/step - loss: 0.0050 - val_loss: 0.0756\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 0s 671us/step - loss: 0.0098 - val_loss: 0.0919\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 0s 671us/step - loss: 0.0064 - val_loss: 0.0671\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 0s 672us/step - loss: 0.0045 - val_loss: 0.0860\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0038 - val_loss: 0.0639\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 0s 581us/step - loss: 0.0040 - val_loss: 0.0724\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 0s 676us/step - loss: 0.0046 - val_loss: 0.0389\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 0s 673us/step - loss: 0.0029 - val_loss: 0.0410\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 0s 734us/step - loss: 0.0072 - val_loss: 0.0320\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0048 - val_loss: 0.0511\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 0s 717us/step - loss: 0.0068 - val_loss: 0.0558\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0050 - val_loss: 0.0776\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 0s 700us/step - loss: 0.0049 - val_loss: 0.0669\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 0s 542us/step - loss: 0.0048 - val_loss: 0.0950\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 0s 692us/step - loss: 0.0053 - val_loss: 0.0686\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 0s 575us/step - loss: 0.0049 - val_loss: 0.0792\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 0s 693us/step - loss: 0.0025 - val_loss: 0.0461\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 0s 670us/step - loss: 0.0033 - val_loss: 0.0548\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 0s 676us/step - loss: 0.0083 - val_loss: 0.0305\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 0s 889us/step - loss: 0.0039 - val_loss: 0.0468\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 0s 755us/step - loss: 0.0040 - val_loss: 0.0518\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 0s 691us/step - loss: 0.0079 - val_loss: 0.0527\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 0s 698us/step - loss: 0.0046 - val_loss: 0.0412\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 0s 762us/step - loss: 0.0029 - val_loss: 0.0760\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 0s 818us/step - loss: 0.0043 - val_loss: 0.0789\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0069 - val_loss: 0.0895\n",
      "Epoch 184/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0027 - val_loss: 0.0513\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 0s 853us/step - loss: 0.0032 - val_loss: 0.0634\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0413\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 0s 776us/step - loss: 0.0040 - val_loss: 0.0643\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 0s 675us/step - loss: 0.0026 - val_loss: 0.0441\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 0s 707us/step - loss: 0.0036 - val_loss: 0.0458\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0065 - val_loss: 0.0284\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0043 - val_loss: 0.0551\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - 0s 743us/step - loss: 0.0051 - val_loss: 0.0596\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.0089 - val_loss: 0.0630\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 0s 712us/step - loss: 0.0031 - val_loss: 0.0525\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 0s 686us/step - loss: 0.0031 - val_loss: 0.0776\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 0s 727us/step - loss: 0.0043 - val_loss: 0.0601\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 0s 712us/step - loss: 0.0046 - val_loss: 0.0746\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 0s 696us/step - loss: 0.0023 - val_loss: 0.0412\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0036 - val_loss: 0.0538\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 0s 625us/step - loss: 0.0080 - val_loss: 0.0290\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 0s 687us/step - loss: 0.0044 - val_loss: 0.0546\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0039 - val_loss: 0.0594\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 0s 707us/step - loss: 0.0077 - val_loss: 0.0538\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0034 - val_loss: 0.0418\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 0s 713us/step - loss: 0.0027 - val_loss: 0.0688\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0037 - val_loss: 0.0695\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 0s 729us/step - loss: 0.0059 - val_loss: 0.0776\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0033 - val_loss: 0.0424\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0025 - val_loss: 0.0538\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 0s 701us/step - loss: 0.0065 - val_loss: 0.0363\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 0s 703us/step - loss: 0.0045 - val_loss: 0.0718\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 0s 737us/step - loss: 0.0042 - val_loss: 0.0544\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 0s 648us/step - loss: 0.0062 - val_loss: 0.0576\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0052 - val_loss: 0.0395\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 0s 564us/step - loss: 0.0028 - val_loss: 0.0626\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 0s 740us/step - loss: 0.0026 - val_loss: 0.0606\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 0s 612us/step - loss: 0.0049 - val_loss: 0.0639\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 0s 756us/step - loss: 0.0034 - val_loss: 0.0358\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 0s 741us/step - loss: 0.0033 - val_loss: 0.0463\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 0s 693us/step - loss: 0.0054 - val_loss: 0.0485\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0074 - val_loss: 0.0568\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0041 - val_loss: 0.0390\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0023 - val_loss: 0.0593\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0044 - val_loss: 0.0453\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 0s 724us/step - loss: 0.0040 - val_loss: 0.0713\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0028 - val_loss: 0.0735\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0058 - val_loss: 0.0793\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 0s 702us/step - loss: 0.0033 - val_loss: 0.0455\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 0s 754us/step - loss: 0.0046 - val_loss: 0.0693\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 0s 666us/step - loss: 0.0052 - val_loss: 0.0508\n",
      "Epoch 231/1000\n",
      "103/103 [==============================] - 0s 763us/step - loss: 0.0061 - val_loss: 0.0541\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 0s 722us/step - loss: 0.0044 - val_loss: 0.0218\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 0s 710us/step - loss: 0.0033 - val_loss: 0.0393\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 740us/step - loss: 0.0051 - val_loss: 0.0339\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 0s 677us/step - loss: 0.0046 - val_loss: 0.0603\n",
      "Epoch 236/1000\n",
      "103/103 [==============================] - 0s 660us/step - loss: 0.0044 - val_loss: 0.0577\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 0s 678us/step - loss: 0.0053 - val_loss: 0.0887\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 0s 692us/step - loss: 0.0045 - val_loss: 0.0711\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.0037 - val_loss: 0.0963\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 0s 674us/step - loss: 0.0038 - val_loss: 0.0735\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 0s 656us/step - loss: 0.0035 - val_loss: 0.0750\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 0s 707us/step - loss: 0.0050 - val_loss: 0.0322\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 0s 667us/step - loss: 0.0047 - val_loss: 0.0431\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 0s 655us/step - loss: 0.0043 - val_loss: 0.0294\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 0s 690us/step - loss: 0.0056 - val_loss: 0.0455\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 0s 683us/step - loss: 0.0058 - val_loss: 0.0318\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0025 - val_loss: 0.0702\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 0s 667us/step - loss: 0.0041 - val_loss: 0.0804\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 0s 701us/step - loss: 0.0066 - val_loss: 0.0941\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 0s 655us/step - loss: 0.0034 - val_loss: 0.0676\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0031 - val_loss: 0.0787\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0042 - val_loss: 0.0459\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 0s 710us/step - loss: 0.0039 - val_loss: 0.0675\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 0s 671us/step - loss: 0.0042 - val_loss: 0.0311\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 0s 664us/step - loss: 0.0035 - val_loss: 0.0393\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 0s 686us/step - loss: 0.0060 - val_loss: 0.0264\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 0s 699us/step - loss: 0.0025 - val_loss: 0.0576\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.0042 - val_loss: 0.0772\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 0s 679us/step - loss: 0.0083 - val_loss: 0.0943\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0038 - val_loss: 0.0783\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 0s 717us/step - loss: 0.0037 - val_loss: 0.0926\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 0s 656us/step - loss: 0.0039 - val_loss: 0.0584\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 0s 749us/step - loss: 0.0030 - val_loss: 0.0709\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0034 - val_loss: 0.0371\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 0s 721us/step - loss: 0.0030 - val_loss: 0.0415\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 0s 686us/step - loss: 0.0058 - val_loss: 0.0274\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 0s 736us/step - loss: 0.0034 - val_loss: 0.0519\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 0s 732us/step - loss: 0.0046 - val_loss: 0.0706\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 0s 723us/step - loss: 0.0055 - val_loss: 0.1043\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 0s 701us/step - loss: 0.0050 - val_loss: 0.0904\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0050 - val_loss: 0.1058\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 0s 676us/step - loss: 0.0037 - val_loss: 0.0684\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0027 - val_loss: 0.0733\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0033 - val_loss: 0.0385\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 0s 678us/step - loss: 0.0027 - val_loss: 0.0413\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 0s 695us/step - loss: 0.0052 - val_loss: 0.0294\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 0s 753us/step - loss: 0.0026 - val_loss: 0.0582\n",
      "Epoch 278/1000\n",
      "103/103 [==============================] - 0s 715us/step - loss: 0.0058 - val_loss: 0.0608\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 0s 635us/step - loss: 0.0063 - val_loss: 0.1114\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 0s 750us/step - loss: 0.0058 - val_loss: 0.0830\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 0s 694us/step - loss: 0.0040 - val_loss: 0.0991\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 0s 532us/step - loss: 0.0029 - val_loss: 0.0683\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 0s 680us/step - loss: 0.0024 - val_loss: 0.0690\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 0s 720us/step - loss: 0.0029 - val_loss: 0.0348\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 0s 671us/step - loss: 0.0027 - val_loss: 0.0412\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 0s 736us/step - loss: 0.0059 - val_loss: 0.0330\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0035 - val_loss: 0.0649\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 0s 746us/step - loss: 0.0061 - val_loss: 0.0680\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0052 - val_loss: 0.1153\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 0s 746us/step - loss: 0.0054 - val_loss: 0.0814\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 0s 743us/step - loss: 0.0033 - val_loss: 0.0933\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0024 - val_loss: 0.0669\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 0s 646us/step - loss: 0.0024 - val_loss: 0.0633\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0034 - val_loss: 0.0320\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 0s 722us/step - loss: 0.0029 - val_loss: 0.0420\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 0s 734us/step - loss: 0.0052 - val_loss: 0.0368\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 0s 693us/step - loss: 0.0048 - val_loss: 0.0678\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0057 - val_loss: 0.0663\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0046 - val_loss: 0.1057\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0050 - val_loss: 0.0764\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 0s 675us/step - loss: 0.0029 - val_loss: 0.0887\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 0s 658us/step - loss: 0.0023 - val_loss: 0.0695\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 0s 729us/step - loss: 0.0023 - val_loss: 0.0599\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 0s 751us/step - loss: 0.0041 - val_loss: 0.0306\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 0s 736us/step - loss: 0.0037 - val_loss: 0.0424\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0038 - val_loss: 0.0450\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 0s 729us/step - loss: 0.0086 - val_loss: 0.0574\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0043 - val_loss: 0.0518\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 0s 751us/step - loss: 0.0024 - val_loss: 0.0926\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0034 - val_loss: 0.0810\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 761us/step - loss: 0.0039 - val_loss: 0.0942\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 0s 637us/step - loss: 0.0029 - val_loss: 0.0633\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 0s 682us/step - loss: 0.0025 - val_loss: 0.0645\n",
      "Epoch 314/1000\n",
      "103/103 [==============================] - 0s 662us/step - loss: 0.0049 - val_loss: 0.0386\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 0s 684us/step - loss: 0.0034 - val_loss: 0.0629\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 0s 545us/step - loss: 0.0038 - val_loss: 0.0414\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 0s 654us/step - loss: 0.0059 - val_loss: 0.0567\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 0s 627us/step - loss: 0.0047 - val_loss: 0.0419\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 0s 696us/step - loss: 0.0032 - val_loss: 0.0750\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 0s 809us/step - loss: 0.0034 - val_loss: 0.0912\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 0s 653us/step - loss: 0.0054 - val_loss: 0.0819\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 0s 710us/step - loss: 0.0015 - val_loss: 0.0590\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0018 - val_loss: 0.0628\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 0s 665us/step - loss: 0.0053 - val_loss: 0.0414\n",
      "Epoch 325/1000\n",
      "103/103 [==============================] - 0s 696us/step - loss: 0.0044 - val_loss: 0.0714\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 0s 570us/step - loss: 0.0035 - val_loss: 0.0388\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 0s 692us/step - loss: 0.0035 - val_loss: 0.0487\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 0s 636us/step - loss: 0.0053 - val_loss: 0.0369\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 0s 799us/step - loss: 0.0033 - val_loss: 0.0676\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0036 - val_loss: 0.0812\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 0s 654us/step - loss: 0.0061 - val_loss: 0.0794\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 0s 676us/step - loss: 0.0021 - val_loss: 0.0597\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 0s 677us/step - loss: 0.0019 - val_loss: 0.0739\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 0s 649us/step - loss: 0.0036 - val_loss: 0.0596\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 0s 660us/step - loss: 0.0042 - val_loss: 0.0765\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 0s 690us/step - loss: 0.0032 - val_loss: 0.0379\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0024 - val_loss: 0.0442\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 0s 666us/step - loss: 0.0056 - val_loss: 0.0308\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0031 - val_loss: 0.0633\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 0s 715us/step - loss: 0.0038 - val_loss: 0.0809\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 0s 712us/step - loss: 0.0069 - val_loss: 0.0925\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 0s 706us/step - loss: 0.0038 - val_loss: 0.0727\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0032 - val_loss: 0.0914\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 0s 677us/step - loss: 0.0025 - val_loss: 0.0651\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0021 - val_loss: 0.0730\n",
      "Epoch 346/1000\n",
      "103/103 [==============================] - 0s 720us/step - loss: 0.0030 - val_loss: 0.0398\n",
      "Epoch 347/1000\n",
      "103/103 [==============================] - 0s 670us/step - loss: 0.0025 - val_loss: 0.0475\n",
      "Epoch 348/1000\n",
      "103/103 [==============================] - 0s 715us/step - loss: 0.0049 - val_loss: 0.0346\n",
      "Epoch 349/1000\n",
      "103/103 [==============================] - 0s 713us/step - loss: 0.0034 - val_loss: 0.0735\n",
      "Epoch 350/1000\n",
      "103/103 [==============================] - 0s 706us/step - loss: 0.0052 - val_loss: 0.0714\n",
      "Epoch 351/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0055 - val_loss: 0.1239\n",
      "Epoch 352/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0068 - val_loss: 0.0743\n",
      "Epoch 353/1000\n",
      "103/103 [==============================] - 0s 734us/step - loss: 0.0024 - val_loss: 0.0831\n",
      "Epoch 354/1000\n",
      "103/103 [==============================] - 0s 715us/step - loss: 0.0012 - val_loss: 0.0643\n",
      "Epoch 355/1000\n",
      "103/103 [==============================] - 0s 736us/step - loss: 0.0018 - val_loss: 0.0628\n",
      "Epoch 356/1000\n",
      "103/103 [==============================] - 0s 703us/step - loss: 0.0035 - val_loss: 0.0325\n",
      "Epoch 357/1000\n",
      "103/103 [==============================] - 0s 559us/step - loss: 0.0033 - val_loss: 0.0454\n",
      "Epoch 358/1000\n",
      "103/103 [==============================] - 0s 702us/step - loss: 0.0031 - val_loss: 0.0526\n",
      "Epoch 359/1000\n",
      "103/103 [==============================] - 0s 684us/step - loss: 0.0081 - val_loss: 0.0663\n",
      "Epoch 360/1000\n",
      "103/103 [==============================] - 0s 631us/step - loss: 0.0049 - val_loss: 0.0515\n",
      "Epoch 361/1000\n",
      "103/103 [==============================] - 0s 722us/step - loss: 0.0024 - val_loss: 0.0971\n",
      "Epoch 362/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0032 - val_loss: 0.0798\n",
      "Epoch 363/1000\n",
      "103/103 [==============================] - 0s 692us/step - loss: 0.0034 - val_loss: 0.0925\n",
      "Epoch 364/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0028 - val_loss: 0.0633\n",
      "Epoch 365/1000\n",
      "103/103 [==============================] - 0s 699us/step - loss: 0.0023 - val_loss: 0.0628\n",
      "Epoch 366/1000\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.0040 - val_loss: 0.0397\n",
      "Epoch 367/1000\n",
      "103/103 [==============================] - 0s 728us/step - loss: 0.0027 - val_loss: 0.0608\n",
      "Epoch 368/1000\n",
      "103/103 [==============================] - 0s 728us/step - loss: 0.0036 - val_loss: 0.0447\n",
      "Epoch 369/1000\n",
      "103/103 [==============================] - 0s 767us/step - loss: 0.0058 - val_loss: 0.0669\n",
      "Epoch 370/1000\n",
      "103/103 [==============================] - 0s 779us/step - loss: 0.0042 - val_loss: 0.0559\n",
      "Epoch 371/1000\n",
      "103/103 [==============================] - 0s 735us/step - loss: 0.0031 - val_loss: 0.0922\n",
      "Epoch 372/1000\n",
      "103/103 [==============================] - 0s 821us/step - loss: 0.0036 - val_loss: 0.0962\n",
      "Epoch 373/1000\n",
      "103/103 [==============================] - 0s 947us/step - loss: 0.0047 - val_loss: 0.0889\n",
      "Epoch 374/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0569\n",
      "Epoch 375/1000\n",
      "103/103 [==============================] - 0s 840us/step - loss: 0.0018 - val_loss: 0.0588\n",
      "Epoch 376/1000\n",
      "103/103 [==============================] - 0s 730us/step - loss: 0.0049 - val_loss: 0.0407\n",
      "Epoch 377/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0033 - val_loss: 0.0665\n",
      "Epoch 378/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0039 - val_loss: 0.0395\n",
      "Epoch 379/1000\n",
      "103/103 [==============================] - 0s 750us/step - loss: 0.0043 - val_loss: 0.0580\n",
      "Epoch 380/1000\n",
      "103/103 [==============================] - 0s 580us/step - loss: 0.0047 - val_loss: 0.0450\n",
      "Epoch 381/1000\n",
      "103/103 [==============================] - 0s 751us/step - loss: 0.0031 - val_loss: 0.0863\n",
      "Epoch 382/1000\n",
      "103/103 [==============================] - 0s 924us/step - loss: 0.0027 - val_loss: 0.0929\n",
      "Epoch 383/1000\n",
      "103/103 [==============================] - 0s 962us/step - loss: 0.0045 - val_loss: 0.0824\n",
      "Epoch 384/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0514\n",
      "Epoch 385/1000\n",
      "103/103 [==============================] - 0s 974us/step - loss: 0.0027 - val_loss: 0.0630\n",
      "Epoch 386/1000\n",
      "103/103 [==============================] - 0s 844us/step - loss: 0.0036 - val_loss: 0.0525\n",
      "Epoch 387/1000\n",
      "103/103 [==============================] - 0s 958us/step - loss: 0.0049 - val_loss: 0.0573\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 930us/step - loss: 0.0045 - val_loss: 0.0339\n",
      "Epoch 389/1000\n",
      "103/103 [==============================] - 0s 920us/step - loss: 0.0015 - val_loss: 0.0579\n",
      "Epoch 390/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0573\n",
      "Epoch 391/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0958\n",
      "Epoch 392/1000\n",
      "103/103 [==============================] - 0s 763us/step - loss: 0.0039 - val_loss: 0.0877\n",
      "Epoch 393/1000\n",
      "103/103 [==============================] - 0s 850us/step - loss: 0.0046 - val_loss: 0.0923\n",
      "Epoch 394/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0042 - val_loss: 0.0587\n",
      "Epoch 395/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0039 - val_loss: 0.0859\n",
      "Epoch 396/1000\n",
      "103/103 [==============================] - 0s 695us/step - loss: 0.0021 - val_loss: 0.0529\n",
      "Epoch 397/1000\n",
      "103/103 [==============================] - 0s 658us/step - loss: 0.0031 - val_loss: 0.0469\n",
      "Epoch 398/1000\n",
      "103/103 [==============================] - 0s 701us/step - loss: 0.0046 - val_loss: 0.0279\n",
      "Epoch 399/1000\n",
      "103/103 [==============================] - 0s 607us/step - loss: 0.0025 - val_loss: 0.0541\n",
      "Epoch 400/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0027 - val_loss: 0.0757\n",
      "Epoch 401/1000\n",
      "103/103 [==============================] - 0s 573us/step - loss: 0.0071 - val_loss: 0.0865\n",
      "Epoch 402/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.0029 - val_loss: 0.0728\n",
      "Epoch 403/1000\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.0029 - val_loss: 0.0960\n",
      "Epoch 404/1000\n",
      "103/103 [==============================] - 0s 666us/step - loss: 0.0035 - val_loss: 0.0667\n",
      "Epoch 405/1000\n",
      "103/103 [==============================] - 0s 823us/step - loss: 0.0026 - val_loss: 0.0741\n",
      "Epoch 406/1000\n",
      "103/103 [==============================] - 0s 680us/step - loss: 0.0025 - val_loss: 0.0440\n",
      "Epoch 407/1000\n",
      "103/103 [==============================] - 0s 692us/step - loss: 0.0017 - val_loss: 0.0548\n",
      "Epoch 408/1000\n",
      "103/103 [==============================] - 0s 696us/step - loss: 0.0038 - val_loss: 0.0386\n",
      "Epoch 409/1000\n",
      "103/103 [==============================] - 0s 707us/step - loss: 0.0037 - val_loss: 0.0695\n",
      "Epoch 410/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0044 - val_loss: 0.0703\n",
      "Epoch 411/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0045 - val_loss: 0.1107\n",
      "Epoch 412/1000\n",
      "103/103 [==============================] - 0s 716us/step - loss: 0.0056 - val_loss: 0.0738\n",
      "Epoch 413/1000\n",
      "103/103 [==============================] - 0s 643us/step - loss: 0.0029 - val_loss: 0.0891\n",
      "Epoch 414/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0012 - val_loss: 0.0675\n",
      "Epoch 415/1000\n",
      "103/103 [==============================] - 0s 682us/step - loss: 0.0019 - val_loss: 0.0710\n",
      "Epoch 416/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0037 - val_loss: 0.0364\n",
      "Epoch 417/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0029 - val_loss: 0.0441\n",
      "Epoch 418/1000\n",
      "103/103 [==============================] - 0s 695us/step - loss: 0.0024 - val_loss: 0.0482\n",
      "Epoch 419/1000\n",
      "103/103 [==============================] - 0s 678us/step - loss: 0.0065 - val_loss: 0.0682\n",
      "Epoch 420/1000\n",
      "103/103 [==============================] - 0s 721us/step - loss: 0.0049 - val_loss: 0.0544\n",
      "Epoch 421/1000\n",
      "103/103 [==============================] - 0s 722us/step - loss: 0.0029 - val_loss: 0.0986\n",
      "Epoch 422/1000\n",
      "103/103 [==============================] - 0s 681us/step - loss: 0.0032 - val_loss: 0.0797\n",
      "Epoch 423/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0030 - val_loss: 0.0899\n",
      "Epoch 424/1000\n",
      "103/103 [==============================] - 0s 669us/step - loss: 0.0024 - val_loss: 0.0652\n",
      "Epoch 425/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0020 - val_loss: 0.0581\n",
      "Epoch 426/1000\n",
      "103/103 [==============================] - 0s 753us/step - loss: 0.0041 - val_loss: 0.0380\n",
      "Epoch 427/1000\n",
      "103/103 [==============================] - 0s 688us/step - loss: 0.0019 - val_loss: 0.0555\n",
      "Epoch 428/1000\n",
      "103/103 [==============================] - 0s 676us/step - loss: 0.0030 - val_loss: 0.0428\n",
      "Epoch 429/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0062 - val_loss: 0.0778\n",
      "Epoch 430/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0046 - val_loss: 0.0647\n",
      "Epoch 431/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0034 - val_loss: 0.1016\n",
      "Epoch 432/1000\n",
      "103/103 [==============================] - 0s 720us/step - loss: 0.0029 - val_loss: 0.0811\n",
      "Epoch 433/1000\n",
      "103/103 [==============================] - 0s 591us/step - loss: 0.0029 - val_loss: 0.0850\n",
      "Epoch 434/1000\n",
      "103/103 [==============================] - 0s 706us/step - loss: 0.0022 - val_loss: 0.0483\n",
      "Epoch 435/1000\n",
      "103/103 [==============================] - 0s 553us/step - loss: 0.0018 - val_loss: 0.0514\n",
      "Epoch 436/1000\n",
      "103/103 [==============================] - 0s 851us/step - loss: 0.0040 - val_loss: 0.0416\n",
      "Epoch 437/1000\n",
      "103/103 [==============================] - 0s 593us/step - loss: 0.0031 - val_loss: 0.0681\n",
      "Epoch 438/1000\n",
      "103/103 [==============================] - 0s 981us/step - loss: 0.0049 - val_loss: 0.0560\n",
      "Epoch 439/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0982\n",
      "Epoch 440/1000\n",
      "103/103 [==============================] - 0s 783us/step - loss: 0.0042 - val_loss: 0.0700\n",
      "Epoch 441/1000\n",
      "103/103 [==============================] - 0s 824us/step - loss: 0.0028 - val_loss: 0.0901\n",
      "Epoch 442/1000\n",
      "103/103 [==============================] - 0s 621us/step - loss: 0.0017 - val_loss: 0.0731\n",
      "Epoch 443/1000\n",
      "103/103 [==============================] - 0s 918us/step - loss: 0.0026 - val_loss: 0.0726\n",
      "Epoch 444/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0375\n",
      "Epoch 445/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0439\n",
      "Epoch 446/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0434\n",
      "Epoch 447/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0045 - val_loss: 0.0803\n",
      "Epoch 448/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0055 - val_loss: 0.0721\n",
      "Epoch 449/1000\n",
      "103/103 [==============================] - 0s 728us/step - loss: 0.0043 - val_loss: 0.1069\n",
      "Epoch 450/1000\n",
      "103/103 [==============================] - 0s 743us/step - loss: 0.0042 - val_loss: 0.0724\n",
      "Epoch 451/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0023 - val_loss: 0.0826\n",
      "Epoch 452/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0014 - val_loss: 0.0646\n",
      "Epoch 453/1000\n",
      "103/103 [==============================] - 0s 707us/step - loss: 0.0017 - val_loss: 0.0566\n",
      "Epoch 454/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0035 - val_loss: 0.0329\n",
      "Epoch 455/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0022 - val_loss: 0.0469\n",
      "Epoch 456/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0023 - val_loss: 0.0503\n",
      "Epoch 457/1000\n",
      "103/103 [==============================] - 0s 674us/step - loss: 0.0066 - val_loss: 0.0815\n",
      "Epoch 458/1000\n",
      "103/103 [==============================] - 0s 715us/step - loss: 0.0045 - val_loss: 0.0783\n",
      "Epoch 459/1000\n",
      "103/103 [==============================] - 0s 802us/step - loss: 0.0037 - val_loss: 0.1074\n",
      "Epoch 460/1000\n",
      "103/103 [==============================] - 0s 721us/step - loss: 0.0038 - val_loss: 0.0681\n",
      "Epoch 461/1000\n",
      "103/103 [==============================] - 0s 664us/step - loss: 0.0024 - val_loss: 0.0763\n",
      "Epoch 462/1000\n",
      "103/103 [==============================] - 0s 794us/step - loss: 0.0018 - val_loss: 0.0553\n",
      "Epoch 463/1000\n",
      "103/103 [==============================] - 0s 624us/step - loss: 0.0017 - val_loss: 0.0526\n",
      "Epoch 464/1000\n",
      "103/103 [==============================] - 0s 759us/step - loss: 0.0034 - val_loss: 0.0353\n",
      "Epoch 465/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 748us/step - loss: 0.0018 - val_loss: 0.0643\n",
      "Epoch 466/1000\n",
      "103/103 [==============================] - 0s 700us/step - loss: 0.0034 - val_loss: 0.0545\n",
      "Epoch 467/1000\n",
      "103/103 [==============================] - 0s 684us/step - loss: 0.0045 - val_loss: 0.1159\n",
      "Epoch 468/1000\n",
      "103/103 [==============================] - 0s 649us/step - loss: 0.0060 - val_loss: 0.0720\n",
      "Epoch 469/1000\n",
      "103/103 [==============================] - 0s 678us/step - loss: 0.0038 - val_loss: 0.0843\n",
      "Epoch 470/1000\n",
      "103/103 [==============================] - 0s 662us/step - loss: 0.0029 - val_loss: 0.0590\n",
      "Epoch 471/1000\n",
      "103/103 [==============================] - 0s 645us/step - loss: 0.0019 - val_loss: 0.0674\n",
      "Epoch 472/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0017 - val_loss: 0.0497\n",
      "Epoch 473/1000\n",
      "103/103 [==============================] - 0s 694us/step - loss: 0.0032 - val_loss: 0.0515\n",
      "Epoch 474/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0038 - val_loss: 0.0376\n",
      "Epoch 475/1000\n",
      "103/103 [==============================] - 0s 661us/step - loss: 0.0023 - val_loss: 0.0651\n",
      "Epoch 476/1000\n",
      "103/103 [==============================] - 0s 756us/step - loss: 0.0023 - val_loss: 0.0788\n",
      "Epoch 477/1000\n",
      "103/103 [==============================] - 0s 750us/step - loss: 0.0058 - val_loss: 0.0912\n",
      "Epoch 478/1000\n",
      "103/103 [==============================] - 0s 700us/step - loss: 0.0030 - val_loss: 0.0657\n",
      "Epoch 479/1000\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.0032 - val_loss: 0.0805\n",
      "Epoch 480/1000\n",
      "103/103 [==============================] - 0s 712us/step - loss: 0.0042 - val_loss: 0.0553\n",
      "Epoch 481/1000\n",
      "103/103 [==============================] - 0s 674us/step - loss: 0.0023 - val_loss: 0.0567\n",
      "Epoch 482/1000\n",
      "103/103 [==============================] - 0s 673us/step - loss: 0.0018 - val_loss: 0.0464\n",
      "Epoch 483/1000\n",
      "103/103 [==============================] - 0s 646us/step - loss: 0.0016 - val_loss: 0.0542\n",
      "Epoch 484/1000\n",
      "103/103 [==============================] - 0s 653us/step - loss: 0.0029 - val_loss: 0.0406\n",
      "Epoch 485/1000\n",
      "103/103 [==============================] - 0s 710us/step - loss: 0.0030 - val_loss: 0.0898\n",
      "Epoch 486/1000\n",
      "103/103 [==============================] - 0s 708us/step - loss: 0.0030 - val_loss: 0.0919\n",
      "Epoch 487/1000\n",
      "103/103 [==============================] - 0s 712us/step - loss: 0.0061 - val_loss: 0.1075\n",
      "Epoch 488/1000\n",
      "103/103 [==============================] - 0s 667us/step - loss: 0.0045 - val_loss: 0.0661\n",
      "Epoch 489/1000\n",
      "103/103 [==============================] - 0s 721us/step - loss: 0.0029 - val_loss: 0.0711\n",
      "Epoch 490/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0014 - val_loss: 0.0509\n",
      "Epoch 491/1000\n",
      "103/103 [==============================] - 0s 706us/step - loss: 0.0017 - val_loss: 0.0554\n",
      "Epoch 492/1000\n",
      "103/103 [==============================] - 0s 712us/step - loss: 0.0029 - val_loss: 0.0388\n",
      "Epoch 493/1000\n",
      "103/103 [==============================] - 0s 695us/step - loss: 0.0027 - val_loss: 0.0575\n",
      "Epoch 494/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0025 - val_loss: 0.0752\n",
      "Epoch 495/1000\n",
      "103/103 [==============================] - 0s 709us/step - loss: 0.0049 - val_loss: 0.1133\n",
      "Epoch 496/1000\n",
      "103/103 [==============================] - 0s 666us/step - loss: 0.0028 - val_loss: 0.0914\n",
      "Epoch 497/1000\n",
      "103/103 [==============================] - 0s 685us/step - loss: 0.0047 - val_loss: 0.1016\n",
      "Epoch 498/1000\n",
      "103/103 [==============================] - 0s 723us/step - loss: 0.0050 - val_loss: 0.0598\n",
      "Epoch 499/1000\n",
      "103/103 [==============================] - 0s 652us/step - loss: 0.0022 - val_loss: 0.0546\n",
      "Epoch 500/1000\n",
      "103/103 [==============================] - 0s 723us/step - loss: 0.0023 - val_loss: 0.0462\n",
      "Epoch 501/1000\n",
      "103/103 [==============================] - 0s 664us/step - loss: 0.0013 - val_loss: 0.0518\n",
      "Epoch 502/1000\n",
      "103/103 [==============================] - 0s 719us/step - loss: 0.0021 - val_loss: 0.0608\n",
      "Epoch 503/1000\n",
      "103/103 [==============================] - 0s 741us/step - loss: 0.0026 - val_loss: 0.1224\n",
      "Epoch 504/1000\n",
      "103/103 [==============================] - 0s 725us/step - loss: 0.0032 - val_loss: 0.0974\n",
      "Epoch 505/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0058 - val_loss: 0.1125\n",
      "Epoch 506/1000\n",
      "103/103 [==============================] - 0s 735us/step - loss: 0.0068 - val_loss: 0.0598\n",
      "Epoch 507/1000\n",
      "103/103 [==============================] - 0s 577us/step - loss: 0.0022 - val_loss: 0.0575\n",
      "Epoch 508/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0015 - val_loss: 0.0466\n",
      "Epoch 509/1000\n",
      "103/103 [==============================] - 0s 718us/step - loss: 0.0010 - val_loss: 0.0511\n",
      "Epoch 510/1000\n",
      "103/103 [==============================] - 0s 693us/step - loss: 0.0015 - val_loss: 0.0568\n",
      "Epoch 511/1000\n",
      "103/103 [==============================] - 0s 688us/step - loss: 0.0029 - val_loss: 0.0979\n",
      "Epoch 512/1000\n",
      "103/103 [==============================] - 0s 726us/step - loss: 0.0030 - val_loss: 0.0934\n",
      "Epoch 513/1000\n",
      "103/103 [==============================] - 0s 721us/step - loss: 0.0058 - val_loss: 0.1015\n",
      "Epoch 514/1000\n",
      "103/103 [==============================] - 0s 652us/step - loss: 0.0045 - val_loss: 0.0647\n",
      "Epoch 515/1000\n",
      "103/103 [==============================] - 0s 743us/step - loss: 0.0030 - val_loss: 0.0703\n",
      "Epoch 516/1000\n",
      "103/103 [==============================] - 0s 694us/step - loss: 0.0026 - val_loss: 0.0543\n",
      "Epoch 517/1000\n",
      "103/103 [==============================] - 0s 730us/step - loss: 0.0017 - val_loss: 0.0479\n",
      "Epoch 518/1000\n",
      "103/103 [==============================] - 0s 729us/step - loss: 0.0024 - val_loss: 0.0455\n",
      "Epoch 519/1000\n",
      "103/103 [==============================] - 0s 661us/step - loss: 0.0016 - val_loss: 0.0727\n",
      "Epoch 520/1000\n",
      "103/103 [==============================] - 0s 730us/step - loss: 0.0021 - val_loss: 0.0723\n",
      "Epoch 521/1000\n",
      "103/103 [==============================] - 0s 696us/step - loss: 0.0037 - val_loss: 0.1230\n",
      "Epoch 522/1000\n",
      "103/103 [==============================] - 0s 748us/step - loss: 0.0050 - val_loss: 0.0853\n",
      "Epoch 523/1000\n",
      "103/103 [==============================] - 0s 720us/step - loss: 0.0039 - val_loss: 0.0807\n",
      "Epoch 524/1000\n",
      "103/103 [==============================] - 0s 749us/step - loss: 0.0041 - val_loss: 0.0540\n",
      "Epoch 525/1000\n",
      "103/103 [==============================] - 0s 714us/step - loss: 0.0018 - val_loss: 0.0615\n",
      "Epoch 526/1000\n",
      "103/103 [==============================] - 0s 715us/step - loss: 0.0022 - val_loss: 0.0499\n",
      "Epoch 527/1000\n",
      "103/103 [==============================] - 0s 697us/step - loss: 0.0025 - val_loss: 0.0621\n",
      "Epoch 528/1000\n",
      "103/103 [==============================] - 0s 738us/step - loss: 0.0026 - val_loss: 0.0486\n",
      "Epoch 529/1000\n",
      "103/103 [==============================] - 0s 673us/step - loss: 0.0031 - val_loss: 0.0810\n",
      "Epoch 530/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.1058\n",
      "Epoch 531/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0864\n",
      "Epoch 532/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0559\n",
      "Epoch 533/1000\n",
      "103/103 [==============================] - 0s 943us/step - loss: 0.0018 - val_loss: 0.0640\n",
      "Epoch 534/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0555\n",
      "Epoch 535/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0610\n",
      "Epoch 536/1000\n",
      "103/103 [==============================] - 0s 820us/step - loss: 0.0016 - val_loss: 0.0616\n",
      "Epoch 537/1000\n",
      "103/103 [==============================] - 0s 797us/step - loss: 0.0036 - val_loss: 0.0730\n",
      "Epoch 538/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0601\n",
      "Epoch 539/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0704\n",
      "Epoch 540/1000\n",
      "103/103 [==============================] - 0s 859us/step - loss: 0.0031 - val_loss: 0.0578\n",
      "Epoch 541/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0551\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0465\n",
      "Epoch 543/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 8.9971e-04 - val_loss: 0.0601\n",
      "Epoch 544/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0608\n",
      "Epoch 545/1000\n",
      "103/103 [==============================] - 0s 581us/step - loss: 0.0034 - val_loss: 0.0858\n",
      "Epoch 546/1000\n",
      "103/103 [==============================] - 0s 749us/step - loss: 0.0021 - val_loss: 0.0641\n",
      "Epoch 547/1000\n",
      "103/103 [==============================] - 0s 698us/step - loss: 0.0029 - val_loss: 0.0796\n",
      "Epoch 548/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0448\n",
      "Epoch 549/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0761\n",
      "Epoch 550/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0757\n",
      "Epoch 551/1000\n",
      "103/103 [==============================] - 0s 896us/step - loss: 0.0039 - val_loss: 0.0487\n",
      "Epoch 552/1000\n",
      "103/103 [==============================] - 0s 948us/step - loss: 0.0024 - val_loss: 0.0419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_inputs['X'],\n",
    "          train_inputs['target'],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(valid_inputs['X'], valid_inputs['target']),\n",
    "          callbacks=[earlystop ,best_val],\n",
    "          verbose=1 , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model.load_weights(str(sat_var) +'_' +  var_name + '_{:02d}.h5'.format(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1225\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0618\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0366\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0115\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0058\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0062\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0053\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0078\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0094\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0061\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0079\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0043\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0112\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0222\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0130\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0054\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0061\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0052\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb0be8cba8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(valid_inputs['X'],\n",
    "          valid_inputs['target'],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=100,\n",
    "          callbacks=[earlystop ,best_val],\n",
    "          verbose=1 , shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Del_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crc</th>\n",
       "      <th colspan=\"6\" halign=\"left\">OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-25 22:00:00</th>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.46962283052577807885</td>\n",
       "      <td>-0.39273867158629655050</td>\n",
       "      <td>-0.47923335037078829135</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27463219356693691076</td>\n",
       "      <td>0.37337886895464111880</td>\n",
       "      <td>0.52855221599246204889</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.38860705922644167565</td>\n",
       "      <td>0.25706379480263585879</td>\n",
       "      <td>0.19129216261319942349</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 12:00:00</th>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.39273867158629655050</td>\n",
       "      <td>-0.47923335037078829135</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37337886895464111880</td>\n",
       "      <td>0.52855221599246204889</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.25706379480263585879</td>\n",
       "      <td>0.19129216261319942349</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 14:00:00</th>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.47923335037078829135</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52855221599246204889</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.19129216261319942349</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 16:00:00</th>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>0.07657504864786630894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.72268683631250651977</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 18:00:00</th>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>0.07657504864786630894</td>\n",
       "      <td>0.20311356023949428407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.72268683631250651977</td>\n",
       "      <td>0.77777001578047755270</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                               target                          \\\n",
       "feature                                   y                           \n",
       "time step                               t+1                     t+2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.08302366920567914865 -0.26429670431587648505   \n",
       "2017-11-26 12:00:00 -0.26429670431587648505 -0.32846415037298160033   \n",
       "2017-11-26 14:00:00 -0.32846415037298160033 -0.87709581405565684165   \n",
       "2017-11-26 16:00:00 -0.87709581405565684165 -0.81132418186622035083   \n",
       "2017-11-26 18:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+3                     t+4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.32846415037298160033 -0.87709581405565684165   \n",
       "2017-11-26 12:00:00 -0.87709581405565684165 -0.81132418186622035083   \n",
       "2017-11-26 14:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-26 16:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-26 18:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+5                     t+6   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-26 12:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-26 14:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "2017-11-26 16:00:00 -0.66213486980703839535 -0.73913580505758535999   \n",
       "2017-11-26 18:00:00 -0.73913580505758535999 -1.26691304879528887639   \n",
       "\n",
       "tensor                                    X                          \\\n",
       "feature                               Del_n                           \n",
       "time step                               t-5                     t-4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.46962283052577807885 -0.39273867158629655050   \n",
       "2017-11-26 12:00:00 -0.39273867158629655050 -0.47923335037078829135   \n",
       "2017-11-26 14:00:00 -0.47923335037078829135 -0.34148256559675088662   \n",
       "2017-11-26 16:00:00 -0.34148256559675088662 -0.65542621465940897885   \n",
       "2017-11-26 18:00:00 -0.65542621465940897885 -0.59936484874735451722   \n",
       "\n",
       "tensor                                                               ...  \\\n",
       "feature                                                              ...   \n",
       "time step                               t-3                     t-2  ...   \n",
       "Epoch_Time_of_Clock                                                  ...   \n",
       "2017-11-25 22:00:00 -0.47923335037078829135 -0.34148256559675088662  ...   \n",
       "2017-11-26 12:00:00 -0.34148256559675088662 -0.65542621465940897885  ...   \n",
       "2017-11-26 14:00:00 -0.65542621465940897885 -0.59936484874735451722  ...   \n",
       "2017-11-26 16:00:00 -0.59936484874735451722  0.07657504864786630894  ...   \n",
       "2017-11-26 18:00:00  0.07657504864786630894  0.20311356023949428407  ...   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                Crc                          \n",
       "time step                              t-3                    t-2   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-25 22:00:00 0.27463219356693691076 0.37337886895464111880   \n",
       "2017-11-26 12:00:00 0.37337886895464111880 0.52855221599246204889   \n",
       "2017-11-26 14:00:00 0.52855221599246204889 0.70992366058212297286   \n",
       "2017-11-26 16:00:00 0.70992366058212297286 0.89935605826465758739   \n",
       "2017-11-26 18:00:00 0.89935605826465758739 0.79859414460373490119   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-1                      t   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-25 22:00:00 0.52855221599246204889 0.70992366058212297286   \n",
       "2017-11-26 12:00:00 0.70992366058212297286 0.89935605826465758739   \n",
       "2017-11-26 14:00:00 0.89935605826465758739 0.79859414460373490119   \n",
       "2017-11-26 16:00:00 0.79859414460373490119 0.72268683631250651977   \n",
       "2017-11-26 18:00:00 0.72268683631250651977 0.77777001578047755270   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                           OMEGA_dot                           \n",
       "time step                               t-5                     t-4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.38860705922644167565  0.25706379480263585879   \n",
       "2017-11-26 12:00:00  0.25706379480263585879  0.19129216261319942349   \n",
       "2017-11-26 14:00:00  0.19129216261319942349 -0.41669438868465402681   \n",
       "2017-11-26 16:00:00 -0.41669438868465402681 -0.37177717644018937193   \n",
       "2017-11-26 18:00:00 -0.37177717644018937193 -0.32204740575379786627   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t-3                     t-2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.19129216261319942349 -0.41669438868465402681   \n",
       "2017-11-26 12:00:00 -0.41669438868465402681 -0.37177717644018937193   \n",
       "2017-11-26 14:00:00 -0.37177717644018937193 -0.32204740575379786627   \n",
       "2017-11-26 16:00:00 -0.32204740575379786627 -0.08302366920567914865   \n",
       "2017-11-26 18:00:00 -0.08302366920567914865 -0.26429670431587648505   \n",
       "\n",
       "tensor                                                               \n",
       "feature                                                              \n",
       "time step                               t-1                       t  \n",
       "Epoch_Time_of_Clock                                                  \n",
       "2017-11-25 22:00:00 -0.37177717644018937193 -0.32204740575379786627  \n",
       "2017-11-26 12:00:00 -0.32204740575379786627 -0.08302366920567914865  \n",
       "2017-11-26 14:00:00 -0.08302366920567914865 -0.26429670431587648505  \n",
       "2017-11-26 16:00:00 -0.26429670431587648505 -0.32846415037298160033  \n",
       "2017-11-26 18:00:00 -0.32846415037298160033 -0.87709581405565684165  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back_dt = dt.datetime.strptime(test_start_dt, '%Y-%m-%d %H:%M:%S') - dt.timedelta(hours=T-1)\n",
    "test = df.copy()[test_start_dt:][['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']]\n",
    "test[['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']] = X_scaler.transform(test)\n",
    "test_inputs = TimeSeriesTensor(test, var_name, HORIZON, tensor_structure,freq =None)\n",
    "test_inputs.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Del_n</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crc</th>\n",
       "      <th colspan=\"6\" halign=\"left\">OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-25 22:00:00</th>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.46962283052577807885</td>\n",
       "      <td>-0.39273867158629655050</td>\n",
       "      <td>-0.47923335037078829135</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27463219356693691076</td>\n",
       "      <td>0.37337886895464111880</td>\n",
       "      <td>0.52855221599246204889</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.38860705922644167565</td>\n",
       "      <td>0.25706379480263585879</td>\n",
       "      <td>0.19129216261319942349</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 12:00:00</th>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.39273867158629655050</td>\n",
       "      <td>-0.47923335037078829135</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37337886895464111880</td>\n",
       "      <td>0.52855221599246204889</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.25706379480263585879</td>\n",
       "      <td>0.19129216261319942349</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 14:00:00</th>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.47923335037078829135</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52855221599246204889</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.19129216261319942349</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 16:00:00</th>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-0.34148256559675088662</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>0.07657504864786630894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70992366058212297286</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.72268683631250651977</td>\n",
       "      <td>-0.41669438868465402681</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 18:00:00</th>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-0.65542621465940897885</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>0.07657504864786630894</td>\n",
       "      <td>0.20311356023949428407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.72268683631250651977</td>\n",
       "      <td>0.77777001578047755270</td>\n",
       "      <td>-0.37177717644018937193</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 20:00:00</th>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-0.59936484874735451722</td>\n",
       "      <td>0.07657504864786630894</td>\n",
       "      <td>0.20311356023949428407</td>\n",
       "      <td>0.04774348906798944747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79859414460373490119</td>\n",
       "      <td>0.72268683631250651977</td>\n",
       "      <td>0.77777001578047755270</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>-0.32204740575379786627</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 22:00:00</th>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>0.07657504864786630894</td>\n",
       "      <td>0.20311356023949428407</td>\n",
       "      <td>0.04774348906798944747</td>\n",
       "      <td>0.15506096092474702663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72268683631250651977</td>\n",
       "      <td>0.77777001578047755270</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>1.10423861604186712704</td>\n",
       "      <td>-0.08302366920567914865</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 12:00:00</th>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>0.20311356023949428407</td>\n",
       "      <td>0.04774348906798944747</td>\n",
       "      <td>0.15506096092474702663</td>\n",
       "      <td>-0.20853704074521492440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77777001578047755270</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>1.10423861604186712704</td>\n",
       "      <td>1.19290910006347905536</td>\n",
       "      <td>-0.26429670431587648505</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 14:00:00</th>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>0.04774348906798944747</td>\n",
       "      <td>0.15506096092474702663</td>\n",
       "      <td>-0.20853704074521492440</td>\n",
       "      <td>-0.11083008877831751482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89935605826465758739</td>\n",
       "      <td>1.10423861604186712704</td>\n",
       "      <td>1.19290910006347905536</td>\n",
       "      <td>1.14252814323301765675</td>\n",
       "      <td>-0.32846415037298160033</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 16:00:00</th>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>0.15506096092474702663</td>\n",
       "      <td>-0.20853704074521492440</td>\n",
       "      <td>-0.11083008877831751482</td>\n",
       "      <td>0.57472032850676346705</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10423861604186712704</td>\n",
       "      <td>1.19290910006347905536</td>\n",
       "      <td>1.14252814323301765675</td>\n",
       "      <td>1.05049892875604156117</td>\n",
       "      <td>-0.87709581405565684165</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 18:00:00</th>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-0.20853704074521492440</td>\n",
       "      <td>-0.11083008877831751482</td>\n",
       "      <td>0.57472032850676346705</td>\n",
       "      <td>0.73329390630822410824</td>\n",
       "      <td>...</td>\n",
       "      <td>1.19290910006347905536</td>\n",
       "      <td>1.14252814323301765675</td>\n",
       "      <td>1.05049892875604156117</td>\n",
       "      <td>1.08341448721860977855</td>\n",
       "      <td>-0.81132418186622035083</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 20:00:00</th>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-0.11083008877831751482</td>\n",
       "      <td>0.57472032850676346705</td>\n",
       "      <td>0.73329390630822410824</td>\n",
       "      <td>0.55710104206444599484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14252814323301765675</td>\n",
       "      <td>1.05049892875604156117</td>\n",
       "      <td>1.08341448721860977855</td>\n",
       "      <td>1.15260433459910993648</td>\n",
       "      <td>-0.75678185273789455589</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 22:00:00</th>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "      <td>0.57472032850676346705</td>\n",
       "      <td>0.73329390630822410824</td>\n",
       "      <td>0.55710104206444599484</td>\n",
       "      <td>0.62597643445146655683</td>\n",
       "      <td>...</td>\n",
       "      <td>1.05049892875604156117</td>\n",
       "      <td>1.08341448721860977855</td>\n",
       "      <td>1.15260433459910993648</td>\n",
       "      <td>1.31785387300302314628</td>\n",
       "      <td>-0.42150694712658837160</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "      <td>-0.36536043182100569338</td>\n",
       "      <td>0.73329390630822410824</td>\n",
       "      <td>0.55710104206444599484</td>\n",
       "      <td>0.62597643445146655683</td>\n",
       "      <td>0.21592758675930659451</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08341448721860977855</td>\n",
       "      <td>1.15260433459910993648</td>\n",
       "      <td>1.31785387300302314628</td>\n",
       "      <td>1.22448116634390147262</td>\n",
       "      <td>-0.66213486980703839535</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "      <td>-0.36536043182100569338</td>\n",
       "      <td>-0.71667719893535675180</td>\n",
       "      <td>0.55710104206444599484</td>\n",
       "      <td>0.62597643445146655683</td>\n",
       "      <td>0.21592758675930659451</td>\n",
       "      <td>0.28320122580892792552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15260433459910993648</td>\n",
       "      <td>1.31785387300302314628</td>\n",
       "      <td>1.22448116634390147262</td>\n",
       "      <td>1.21440497497780919289</td>\n",
       "      <td>-0.73913580505758535999</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "      <td>-0.36536043182100569338</td>\n",
       "      <td>-0.71667719893535675180</td>\n",
       "      <td>-0.85624139411067756722</td>\n",
       "      <td>0.62597643445146655683</td>\n",
       "      <td>0.21592758675930659451</td>\n",
       "      <td>0.28320122580892792552</td>\n",
       "      <td>0.91269027718195072651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.31785387300302314628</td>\n",
       "      <td>1.22448116634390147262</td>\n",
       "      <td>1.21440497497780919289</td>\n",
       "      <td>1.15865004941876525990</td>\n",
       "      <td>-1.26691304879528887639</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "      <td>-0.36536043182100569338</td>\n",
       "      <td>-0.71667719893535675180</td>\n",
       "      <td>-0.85624139411067756722</td>\n",
       "      <td>-1.47866562077924457164</td>\n",
       "      <td>0.21592758675930659451</td>\n",
       "      <td>0.28320122580892792552</td>\n",
       "      <td>0.91269027718195072651</td>\n",
       "      <td>1.07767086824331581596</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22448116634390147262</td>\n",
       "      <td>1.21440497497780919289</td>\n",
       "      <td>1.15865004941876525990</td>\n",
       "      <td>1.19693957660991601166</td>\n",
       "      <td>-1.15782839053864461398</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "      <td>-0.36536043182100569338</td>\n",
       "      <td>-0.71667719893535675180</td>\n",
       "      <td>-0.85624139411067756722</td>\n",
       "      <td>-1.47866562077924457164</td>\n",
       "      <td>-1.22520420886041980779</td>\n",
       "      <td>0.28320122580892792552</td>\n",
       "      <td>0.91269027718195072651</td>\n",
       "      <td>1.07767086824331581596</td>\n",
       "      <td>0.93992008346927835571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.21440497497780919289</td>\n",
       "      <td>1.15865004941876525990</td>\n",
       "      <td>1.19693957660991601166</td>\n",
       "      <td>1.20903100624922665851</td>\n",
       "      <td>-1.07120233835930345201</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>-0.36536043182100569338</td>\n",
       "      <td>-0.71667719893535675180</td>\n",
       "      <td>-0.85624139411067756722</td>\n",
       "      <td>-1.47866562077924457164</td>\n",
       "      <td>-1.22520420886041980779</td>\n",
       "      <td>-1.02628512611483890815</td>\n",
       "      <td>0.91269027718195072651</td>\n",
       "      <td>1.07767086824331581596</td>\n",
       "      <td>0.93992008346927835571</td>\n",
       "      <td>0.97195514972395735676</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15865004941876525990</td>\n",
       "      <td>1.19693957660991601166</td>\n",
       "      <td>1.20903100624922665851</td>\n",
       "      <td>1.27217513881007149301</td>\n",
       "      <td>-0.53700835000242375106</td>\n",
       "      <td>-0.83859534643038335933</td>\n",
       "      <td>-0.94447163242235010472</td>\n",
       "      <td>-1.49791585459187781559</td>\n",
       "      <td>-1.32305956410087155461</td>\n",
       "      <td>-1.18349536892555073919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                               target                          \\\n",
       "feature                                   y                           \n",
       "time step                               t+1                     t+2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.08302366920567914865 -0.26429670431587648505   \n",
       "2017-11-26 12:00:00 -0.26429670431587648505 -0.32846415037298160033   \n",
       "2017-11-26 14:00:00 -0.32846415037298160033 -0.87709581405565684165   \n",
       "2017-11-26 16:00:00 -0.87709581405565684165 -0.81132418186622035083   \n",
       "2017-11-26 18:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-26 20:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-26 22:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "2017-11-27 12:00:00 -0.66213486980703839535 -0.73913580505758535999   \n",
       "2017-11-27 14:00:00 -0.73913580505758535999 -1.26691304879528887639   \n",
       "2017-11-27 16:00:00 -1.26691304879528887639 -1.15782839053864461398   \n",
       "2017-11-27 18:00:00 -1.15782839053864461398 -1.07120233835930345201   \n",
       "2017-11-27 20:00:00 -1.07120233835930345201 -0.53700835000242375106   \n",
       "2017-11-27 22:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
       "2017-11-28 12:00:00 -0.83859534643038335933 -0.94447163242235010472   \n",
       "2017-11-28 14:00:00 -0.94447163242235010472 -1.49791585459187781559   \n",
       "2017-11-28 16:00:00 -1.49791585459187781559 -1.32305956410087155461   \n",
       "2017-11-28 18:00:00 -1.32305956410087155461 -1.18349536892555073919   \n",
       "2017-11-28 20:00:00 -1.18349536892555073919 -0.36536043182100569338   \n",
       "2017-11-28 22:00:00 -0.36536043182100569338 -0.71667719893535675180   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+3                     t+4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.32846415037298160033 -0.87709581405565684165   \n",
       "2017-11-26 12:00:00 -0.87709581405565684165 -0.81132418186622035083   \n",
       "2017-11-26 14:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-26 16:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-26 18:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "2017-11-26 20:00:00 -0.66213486980703839535 -0.73913580505758535999   \n",
       "2017-11-26 22:00:00 -0.73913580505758535999 -1.26691304879528887639   \n",
       "2017-11-27 12:00:00 -1.26691304879528887639 -1.15782839053864461398   \n",
       "2017-11-27 14:00:00 -1.15782839053864461398 -1.07120233835930345201   \n",
       "2017-11-27 16:00:00 -1.07120233835930345201 -0.53700835000242375106   \n",
       "2017-11-27 18:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
       "2017-11-27 20:00:00 -0.83859534643038335933 -0.94447163242235010472   \n",
       "2017-11-27 22:00:00 -0.94447163242235010472 -1.49791585459187781559   \n",
       "2017-11-28 12:00:00 -1.49791585459187781559 -1.32305956410087155461   \n",
       "2017-11-28 14:00:00 -1.32305956410087155461 -1.18349536892555073919   \n",
       "2017-11-28 16:00:00 -1.18349536892555073919 -0.36536043182100569338   \n",
       "2017-11-28 18:00:00 -0.36536043182100569338 -0.71667719893535675180   \n",
       "2017-11-28 20:00:00 -0.71667719893535675180 -0.85624139411067756722   \n",
       "2017-11-28 22:00:00 -0.85624139411067756722 -1.47866562077924457164   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+5                     t+6   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-26 12:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-26 14:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "2017-11-26 16:00:00 -0.66213486980703839535 -0.73913580505758535999   \n",
       "2017-11-26 18:00:00 -0.73913580505758535999 -1.26691304879528887639   \n",
       "2017-11-26 20:00:00 -1.26691304879528887639 -1.15782839053864461398   \n",
       "2017-11-26 22:00:00 -1.15782839053864461398 -1.07120233835930345201   \n",
       "2017-11-27 12:00:00 -1.07120233835930345201 -0.53700835000242375106   \n",
       "2017-11-27 14:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
       "2017-11-27 16:00:00 -0.83859534643038335933 -0.94447163242235010472   \n",
       "2017-11-27 18:00:00 -0.94447163242235010472 -1.49791585459187781559   \n",
       "2017-11-27 20:00:00 -1.49791585459187781559 -1.32305956410087155461   \n",
       "2017-11-27 22:00:00 -1.32305956410087155461 -1.18349536892555073919   \n",
       "2017-11-28 12:00:00 -1.18349536892555073919 -0.36536043182100569338   \n",
       "2017-11-28 14:00:00 -0.36536043182100569338 -0.71667719893535675180   \n",
       "2017-11-28 16:00:00 -0.71667719893535675180 -0.85624139411067756722   \n",
       "2017-11-28 18:00:00 -0.85624139411067756722 -1.47866562077924457164   \n",
       "2017-11-28 20:00:00 -1.47866562077924457164 -1.22520420886041980779   \n",
       "2017-11-28 22:00:00 -1.22520420886041980779 -1.02628512611483890815   \n",
       "\n",
       "tensor                                    X                          \\\n",
       "feature                               Del_n                           \n",
       "time step                               t-5                     t-4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -0.46962283052577807885 -0.39273867158629655050   \n",
       "2017-11-26 12:00:00 -0.39273867158629655050 -0.47923335037078829135   \n",
       "2017-11-26 14:00:00 -0.47923335037078829135 -0.34148256559675088662   \n",
       "2017-11-26 16:00:00 -0.34148256559675088662 -0.65542621465940897885   \n",
       "2017-11-26 18:00:00 -0.65542621465940897885 -0.59936484874735451722   \n",
       "2017-11-26 20:00:00 -0.59936484874735451722  0.07657504864786630894   \n",
       "2017-11-26 22:00:00  0.07657504864786630894  0.20311356023949428407   \n",
       "2017-11-27 12:00:00  0.20311356023949428407  0.04774348906798944747   \n",
       "2017-11-27 14:00:00  0.04774348906798944747  0.15506096092474702663   \n",
       "2017-11-27 16:00:00  0.15506096092474702663 -0.20853704074521492440   \n",
       "2017-11-27 18:00:00 -0.20853704074521492440 -0.11083008877831751482   \n",
       "2017-11-27 20:00:00 -0.11083008877831751482  0.57472032850676346705   \n",
       "2017-11-27 22:00:00  0.57472032850676346705  0.73329390630822410824   \n",
       "2017-11-28 12:00:00  0.73329390630822410824  0.55710104206444599484   \n",
       "2017-11-28 14:00:00  0.55710104206444599484  0.62597643445146655683   \n",
       "2017-11-28 16:00:00  0.62597643445146655683  0.21592758675930659451   \n",
       "2017-11-28 18:00:00  0.21592758675930659451  0.28320122580892792552   \n",
       "2017-11-28 20:00:00  0.28320122580892792552  0.91269027718195072651   \n",
       "2017-11-28 22:00:00  0.91269027718195072651  1.07767086824331581596   \n",
       "\n",
       "tensor                                                               ...  \\\n",
       "feature                                                              ...   \n",
       "time step                               t-3                     t-2  ...   \n",
       "Epoch_Time_of_Clock                                                  ...   \n",
       "2017-11-25 22:00:00 -0.47923335037078829135 -0.34148256559675088662  ...   \n",
       "2017-11-26 12:00:00 -0.34148256559675088662 -0.65542621465940897885  ...   \n",
       "2017-11-26 14:00:00 -0.65542621465940897885 -0.59936484874735451722  ...   \n",
       "2017-11-26 16:00:00 -0.59936484874735451722  0.07657504864786630894  ...   \n",
       "2017-11-26 18:00:00  0.07657504864786630894  0.20311356023949428407  ...   \n",
       "2017-11-26 20:00:00  0.20311356023949428407  0.04774348906798944747  ...   \n",
       "2017-11-26 22:00:00  0.04774348906798944747  0.15506096092474702663  ...   \n",
       "2017-11-27 12:00:00  0.15506096092474702663 -0.20853704074521492440  ...   \n",
       "2017-11-27 14:00:00 -0.20853704074521492440 -0.11083008877831751482  ...   \n",
       "2017-11-27 16:00:00 -0.11083008877831751482  0.57472032850676346705  ...   \n",
       "2017-11-27 18:00:00  0.57472032850676346705  0.73329390630822410824  ...   \n",
       "2017-11-27 20:00:00  0.73329390630822410824  0.55710104206444599484  ...   \n",
       "2017-11-27 22:00:00  0.55710104206444599484  0.62597643445146655683  ...   \n",
       "2017-11-28 12:00:00  0.62597643445146655683  0.21592758675930659451  ...   \n",
       "2017-11-28 14:00:00  0.21592758675930659451  0.28320122580892792552  ...   \n",
       "2017-11-28 16:00:00  0.28320122580892792552  0.91269027718195072651  ...   \n",
       "2017-11-28 18:00:00  0.91269027718195072651  1.07767086824331581596  ...   \n",
       "2017-11-28 20:00:00  1.07767086824331581596  0.93992008346927835571  ...   \n",
       "2017-11-28 22:00:00  0.93992008346927835571  0.97195514972395735676  ...   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                Crc                          \n",
       "time step                              t-3                    t-2   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-25 22:00:00 0.27463219356693691076 0.37337886895464111880   \n",
       "2017-11-26 12:00:00 0.37337886895464111880 0.52855221599246204889   \n",
       "2017-11-26 14:00:00 0.52855221599246204889 0.70992366058212297286   \n",
       "2017-11-26 16:00:00 0.70992366058212297286 0.89935605826465758739   \n",
       "2017-11-26 18:00:00 0.89935605826465758739 0.79859414460373490119   \n",
       "2017-11-26 20:00:00 0.79859414460373490119 0.72268683631250651977   \n",
       "2017-11-26 22:00:00 0.72268683631250651977 0.77777001578047755270   \n",
       "2017-11-27 12:00:00 0.77777001578047755270 0.89935605826465758739   \n",
       "2017-11-27 14:00:00 0.89935605826465758739 1.10423861604186712704   \n",
       "2017-11-27 16:00:00 1.10423861604186712704 1.19290910006347905536   \n",
       "2017-11-27 18:00:00 1.19290910006347905536 1.14252814323301765675   \n",
       "2017-11-27 20:00:00 1.14252814323301765675 1.05049892875604156117   \n",
       "2017-11-27 22:00:00 1.05049892875604156117 1.08341448721860977855   \n",
       "2017-11-28 12:00:00 1.08341448721860977855 1.15260433459910993648   \n",
       "2017-11-28 14:00:00 1.15260433459910993648 1.31785387300302314628   \n",
       "2017-11-28 16:00:00 1.31785387300302314628 1.22448116634390147262   \n",
       "2017-11-28 18:00:00 1.22448116634390147262 1.21440497497780919289   \n",
       "2017-11-28 20:00:00 1.21440497497780919289 1.15865004941876525990   \n",
       "2017-11-28 22:00:00 1.15865004941876525990 1.19693957660991601166   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-1                      t   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-25 22:00:00 0.52855221599246204889 0.70992366058212297286   \n",
       "2017-11-26 12:00:00 0.70992366058212297286 0.89935605826465758739   \n",
       "2017-11-26 14:00:00 0.89935605826465758739 0.79859414460373490119   \n",
       "2017-11-26 16:00:00 0.79859414460373490119 0.72268683631250651977   \n",
       "2017-11-26 18:00:00 0.72268683631250651977 0.77777001578047755270   \n",
       "2017-11-26 20:00:00 0.77777001578047755270 0.89935605826465758739   \n",
       "2017-11-26 22:00:00 0.89935605826465758739 1.10423861604186712704   \n",
       "2017-11-27 12:00:00 1.10423861604186712704 1.19290910006347905536   \n",
       "2017-11-27 14:00:00 1.19290910006347905536 1.14252814323301765675   \n",
       "2017-11-27 16:00:00 1.14252814323301765675 1.05049892875604156117   \n",
       "2017-11-27 18:00:00 1.05049892875604156117 1.08341448721860977855   \n",
       "2017-11-27 20:00:00 1.08341448721860977855 1.15260433459910993648   \n",
       "2017-11-27 22:00:00 1.15260433459910993648 1.31785387300302314628   \n",
       "2017-11-28 12:00:00 1.31785387300302314628 1.22448116634390147262   \n",
       "2017-11-28 14:00:00 1.22448116634390147262 1.21440497497780919289   \n",
       "2017-11-28 16:00:00 1.21440497497780919289 1.15865004941876525990   \n",
       "2017-11-28 18:00:00 1.15865004941876525990 1.19693957660991601166   \n",
       "2017-11-28 20:00:00 1.19693957660991601166 1.20903100624922665851   \n",
       "2017-11-28 22:00:00 1.20903100624922665851 1.27217513881007149301   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                           OMEGA_dot                           \n",
       "time step                               t-5                     t-4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.38860705922644167565  0.25706379480263585879   \n",
       "2017-11-26 12:00:00  0.25706379480263585879  0.19129216261319942349   \n",
       "2017-11-26 14:00:00  0.19129216261319942349 -0.41669438868465402681   \n",
       "2017-11-26 16:00:00 -0.41669438868465402681 -0.37177717644018937193   \n",
       "2017-11-26 18:00:00 -0.37177717644018937193 -0.32204740575379786627   \n",
       "2017-11-26 20:00:00 -0.32204740575379786627 -0.08302366920567914865   \n",
       "2017-11-26 22:00:00 -0.08302366920567914865 -0.26429670431587648505   \n",
       "2017-11-27 12:00:00 -0.26429670431587648505 -0.32846415037298160033   \n",
       "2017-11-27 14:00:00 -0.32846415037298160033 -0.87709581405565684165   \n",
       "2017-11-27 16:00:00 -0.87709581405565684165 -0.81132418186622035083   \n",
       "2017-11-27 18:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-27 20:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-27 22:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "2017-11-28 12:00:00 -0.66213486980703839535 -0.73913580505758535999   \n",
       "2017-11-28 14:00:00 -0.73913580505758535999 -1.26691304879528887639   \n",
       "2017-11-28 16:00:00 -1.26691304879528887639 -1.15782839053864461398   \n",
       "2017-11-28 18:00:00 -1.15782839053864461398 -1.07120233835930345201   \n",
       "2017-11-28 20:00:00 -1.07120233835930345201 -0.53700835000242375106   \n",
       "2017-11-28 22:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t-3                     t-2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.19129216261319942349 -0.41669438868465402681   \n",
       "2017-11-26 12:00:00 -0.41669438868465402681 -0.37177717644018937193   \n",
       "2017-11-26 14:00:00 -0.37177717644018937193 -0.32204740575379786627   \n",
       "2017-11-26 16:00:00 -0.32204740575379786627 -0.08302366920567914865   \n",
       "2017-11-26 18:00:00 -0.08302366920567914865 -0.26429670431587648505   \n",
       "2017-11-26 20:00:00 -0.26429670431587648505 -0.32846415037298160033   \n",
       "2017-11-26 22:00:00 -0.32846415037298160033 -0.87709581405565684165   \n",
       "2017-11-27 12:00:00 -0.87709581405565684165 -0.81132418186622035083   \n",
       "2017-11-27 14:00:00 -0.81132418186622035083 -0.75678185273789455589   \n",
       "2017-11-27 16:00:00 -0.75678185273789455589 -0.42150694712658837160   \n",
       "2017-11-27 18:00:00 -0.42150694712658837160 -0.66213486980703839535   \n",
       "2017-11-27 20:00:00 -0.66213486980703839535 -0.73913580505758535999   \n",
       "2017-11-27 22:00:00 -0.73913580505758535999 -1.26691304879528887639   \n",
       "2017-11-28 12:00:00 -1.26691304879528887639 -1.15782839053864461398   \n",
       "2017-11-28 14:00:00 -1.15782839053864461398 -1.07120233835930345201   \n",
       "2017-11-28 16:00:00 -1.07120233835930345201 -0.53700835000242375106   \n",
       "2017-11-28 18:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
       "2017-11-28 20:00:00 -0.83859534643038335933 -0.94447163242235010472   \n",
       "2017-11-28 22:00:00 -0.94447163242235010472 -1.49791585459187781559   \n",
       "\n",
       "tensor                                                               \n",
       "feature                                                              \n",
       "time step                               t-1                       t  \n",
       "Epoch_Time_of_Clock                                                  \n",
       "2017-11-25 22:00:00 -0.37177717644018937193 -0.32204740575379786627  \n",
       "2017-11-26 12:00:00 -0.32204740575379786627 -0.08302366920567914865  \n",
       "2017-11-26 14:00:00 -0.08302366920567914865 -0.26429670431587648505  \n",
       "2017-11-26 16:00:00 -0.26429670431587648505 -0.32846415037298160033  \n",
       "2017-11-26 18:00:00 -0.32846415037298160033 -0.87709581405565684165  \n",
       "2017-11-26 20:00:00 -0.87709581405565684165 -0.81132418186622035083  \n",
       "2017-11-26 22:00:00 -0.81132418186622035083 -0.75678185273789455589  \n",
       "2017-11-27 12:00:00 -0.75678185273789455589 -0.42150694712658837160  \n",
       "2017-11-27 14:00:00 -0.42150694712658837160 -0.66213486980703839535  \n",
       "2017-11-27 16:00:00 -0.66213486980703839535 -0.73913580505758535999  \n",
       "2017-11-27 18:00:00 -0.73913580505758535999 -1.26691304879528887639  \n",
       "2017-11-27 20:00:00 -1.26691304879528887639 -1.15782839053864461398  \n",
       "2017-11-27 22:00:00 -1.15782839053864461398 -1.07120233835930345201  \n",
       "2017-11-28 12:00:00 -1.07120233835930345201 -0.53700835000242375106  \n",
       "2017-11-28 14:00:00 -0.53700835000242375106 -0.83859534643038335933  \n",
       "2017-11-28 16:00:00 -0.83859534643038335933 -0.94447163242235010472  \n",
       "2017-11-28 18:00:00 -0.94447163242235010472 -1.49791585459187781559  \n",
       "2017-11-28 20:00:00 -1.49791585459187781559 -1.32305956410087155461  \n",
       "2017-11-28 22:00:00 -1.32305956410087155461 -1.18349536892555073919  \n",
       "\n",
       "[19 rows x 36 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.dataframe.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 36)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.031763002, -0.11710991 , -0.41730446 , -0.90459347 ,\n",
       "        -0.89281183 , -0.643763   ],\n",
       "       [-0.1386549  , -0.39251626 , -0.8045937  , -0.96378136 ,\n",
       "        -0.7410399  , -0.42014718 ],\n",
       "       [-0.379624   , -0.7069001  , -0.9379312  , -0.8277328  ,\n",
       "        -0.55334586 , -0.43418175 ],\n",
       "       [-0.77925736 , -0.83077675 , -0.6939968  , -0.49308133 ,\n",
       "        -0.54321027 , -0.7256571  ],\n",
       "       [-0.7283374  , -0.64207065 , -0.5820385  , -0.63402206 ,\n",
       "        -0.8250493  , -1.0427042  ],\n",
       "       [-0.5757264  , -0.5188341  , -0.6691359  , -0.9497264  ,\n",
       "        -1.0945901  , -0.89411485 ],\n",
       "       [-0.33366954 , -0.4657858  , -0.7953437  , -1.2154564  ,\n",
       "        -1.1358901  , -0.8334595  ],\n",
       "       [-0.4450696  , -0.7323377  , -1.1320943  , -1.2263902  ,\n",
       "        -0.94344866 , -0.576315   ],\n",
       "       [-0.6656056  , -0.99445045 , -1.1989169  , -1.0368716  ,\n",
       "        -0.7083173  , -0.60363376 ],\n",
       "       [-1.0208727  , -1.089477   , -0.9370807  , -0.6709142  ,\n",
       "        -0.6779554  , -0.8317019  ],\n",
       "       [-0.9513687  , -0.8770848  , -0.7890003  , -0.7774279  ,\n",
       "        -0.8885752  , -1.0702335  ],\n",
       "       [-0.74774086 , -0.7316944  , -0.8723961  , -1.0714904  ,\n",
       "        -1.1064405  , -0.8821538  ],\n",
       "       [-0.479178   , -0.6612403  , -1.0016208  , -1.3288335  ,\n",
       "        -1.1665012  , -0.80646676 ],\n",
       "       [-0.56973064 , -0.90676385 , -1.3016397  , -1.2761902  ,\n",
       "        -0.9194031  , -0.5279775  ],\n",
       "       [-0.7821952  , -1.1553111  , -1.280295   , -1.01051    ,\n",
       "        -0.60598254 , -0.59946007 ],\n",
       "       [-1.1184679  , -1.1970712  , -0.9726893  , -0.5751082  ,\n",
       "        -0.59466803 , -0.7200606  ],\n",
       "       [-1.0410472  , -0.94188076 , -0.73986006 , -0.6151656  ,\n",
       "        -0.6795636  , -0.88698655 ],\n",
       "       [-0.7486103  , -0.7179251  , -0.82153416 , -0.94453025 ,\n",
       "        -0.9075494  , -0.6611469  ],\n",
       "       [-0.3903802  , -0.60097617 , -0.9670547  , -1.2216293  ,\n",
       "        -0.9747424  , -0.5217734  ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp    h              prediction                  actual\n",
      "0 2017-11-25 22:00:00  t+1 -0.00000000801892176551 -0.00000000803033449566\n",
      "1 2017-11-26 12:00:00  t+1 -0.00000000804272029343 -0.00000000807069331963\n",
      "2 2017-11-26 14:00:00  t+1 -0.00000000809636991511 -0.00000000808497962900\n",
      "3 2017-11-26 16:00:00  t+1 -0.00000000818534471456 -0.00000000820712757409\n",
      "4 2017-11-26 18:00:00  t+1 -0.00000000817400784199 -0.00000000819248410699\n",
      "              timestamp    h              prediction                  actual\n",
      "109 2017-11-28 14:00:00  t+6 -0.00000000814531445168 -0.00000000817141180067\n",
      "110 2017-11-28 16:00:00  t+6 -0.00000000817216508182 -0.00000000820248452355\n",
      "111 2017-11-28 18:00:00  t+6 -0.00000000820932965902 -0.00000000834106172442\n",
      "112 2017-11-28 20:00:00  t+6 -0.00000000815904847042 -0.00000000828463080241\n",
      "113 2017-11-28 22:00:00  t+6 -0.00000000812801820828 -0.00000000824034324337\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "eval_df = create_evaluation_df(predictions, test_inputs, HORIZON, y_scalar)\n",
    "print(eval_df.head())\n",
    "print(eval_df.tail())\n",
    "print(eval_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h\n",
       "t+1   -0.00477433784738212977\n",
       "t+2   -0.00419670884946418948\n",
       "t+3   -0.00324340309959317676\n",
       "t+4   -0.00296960326945073377\n",
       "t+5   -0.00471258651572456413\n",
       "t+6   -0.00679278727001576040\n",
       "Name: APE, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']\n",
    "eval_df.groupby('h')['APE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.662188585405348e-11"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(eval_df['prediction'], eval_df['actual'])\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "a = mean_absolute_error(eval_df['prediction'], eval_df['actual'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot actuals vs predictions at each horizon for first week of the test period. As is to be expected, predictions for one step ahead (*t+1*) are more accurate than those for 2 or 3 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]\n",
    "for t in range(1, HORIZON+1):\n",
    "    plot_df['t+'+str(t)] = eval_df[ (eval_df.h=='t+'+str(t))]['prediction'].values\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+1'], color='blue', linewidth=4.0, alpha=0.75)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+2'], color='blue', linewidth=3.0, alpha=0.5)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+3'], color='blue', linewidth=2.0, alpha=0.25)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>0.00000000468162357984</td>\n",
       "      <td>0.00000496394932270000</td>\n",
       "      <td>5,153.67251396000028762501</td>\n",
       "      <td>288.25000000000000000000</td>\n",
       "      <td>-0.00000000813141013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>0.00000000471841082646</td>\n",
       "      <td>0.00000500492751598000</td>\n",
       "      <td>5,153.67150496999965980649</td>\n",
       "      <td>287.78125000000000000000</td>\n",
       "      <td>-0.00000000819855578847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>0.00000000468769526132</td>\n",
       "      <td>0.00000502541661263000</td>\n",
       "      <td>5,153.67233276000024488894</td>\n",
       "      <td>285.18750000000000000000</td>\n",
       "      <td>-0.00000000822212819893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>0.00000000469483841601</td>\n",
       "      <td>0.00000506825745106000</td>\n",
       "      <td>5,153.67309189000025071437</td>\n",
       "      <td>286.96875000000000000000</td>\n",
       "      <td>-0.00000000834534761723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>0.00000000459626288137</td>\n",
       "      <td>0.00000505149364471000</td>\n",
       "      <td>5,153.67578505999972549034</td>\n",
       "      <td>287.53125000000000000000</td>\n",
       "      <td>-0.00000000830641742420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>0.00000000458697678028</td>\n",
       "      <td>0.00000484287738800000</td>\n",
       "      <td>5,153.67449759999999514548</td>\n",
       "      <td>290.46875000000000000000</td>\n",
       "      <td>-0.00000000827534470132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-28 12:00:00 0.00000000468162357984 0.00000496394932270000   \n",
       "2017-11-28 14:00:00 0.00000000471841082646 0.00000500492751598000   \n",
       "2017-11-28 16:00:00 0.00000000468769526132 0.00000502541661263000   \n",
       "2017-11-28 18:00:00 0.00000000469483841601 0.00000506825745106000   \n",
       "2017-11-28 20:00:00 0.00000000459626288137 0.00000505149364471000   \n",
       "2017-11-28 22:00:00 0.00000000458697678028 0.00000484287738800000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-28 12:00:00 5,153.67251396000028762501 288.25000000000000000000   \n",
       "2017-11-28 14:00:00 5,153.67150496999965980649 287.78125000000000000000   \n",
       "2017-11-28 16:00:00 5,153.67233276000024488894 285.18750000000000000000   \n",
       "2017-11-28 18:00:00 5,153.67309189000025071437 286.96875000000000000000   \n",
       "2017-11-28 20:00:00 5,153.67578505999972549034 287.53125000000000000000   \n",
       "2017-11-28 22:00:00 5,153.67449759999999514548 290.46875000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-28 12:00:00 -0.00000000813141013444  \n",
       "2017-11-28 14:00:00 -0.00000000819855578847  \n",
       "2017-11-28 16:00:00 -0.00000000822212819893  \n",
       "2017-11-28 18:00:00 -0.00000000834534761723  \n",
       "2017-11-28 20:00:00 -0.00000000830641742420  \n",
       "2017-11-28 22:00:00 -0.00000000827534470132  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.iloc[156:162  , :]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key , value in enumerate(columns):\n",
    "    new_df[value] = a[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna( how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>0.00000000468162357984</td>\n",
       "      <td>0.00000496394932270000</td>\n",
       "      <td>5,153.67251396000028762501</td>\n",
       "      <td>288.25000000000000000000</td>\n",
       "      <td>-0.00000000813141013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>0.00000000471841082646</td>\n",
       "      <td>0.00000500492751598000</td>\n",
       "      <td>5,153.67150496999965980649</td>\n",
       "      <td>287.78125000000000000000</td>\n",
       "      <td>-0.00000000819855578847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>0.00000000468769526132</td>\n",
       "      <td>0.00000502541661263000</td>\n",
       "      <td>5,153.67233276000024488894</td>\n",
       "      <td>285.18750000000000000000</td>\n",
       "      <td>-0.00000000822212819893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>0.00000000469483841601</td>\n",
       "      <td>0.00000506825745106000</td>\n",
       "      <td>5,153.67309189000025071437</td>\n",
       "      <td>286.96875000000000000000</td>\n",
       "      <td>-0.00000000834534761723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>0.00000000459626288137</td>\n",
       "      <td>0.00000505149364471000</td>\n",
       "      <td>5,153.67578505999972549034</td>\n",
       "      <td>287.53125000000000000000</td>\n",
       "      <td>-0.00000000830641742420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>0.00000000458697678028</td>\n",
       "      <td>0.00000484287738800000</td>\n",
       "      <td>5,153.67449759999999514548</td>\n",
       "      <td>290.46875000000000000000</td>\n",
       "      <td>-0.00000000827534470132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-28 12:00:00 0.00000000468162357984 0.00000496394932270000   \n",
       "2017-11-28 14:00:00 0.00000000471841082646 0.00000500492751598000   \n",
       "2017-11-28 16:00:00 0.00000000468769526132 0.00000502541661263000   \n",
       "2017-11-28 18:00:00 0.00000000469483841601 0.00000506825745106000   \n",
       "2017-11-28 20:00:00 0.00000000459626288137 0.00000505149364471000   \n",
       "2017-11-28 22:00:00 0.00000000458697678028 0.00000484287738800000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-28 12:00:00 5,153.67251396000028762501 288.25000000000000000000   \n",
       "2017-11-28 14:00:00 5,153.67150496999965980649 287.78125000000000000000   \n",
       "2017-11-28 16:00:00 5,153.67233276000024488894 285.18750000000000000000   \n",
       "2017-11-28 18:00:00 5,153.67309189000025071437 286.96875000000000000000   \n",
       "2017-11-28 20:00:00 5,153.67578505999972549034 287.53125000000000000000   \n",
       "2017-11-28 22:00:00 5,153.67449759999999514548 290.46875000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-28 12:00:00 -0.00000000813141013444  \n",
       "2017-11-28 14:00:00 -0.00000000819855578847  \n",
       "2017-11-28 16:00:00 -0.00000000822212819893  \n",
       "2017-11-28 18:00:00 -0.00000000834534761723  \n",
       "2017-11-28 20:00:00 -0.00000000830641742420  \n",
       "2017-11-28 22:00:00 -0.00000000827534470132  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 11, 29)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating index for output\n",
    "import datetime\n",
    "date = new_df.index.date[0]\n",
    "date + datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = new_df.index + datetime.timedelta(days =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-11-29 12:00:00', '2017-11-29 14:00:00',\n",
       "               '2017-11-29 16:00:00', '2017-11-29 18:00:00',\n",
       "               '2017-11-29 20:00:00', '2017-11-29 22:00:00'],\n",
       "              dtype='datetime64[ns]', name='Epoch_Time_of_Clock', freq='2H')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.index= date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'], dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Del_n                    Cus  \\\n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 12:00:00 0.00000000468162357984 0.00000496394932270000   \n",
      "2017-11-29 14:00:00 0.00000000471841082646 0.00000500492751598000   \n",
      "2017-11-29 16:00:00 0.00000000468769526132 0.00000502541661263000   \n",
      "2017-11-29 18:00:00 0.00000000469483841601 0.00000506825745106000   \n",
      "2017-11-29 20:00:00 0.00000000459626288137 0.00000505149364471000   \n",
      "2017-11-29 22:00:00 0.00000000458697678028 0.00000484287738800000   \n",
      "\n",
      "                                        sqrt_A                      Crc  \\\n",
      "Epoch_Time_of_Clock                                                       \n",
      "2017-11-29 12:00:00 5,153.67251396000028762501 288.25000000000000000000   \n",
      "2017-11-29 14:00:00 5,153.67150496999965980649 287.78125000000000000000   \n",
      "2017-11-29 16:00:00 5,153.67233276000024488894 285.18750000000000000000   \n",
      "2017-11-29 18:00:00 5,153.67309189000025071437 286.96875000000000000000   \n",
      "2017-11-29 20:00:00 5,153.67578505999972549034 287.53125000000000000000   \n",
      "2017-11-29 22:00:00 5,153.67449759999999514548 290.46875000000000000000   \n",
      "\n",
      "                                  OMEGA_dot  \n",
      "Epoch_Time_of_Clock                          \n",
      "2017-11-29 12:00:00 -0.00000000813141013444  \n",
      "2017-11-29 14:00:00 -0.00000000819855578847  \n",
      "2017-11-29 16:00:00 -0.00000000822212819893  \n",
      "2017-11-29 18:00:00 -0.00000000834534761723  \n",
      "2017-11-29 20:00:00 -0.00000000830641742420  \n",
      "2017-11-29 22:00:00 -0.00000000827534470132  \n",
      "Index(['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(new_df)\n",
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Del_n                     Cus  \\\n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 12:00:00 0.91269027718195072651 -1.22312509319444773226   \n",
      "2017-11-29 14:00:00 1.07767086824331581596 -1.20617816297157554040   \n",
      "2017-11-29 16:00:00 0.93992008346927835571 -1.19770469785600397472   \n",
      "2017-11-29 18:00:00 0.97195514972395735676 -1.17998745262262549893   \n",
      "2017-11-29 20:00:00 0.52987123577711836564 -1.18692028771718405267   \n",
      "\n",
      "                                     sqrt_A                    Crc  \\\n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 12:00:00 -0.90370805607990212227 1.22448116634390147262   \n",
      "2017-11-29 14:00:00 -1.14731878453497881942 1.21440497497780919289   \n",
      "2017-11-29 16:00:00 -0.94745701690112382742 1.15865004941876525990   \n",
      "2017-11-29 18:00:00 -0.76417253223977721355 1.19693957660991601166   \n",
      "2017-11-29 20:00:00 -0.11393307989914304434 1.20903100624922665851   \n",
      "\n",
      "                                  OMEGA_dot  \n",
      "Epoch_Time_of_Clock                          \n",
      "2017-11-29 12:00:00 -0.53700835000242375106  \n",
      "2017-11-29 14:00:00 -0.83859534643038335933  \n",
      "2017-11-29 16:00:00 -0.94447163242235010472  \n",
      "2017-11-29 18:00:00 -1.49791585459187781559  \n",
      "2017-11-29 20:00:00 -1.32305956410087155461  \n"
     ]
    }
   ],
   "source": [
    "freq = None\n",
    "idx_tuples = []\n",
    "drop_incomplete  = True\n",
    "new_df[['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']] = X_scaler.transform(new_df)\n",
    "new_new_df = new_df.copy()\n",
    "tensor_structure={'X':(range(-T+1, 1), ['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'])}\n",
    "for name, structure in tensor_structure.items():\n",
    "        rng = structure[0]\n",
    "        dataset_cols = structure[1]\n",
    "        for col in dataset_cols:\n",
    "        # do not shift non-sequential 'static' features\n",
    "            if rng is None:\n",
    "                new_df['context_'+col] = new_df[col]\n",
    "                idx_tuples.append((name, col, 'static'))\n",
    "            else:\n",
    "                for t in rng:\n",
    "                    sign = '+' if t > 0 else ''\n",
    "                    shift = str(t) if t != 0 else ''\n",
    "                    period = 't'+sign+shift\n",
    "                    shifted_col = name+'_'+col+'_'+ period\n",
    "                    new_new_df[shifted_col] = new_new_df[col].shift(t*-1, freq=freq)\n",
    "                    idx_tuples.append((name, col, period))\n",
    "        new_new_df = new_new_df.drop(new_df.columns, axis=1)\n",
    "        idx = pd.MultiIndex.from_tuples(idx_tuples, names=['tensor', 'feature', 'time step'])\n",
    "        print(new_df.head())\n",
    "        new_new_df.columns = idx\n",
    "        if drop_incomplete:\n",
    "            new_new_df = new_new_df.dropna(how='any')\n",
    "            \n",
    "inputs = {}           \n",
    "for name, structure in tensor_structure.items():\n",
    "    rng = structure[0]\n",
    "    cols = structure[1]\n",
    "    tensor = new_new_df[name][cols].as_matrix()\n",
    "    if rng is None:\n",
    "        tensor = tensor.reshape(tensor.shape[0], len(cols))\n",
    "    else:\n",
    "        tensor = tensor.reshape(tensor.shape[0], len(cols), len(rng))\n",
    "        tensor = np.transpose(tensor, axes=[0, 2, 1])\n",
    "    inputs[name] = tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor                                   X                         \\\n",
      "feature                              Del_n                          \n",
      "time step                              t-5                    t-4   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 0.91269027718195072651 1.07767086824331581596   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                              t-3                    t-2   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 0.93992008346927835571 0.97195514972395735676   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                              t-1                      t   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 0.52987123577711836564 0.48822564967742920761   \n",
      "\n",
      "tensor                                                               \\\n",
      "feature                                 Cus                           \n",
      "time step                               t-5                     t-4   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -1.22312509319444773226 -1.20617816297157554040   \n",
      "\n",
      "tensor                                                               ...  \\\n",
      "feature                                                              ...   \n",
      "time step                               t-3                     t-2  ...   \n",
      "Epoch_Time_of_Clock                                                  ...   \n",
      "2017-11-29 22:00:00 -1.19770469785600397472 -1.17998745262262549893  ...   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                Crc                          \n",
      "time step                              t-3                    t-2   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 1.15865004941876525990 1.19693957660991601166   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                              t-1                      t   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 1.20903100624922665851 1.27217513881007149301   \n",
      "\n",
      "tensor                                                               \\\n",
      "feature                           OMEGA_dot                           \n",
      "time step                               t-5                     t-4   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
      "\n",
      "tensor                                                               \\\n",
      "feature                                                               \n",
      "time step                               t-3                     t-2   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -0.94447163242235010472 -1.49791585459187781559   \n",
      "\n",
      "tensor                                                               \n",
      "feature                                                              \n",
      "time step                               t-1                       t  \n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 22:00:00 -1.32305956410087155461 -1.18349536892555073919  \n",
      "\n",
      "[1 rows x 30 columns]\n",
      "[[[ 0.9126902771819507  -1.2231250931944477  -0.9037080560799021\n",
      "    1.2244811663439015  -0.5370083500024238 ]\n",
      "  [ 1.0776708682433158  -1.2061781629715755  -1.1473187845349788\n",
      "    1.2144049749778092  -0.8385953464303834 ]\n",
      "  [ 0.9399200834692784  -1.197704697856004   -0.9474570169011238\n",
      "    1.1586500494187653  -0.9444716324223501 ]\n",
      "  [ 0.9719551497239574  -1.1799874526226255  -0.7641725322397772\n",
      "    1.196939576609916   -1.4979158545918778 ]\n",
      "  [ 0.5298712357771184  -1.186920287717184   -0.11393307989914304\n",
      "    1.2090310062492267  -1.3230595641008716 ]\n",
      "  [ 0.4882256496774292  -1.273195568856693   -0.42477765536166323\n",
      "    1.2721751388100715  -1.1834953689255507 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(new_new_df)\n",
    "print(inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3903802 , -0.60097617, -0.9670547 , -1.2216293 , -0.9747424 ,\n",
       "        -0.5217734 ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictions[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3903802 , -0.60097617, -0.9670547 , -1.2216293 , -0.9747424 ,\n",
       "       -0.5217734 ], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.39038020372390747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.60097616910934448242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.96705472469329833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.22162926197052001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.97474241256713867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.52177339792251586914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                OMEGA_dot\n",
       "0 -0.39038020372390747070\n",
       "1 -0.60097616910934448242\n",
       "2 -0.96705472469329833984\n",
       "3 -1.22162926197052001953\n",
       "4 -0.97474241256713867188\n",
       "5 -0.52177339792251586914"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results , columns = [var_name])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>-0.39038020372390747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>-0.60097616910934448242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>-0.96705472469329833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>-1.22162926197052001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>-0.97474241256713867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>-0.52177339792251586914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OMEGA_dot\n",
       "Epoch_Time_of_Clock                        \n",
       "2017-11-29 12:00:00 -0.39038020372390747070\n",
       "2017-11-29 14:00:00 -0.60097616910934448242\n",
       "2017-11-29 16:00:00 -0.96705472469329833984\n",
       "2017-11-29 18:00:00 -1.22162926197052001953\n",
       "2017-11-29 20:00:00 -0.97474241256713867188\n",
       "2017-11-29 22:00:00 -0.52177339792251586914"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.index = date\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[var_name] = y_scalar.inverse_transform(res_df[[var_name]])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final generated output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>-0.00000000809876432584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>-0.00000000814565215279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>-0.00000000822715584547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>-0.00000000828383495133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>-0.00000000822886736529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>-0.00000000812801825845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OMEGA_dot\n",
       "Epoch_Time_of_Clock                        \n",
       "2017-11-29 12:00:00 -0.00000000809876432584\n",
       "2017-11-29 14:00:00 -0.00000000814565215279\n",
       "2017-11-29 16:00:00 -0.00000000822715584547\n",
       "2017-11-29 18:00:00 -0.00000000828383495133\n",
       "2017-11-29 20:00:00 -0.00000000822886736529\n",
       "2017-11-29 22:00:00 -0.00000000812801825845"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final generated ouput\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('SA1_OMEGA_dot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
