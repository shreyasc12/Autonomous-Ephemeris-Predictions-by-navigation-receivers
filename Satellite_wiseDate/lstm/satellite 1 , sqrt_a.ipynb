{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi step model (simple encoder-decoder)\n",
    "\n",
    "In this notebook, we demonstrate how to:\n",
    "- prepare time series data for training a RNN forecasting model\n",
    "- get data in the required shape for the keras API\n",
    "- implement a RNN model in keras to predict the next 3 steps ahead (time *t+1* to *t+3*) in the time series. This model uses a simple encoder decoder approach in which the final hidden state of the encoder is replicated across each time step of the decoder. \n",
    "- enable early stopping to reduce the likelihood of model overfitting\n",
    "- evaluate the model on a test dataset\n",
    "\n",
    "The data in this example is taken from the GEFCom2014 forecasting competition<sup>1</sup>. It consists of 3 years of hourly electricity load and temperature values between 2012 and 2014. The task is to forecast future values of electricity load.\n",
    "\n",
    "<sup>1</sup>Tao Hong, Pierre Pinson, Shu Fan, Hamidreza Zareipour, Alberto Troccoli and Rob J. Hyndman, \"Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond\", International Journal of Forecasting, vol.32, no.3, pp 896-913, July-September, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from collections import UserDict\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "from common.utils import load_data, mape, TimeSeriesTensor, create_evaluation_df\n",
    "\n",
    "pd.options.display.float_format = '{:,.12f}'.format\n",
    "np.set_printoptions(precision=12)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-01 14:00:00</th>\n",
       "      <td>20.718750000000</td>\n",
       "      <td>0.000000004875</td>\n",
       "      <td>0.000001013279</td>\n",
       "      <td>5,153.670196530000</td>\n",
       "      <td>309.375000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 16:00:00</th>\n",
       "      <td>16.812500000000</td>\n",
       "      <td>0.000000004917</td>\n",
       "      <td>0.000000726432</td>\n",
       "      <td>5,153.669187550000</td>\n",
       "      <td>310.125000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 18:00:00</th>\n",
       "      <td>13.843750000000</td>\n",
       "      <td>0.000000004875</td>\n",
       "      <td>0.000000702217</td>\n",
       "      <td>5,153.669887540000</td>\n",
       "      <td>308.625000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 20:00:00</th>\n",
       "      <td>12.281250000000</td>\n",
       "      <td>0.000000004875</td>\n",
       "      <td>0.000000769272</td>\n",
       "      <td>5,153.670305250000</td>\n",
       "      <td>309.375000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 22:00:00</th>\n",
       "      <td>23.031250000000</td>\n",
       "      <td>0.000000004753</td>\n",
       "      <td>0.000001149252</td>\n",
       "      <td>5,153.673240660000</td>\n",
       "      <td>307.437500000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Crs          Del_n            Cuc  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-01 14:00:00 20.718750000000 0.000000004875 0.000001013279   \n",
       "2017-11-01 16:00:00 16.812500000000 0.000000004917 0.000000726432   \n",
       "2017-11-01 18:00:00 13.843750000000 0.000000004875 0.000000702217   \n",
       "2017-11-01 20:00:00 12.281250000000 0.000000004875 0.000000769272   \n",
       "2017-11-01 22:00:00 23.031250000000 0.000000004753 0.000001149252   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-01 14:00:00 5,153.670196530000 309.375000000000  \n",
       "2017-11-01 16:00:00 5,153.669187550000 310.125000000000  \n",
       "2017-11-01 18:00:00 5,153.669887540000 308.625000000000  \n",
       "2017-11-01 20:00:00 5,153.670305250000 309.375000000000  \n",
       "2017-11-01 22:00:00 5,153.673240660000 307.437500000000  "
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Cleaned1.csv\" , parse_dates = True)\n",
    "a = pd.to_datetime(df['Epoch_Time_of_Clock'])\n",
    "print(type(a[0]))\n",
    "df = df.drop(['Unnamed: 0', 'Unnamed: 0.1' , 'PRN','SV_Clock_Bias', 'SV_Clock_Drift', 'SV_Clock_Drift_Rate', 'IODE', 'M0','Cus','Toe', 'Cic', 'OMEGA', 'e',\n",
    "       'Cis', 'i0', 'omega', 'OMEGA_dot', 'I_dot', 'Codes', 'GPS_week',\n",
    "       'L2_P_Data_flag', 'SV_accuracy', 'SV_health', 'Tgd', 'IODC', 'T_Tx',\n",
    "       'Fit_Interval' ,'Epoch_Time_of_Clock' ],axis =1 )\n",
    "df.head()\n",
    "#df = df.set_index(['Epoch_Time_of_Clock'])\n",
    "df = df.set_index(a)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc'], dtype='object')"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter parameters and Satellite PRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'sqrt_A'\n",
    "sat_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[5 : , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 12:00:00</th>\n",
       "      <td>40.031250000000</td>\n",
       "      <td>0.000000004919</td>\n",
       "      <td>0.000002089888</td>\n",
       "      <td>5,153.672128680000</td>\n",
       "      <td>297.031250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 14:00:00</th>\n",
       "      <td>46.562500000000</td>\n",
       "      <td>0.000000004852</td>\n",
       "      <td>0.000002363697</td>\n",
       "      <td>5,153.669368740000</td>\n",
       "      <td>288.656250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 16:00:00</th>\n",
       "      <td>43.843750000000</td>\n",
       "      <td>0.000000004891</td>\n",
       "      <td>0.000002117828</td>\n",
       "      <td>5,153.668636320000</td>\n",
       "      <td>289.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 18:00:00</th>\n",
       "      <td>41.750000000000</td>\n",
       "      <td>0.000000004866</td>\n",
       "      <td>0.000002151355</td>\n",
       "      <td>5,153.668607710000</td>\n",
       "      <td>290.937500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 20:00:00</th>\n",
       "      <td>38.531250000000</td>\n",
       "      <td>0.000000004865</td>\n",
       "      <td>0.000002132729</td>\n",
       "      <td>5,153.669593810000</td>\n",
       "      <td>293.375000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 22:00:00</th>\n",
       "      <td>47.281250000000</td>\n",
       "      <td>0.000000004740</td>\n",
       "      <td>0.000002415851</td>\n",
       "      <td>5,153.672065730000</td>\n",
       "      <td>289.593750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 12:00:00</th>\n",
       "      <td>53.625000000000</td>\n",
       "      <td>0.000000004826</td>\n",
       "      <td>0.000002810732</td>\n",
       "      <td>5,153.673458100000</td>\n",
       "      <td>266.281250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 14:00:00</th>\n",
       "      <td>58.187500000000</td>\n",
       "      <td>0.000000004746</td>\n",
       "      <td>0.000002987683</td>\n",
       "      <td>5,153.670349120000</td>\n",
       "      <td>255.406250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 16:00:00</th>\n",
       "      <td>55.843750000000</td>\n",
       "      <td>0.000000004778</td>\n",
       "      <td>0.000002736226</td>\n",
       "      <td>5,153.669727330000</td>\n",
       "      <td>254.875000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 18:00:00</th>\n",
       "      <td>56.031250000000</td>\n",
       "      <td>0.000000004766</td>\n",
       "      <td>0.000002887100</td>\n",
       "      <td>5,153.669181820000</td>\n",
       "      <td>257.343750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 20:00:00</th>\n",
       "      <td>53.281250000000</td>\n",
       "      <td>0.000000004768</td>\n",
       "      <td>0.000002885237</td>\n",
       "      <td>5,153.670465470000</td>\n",
       "      <td>261.406250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 22:00:00</th>\n",
       "      <td>58.937500000000</td>\n",
       "      <td>0.000000004648</td>\n",
       "      <td>0.000003017485</td>\n",
       "      <td>5,153.672172550000</td>\n",
       "      <td>257.843750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 12:00:00</th>\n",
       "      <td>50.843750000000</td>\n",
       "      <td>0.000000004674</td>\n",
       "      <td>0.000002674758</td>\n",
       "      <td>5,153.675607680000</td>\n",
       "      <td>227.906250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 14:00:00</th>\n",
       "      <td>51.312500000000</td>\n",
       "      <td>0.000000004577</td>\n",
       "      <td>0.000002650544</td>\n",
       "      <td>5,153.673034670000</td>\n",
       "      <td>217.781250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 16:00:00</th>\n",
       "      <td>47.406250000000</td>\n",
       "      <td>0.000000004606</td>\n",
       "      <td>0.000002304092</td>\n",
       "      <td>5,153.672115330000</td>\n",
       "      <td>215.468750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 18:00:00</th>\n",
       "      <td>48.562500000000</td>\n",
       "      <td>0.000000004588</td>\n",
       "      <td>0.000002503395</td>\n",
       "      <td>5,153.671932220000</td>\n",
       "      <td>215.406250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 20:00:00</th>\n",
       "      <td>48.250000000000</td>\n",
       "      <td>0.000000004599</td>\n",
       "      <td>0.000002603978</td>\n",
       "      <td>5,153.672990800000</td>\n",
       "      <td>219.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 22:00:00</th>\n",
       "      <td>51.593750000000</td>\n",
       "      <td>0.000000004487</td>\n",
       "      <td>0.000002626330</td>\n",
       "      <td>5,153.674003600001</td>\n",
       "      <td>218.250000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 12:00:00</th>\n",
       "      <td>31.093750000000</td>\n",
       "      <td>0.000000004503</td>\n",
       "      <td>0.000001646578</td>\n",
       "      <td>5,153.677953720000</td>\n",
       "      <td>191.875000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 14:00:00</th>\n",
       "      <td>27.375000000000</td>\n",
       "      <td>0.000000004391</td>\n",
       "      <td>0.000001415610</td>\n",
       "      <td>5,153.676698680000</td>\n",
       "      <td>186.031250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 16:00:00</th>\n",
       "      <td>20.031250000000</td>\n",
       "      <td>0.000000004422</td>\n",
       "      <td>0.000000890344</td>\n",
       "      <td>5,153.675025940000</td>\n",
       "      <td>183.187500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 18:00:00</th>\n",
       "      <td>18.687500000000</td>\n",
       "      <td>0.000000004379</td>\n",
       "      <td>0.000000966713</td>\n",
       "      <td>5,153.676235200000</td>\n",
       "      <td>178.031250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 20:00:00</th>\n",
       "      <td>21.156250000000</td>\n",
       "      <td>0.000000004405</td>\n",
       "      <td>0.000001180917</td>\n",
       "      <td>5,153.676540370000</td>\n",
       "      <td>179.875000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 22:00:00</th>\n",
       "      <td>24.531250000000</td>\n",
       "      <td>0.000000004298</td>\n",
       "      <td>0.000001206994</td>\n",
       "      <td>5,153.677331920000</td>\n",
       "      <td>181.468750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 12:00:00</th>\n",
       "      <td>-0.687500000000</td>\n",
       "      <td>0.000000004359</td>\n",
       "      <td>-0.000000014901</td>\n",
       "      <td>5,153.679876330000</td>\n",
       "      <td>168.125000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 14:00:00</th>\n",
       "      <td>-6.750000000000</td>\n",
       "      <td>0.000000004238</td>\n",
       "      <td>-0.000000361353</td>\n",
       "      <td>5,153.680284500000</td>\n",
       "      <td>168.718750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 16:00:00</th>\n",
       "      <td>-17.968750000000</td>\n",
       "      <td>0.000000004278</td>\n",
       "      <td>-0.000001076609</td>\n",
       "      <td>5,153.677629470000</td>\n",
       "      <td>167.500000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 18:00:00</th>\n",
       "      <td>-24.812500000000</td>\n",
       "      <td>0.000000004208</td>\n",
       "      <td>-0.000001272187</td>\n",
       "      <td>5,153.680631640000</td>\n",
       "      <td>157.937500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 20:00:00</th>\n",
       "      <td>-21.187500000000</td>\n",
       "      <td>0.000000004249</td>\n",
       "      <td>-0.000001024455</td>\n",
       "      <td>5,153.679979320000</td>\n",
       "      <td>156.031250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 22:00:00</th>\n",
       "      <td>-15.406250000000</td>\n",
       "      <td>0.000000004141</td>\n",
       "      <td>-0.000000873581</td>\n",
       "      <td>5,153.681163790000</td>\n",
       "      <td>159.031250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25 12:00:00</th>\n",
       "      <td>-81.125000000000</td>\n",
       "      <td>0.000000004373</td>\n",
       "      <td>-0.000004203990</td>\n",
       "      <td>5,153.680116650000</td>\n",
       "      <td>251.218750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25 14:00:00</th>\n",
       "      <td>-82.937500000000</td>\n",
       "      <td>0.000000004391</td>\n",
       "      <td>-0.000004375353</td>\n",
       "      <td>5,153.679018020000</td>\n",
       "      <td>244.562500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25 16:00:00</th>\n",
       "      <td>-76.906250000000</td>\n",
       "      <td>0.000000004371</td>\n",
       "      <td>-0.000004079193</td>\n",
       "      <td>5,153.678968430000</td>\n",
       "      <td>244.062500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25 18:00:00</th>\n",
       "      <td>-72.406250000000</td>\n",
       "      <td>0.000000004402</td>\n",
       "      <td>-0.000003699213</td>\n",
       "      <td>5,153.678714750000</td>\n",
       "      <td>248.656250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25 20:00:00</th>\n",
       "      <td>-67.500000000000</td>\n",
       "      <td>0.000000004332</td>\n",
       "      <td>-0.000003566965</td>\n",
       "      <td>5,153.680696490000</td>\n",
       "      <td>255.875000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-25 22:00:00</th>\n",
       "      <td>-68.781250000000</td>\n",
       "      <td>0.000000004344</td>\n",
       "      <td>-0.000003634021</td>\n",
       "      <td>5,153.678533550000</td>\n",
       "      <td>264.312500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 12:00:00</th>\n",
       "      <td>-63.437500000000</td>\n",
       "      <td>0.000000004495</td>\n",
       "      <td>-0.000003309920</td>\n",
       "      <td>5,153.677621840000</td>\n",
       "      <td>273.125000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 14:00:00</th>\n",
       "      <td>-67.125000000000</td>\n",
       "      <td>0.000000004523</td>\n",
       "      <td>-0.000003563240</td>\n",
       "      <td>5,153.676332470000</td>\n",
       "      <td>268.437500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 16:00:00</th>\n",
       "      <td>-64.125000000000</td>\n",
       "      <td>0.000000004489</td>\n",
       "      <td>-0.000003395602</td>\n",
       "      <td>5,153.677089690000</td>\n",
       "      <td>264.906250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 18:00:00</th>\n",
       "      <td>-60.781250000000</td>\n",
       "      <td>0.000000004513</td>\n",
       "      <td>-0.000003080815</td>\n",
       "      <td>5,153.676860810000</td>\n",
       "      <td>267.468750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 20:00:00</th>\n",
       "      <td>-53.031250000000</td>\n",
       "      <td>0.000000004432</td>\n",
       "      <td>-0.000002814457</td>\n",
       "      <td>5,153.679340360000</td>\n",
       "      <td>273.125000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 22:00:00</th>\n",
       "      <td>-50.718750000000</td>\n",
       "      <td>0.000000004453</td>\n",
       "      <td>-0.000002704561</td>\n",
       "      <td>5,153.676721570000</td>\n",
       "      <td>282.656250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 12:00:00</th>\n",
       "      <td>-37.531250000000</td>\n",
       "      <td>0.000000004606</td>\n",
       "      <td>-0.000001987442</td>\n",
       "      <td>5,153.674901960000</td>\n",
       "      <td>286.781250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 14:00:00</th>\n",
       "      <td>-41.937500000000</td>\n",
       "      <td>0.000000004642</td>\n",
       "      <td>-0.000002272427</td>\n",
       "      <td>5,153.673654560000</td>\n",
       "      <td>284.437500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 16:00:00</th>\n",
       "      <td>-42.187500000000</td>\n",
       "      <td>0.000000004602</td>\n",
       "      <td>-0.000002242625</td>\n",
       "      <td>5,153.674737930000</td>\n",
       "      <td>280.156250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 18:00:00</th>\n",
       "      <td>-41.343750000000</td>\n",
       "      <td>0.000000004618</td>\n",
       "      <td>-0.000002054498</td>\n",
       "      <td>5,153.674879070000</td>\n",
       "      <td>281.687500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 20:00:00</th>\n",
       "      <td>-31.781250000000</td>\n",
       "      <td>0.000000004526</td>\n",
       "      <td>-0.000001702458</td>\n",
       "      <td>5,153.677614210000</td>\n",
       "      <td>284.906250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 22:00:00</th>\n",
       "      <td>-26.656250000000</td>\n",
       "      <td>0.000000004541</td>\n",
       "      <td>-0.000001456589</td>\n",
       "      <td>5,153.675252910000</td>\n",
       "      <td>292.593750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>-7.843750000000</td>\n",
       "      <td>0.000000004682</td>\n",
       "      <td>-0.000000456348</td>\n",
       "      <td>5,153.672513960000</td>\n",
       "      <td>288.250000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>-11.718750000000</td>\n",
       "      <td>0.000000004718</td>\n",
       "      <td>-0.000000722706</td>\n",
       "      <td>5,153.671504970000</td>\n",
       "      <td>287.781250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>-14.062500000000</td>\n",
       "      <td>0.000000004688</td>\n",
       "      <td>-0.000000778586</td>\n",
       "      <td>5,153.672332760000</td>\n",
       "      <td>285.187500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>-16.187500000000</td>\n",
       "      <td>0.000000004695</td>\n",
       "      <td>-0.000000737607</td>\n",
       "      <td>5,153.673091890000</td>\n",
       "      <td>286.968750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>-6.312500000000</td>\n",
       "      <td>0.000000004596</td>\n",
       "      <td>-0.000000370666</td>\n",
       "      <td>5,153.675785060000</td>\n",
       "      <td>287.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>-0.562500000000</td>\n",
       "      <td>0.000000004587</td>\n",
       "      <td>-0.000000091270</td>\n",
       "      <td>5,153.674497600000</td>\n",
       "      <td>290.468750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>19.437500000000</td>\n",
       "      <td>0.000000004697</td>\n",
       "      <td>0.000000964850</td>\n",
       "      <td>5,153.671113970000</td>\n",
       "      <td>275.218750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>16.781250000000</td>\n",
       "      <td>0.000000004731</td>\n",
       "      <td>0.000000741333</td>\n",
       "      <td>5,153.670415880000</td>\n",
       "      <td>275.343750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>14.406250000000</td>\n",
       "      <td>0.000000004717</td>\n",
       "      <td>0.000000698492</td>\n",
       "      <td>5,153.670558930000</td>\n",
       "      <td>275.750000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>10.031250000000</td>\n",
       "      <td>0.000000004719</td>\n",
       "      <td>0.000000629574</td>\n",
       "      <td>5,153.671985630000</td>\n",
       "      <td>279.062500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>18.531250000000</td>\n",
       "      <td>0.000000004618</td>\n",
       "      <td>0.000000927597</td>\n",
       "      <td>5,153.674263000000</td>\n",
       "      <td>277.437500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>22.062500000000</td>\n",
       "      <td>0.000000004572</td>\n",
       "      <td>0.000001100823</td>\n",
       "      <td>5,153.674684520000</td>\n",
       "      <td>274.031250000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Crs          Del_n             Cuc  \\\n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 12:00:00  40.031250000000 0.000000004919  0.000002089888   \n",
       "2017-11-02 14:00:00  46.562500000000 0.000000004852  0.000002363697   \n",
       "2017-11-02 16:00:00  43.843750000000 0.000000004891  0.000002117828   \n",
       "2017-11-02 18:00:00  41.750000000000 0.000000004866  0.000002151355   \n",
       "2017-11-02 20:00:00  38.531250000000 0.000000004865  0.000002132729   \n",
       "2017-11-02 22:00:00  47.281250000000 0.000000004740  0.000002415851   \n",
       "2017-11-03 12:00:00  53.625000000000 0.000000004826  0.000002810732   \n",
       "2017-11-03 14:00:00  58.187500000000 0.000000004746  0.000002987683   \n",
       "2017-11-03 16:00:00  55.843750000000 0.000000004778  0.000002736226   \n",
       "2017-11-03 18:00:00  56.031250000000 0.000000004766  0.000002887100   \n",
       "2017-11-03 20:00:00  53.281250000000 0.000000004768  0.000002885237   \n",
       "2017-11-03 22:00:00  58.937500000000 0.000000004648  0.000003017485   \n",
       "2017-11-04 12:00:00  50.843750000000 0.000000004674  0.000002674758   \n",
       "2017-11-04 14:00:00  51.312500000000 0.000000004577  0.000002650544   \n",
       "2017-11-04 16:00:00  47.406250000000 0.000000004606  0.000002304092   \n",
       "2017-11-04 18:00:00  48.562500000000 0.000000004588  0.000002503395   \n",
       "2017-11-04 20:00:00  48.250000000000 0.000000004599  0.000002603978   \n",
       "2017-11-04 22:00:00  51.593750000000 0.000000004487  0.000002626330   \n",
       "2017-11-05 12:00:00  31.093750000000 0.000000004503  0.000001646578   \n",
       "2017-11-05 14:00:00  27.375000000000 0.000000004391  0.000001415610   \n",
       "2017-11-05 16:00:00  20.031250000000 0.000000004422  0.000000890344   \n",
       "2017-11-05 18:00:00  18.687500000000 0.000000004379  0.000000966713   \n",
       "2017-11-05 20:00:00  21.156250000000 0.000000004405  0.000001180917   \n",
       "2017-11-05 22:00:00  24.531250000000 0.000000004298  0.000001206994   \n",
       "2017-11-06 12:00:00  -0.687500000000 0.000000004359 -0.000000014901   \n",
       "2017-11-06 14:00:00  -6.750000000000 0.000000004238 -0.000000361353   \n",
       "2017-11-06 16:00:00 -17.968750000000 0.000000004278 -0.000001076609   \n",
       "2017-11-06 18:00:00 -24.812500000000 0.000000004208 -0.000001272187   \n",
       "2017-11-06 20:00:00 -21.187500000000 0.000000004249 -0.000001024455   \n",
       "2017-11-06 22:00:00 -15.406250000000 0.000000004141 -0.000000873581   \n",
       "...                              ...            ...             ...   \n",
       "2017-11-25 12:00:00 -81.125000000000 0.000000004373 -0.000004203990   \n",
       "2017-11-25 14:00:00 -82.937500000000 0.000000004391 -0.000004375353   \n",
       "2017-11-25 16:00:00 -76.906250000000 0.000000004371 -0.000004079193   \n",
       "2017-11-25 18:00:00 -72.406250000000 0.000000004402 -0.000003699213   \n",
       "2017-11-25 20:00:00 -67.500000000000 0.000000004332 -0.000003566965   \n",
       "2017-11-25 22:00:00 -68.781250000000 0.000000004344 -0.000003634021   \n",
       "2017-11-26 12:00:00 -63.437500000000 0.000000004495 -0.000003309920   \n",
       "2017-11-26 14:00:00 -67.125000000000 0.000000004523 -0.000003563240   \n",
       "2017-11-26 16:00:00 -64.125000000000 0.000000004489 -0.000003395602   \n",
       "2017-11-26 18:00:00 -60.781250000000 0.000000004513 -0.000003080815   \n",
       "2017-11-26 20:00:00 -53.031250000000 0.000000004432 -0.000002814457   \n",
       "2017-11-26 22:00:00 -50.718750000000 0.000000004453 -0.000002704561   \n",
       "2017-11-27 12:00:00 -37.531250000000 0.000000004606 -0.000001987442   \n",
       "2017-11-27 14:00:00 -41.937500000000 0.000000004642 -0.000002272427   \n",
       "2017-11-27 16:00:00 -42.187500000000 0.000000004602 -0.000002242625   \n",
       "2017-11-27 18:00:00 -41.343750000000 0.000000004618 -0.000002054498   \n",
       "2017-11-27 20:00:00 -31.781250000000 0.000000004526 -0.000001702458   \n",
       "2017-11-27 22:00:00 -26.656250000000 0.000000004541 -0.000001456589   \n",
       "2017-11-28 12:00:00  -7.843750000000 0.000000004682 -0.000000456348   \n",
       "2017-11-28 14:00:00 -11.718750000000 0.000000004718 -0.000000722706   \n",
       "2017-11-28 16:00:00 -14.062500000000 0.000000004688 -0.000000778586   \n",
       "2017-11-28 18:00:00 -16.187500000000 0.000000004695 -0.000000737607   \n",
       "2017-11-28 20:00:00  -6.312500000000 0.000000004596 -0.000000370666   \n",
       "2017-11-28 22:00:00  -0.562500000000 0.000000004587 -0.000000091270   \n",
       "2017-11-29 12:00:00  19.437500000000 0.000000004697  0.000000964850   \n",
       "2017-11-29 14:00:00  16.781250000000 0.000000004731  0.000000741333   \n",
       "2017-11-29 16:00:00  14.406250000000 0.000000004717  0.000000698492   \n",
       "2017-11-29 18:00:00  10.031250000000 0.000000004719  0.000000629574   \n",
       "2017-11-29 20:00:00  18.531250000000 0.000000004618  0.000000927597   \n",
       "2017-11-29 22:00:00  22.062500000000 0.000000004572  0.000001100823   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-02 12:00:00 5,153.672128680000 297.031250000000  \n",
       "2017-11-02 14:00:00 5,153.669368740000 288.656250000000  \n",
       "2017-11-02 16:00:00 5,153.668636320000 289.531250000000  \n",
       "2017-11-02 18:00:00 5,153.668607710000 290.937500000000  \n",
       "2017-11-02 20:00:00 5,153.669593810000 293.375000000000  \n",
       "2017-11-02 22:00:00 5,153.672065730000 289.593750000000  \n",
       "2017-11-03 12:00:00 5,153.673458100000 266.281250000000  \n",
       "2017-11-03 14:00:00 5,153.670349120000 255.406250000000  \n",
       "2017-11-03 16:00:00 5,153.669727330000 254.875000000000  \n",
       "2017-11-03 18:00:00 5,153.669181820000 257.343750000000  \n",
       "2017-11-03 20:00:00 5,153.670465470000 261.406250000000  \n",
       "2017-11-03 22:00:00 5,153.672172550000 257.843750000000  \n",
       "2017-11-04 12:00:00 5,153.675607680000 227.906250000000  \n",
       "2017-11-04 14:00:00 5,153.673034670000 217.781250000000  \n",
       "2017-11-04 16:00:00 5,153.672115330000 215.468750000000  \n",
       "2017-11-04 18:00:00 5,153.671932220000 215.406250000000  \n",
       "2017-11-04 20:00:00 5,153.672990800000 219.531250000000  \n",
       "2017-11-04 22:00:00 5,153.674003600001 218.250000000000  \n",
       "2017-11-05 12:00:00 5,153.677953720000 191.875000000000  \n",
       "2017-11-05 14:00:00 5,153.676698680000 186.031250000000  \n",
       "2017-11-05 16:00:00 5,153.675025940000 183.187500000000  \n",
       "2017-11-05 18:00:00 5,153.676235200000 178.031250000000  \n",
       "2017-11-05 20:00:00 5,153.676540370000 179.875000000000  \n",
       "2017-11-05 22:00:00 5,153.677331920000 181.468750000000  \n",
       "2017-11-06 12:00:00 5,153.679876330000 168.125000000000  \n",
       "2017-11-06 14:00:00 5,153.680284500000 168.718750000000  \n",
       "2017-11-06 16:00:00 5,153.677629470000 167.500000000000  \n",
       "2017-11-06 18:00:00 5,153.680631640000 157.937500000000  \n",
       "2017-11-06 20:00:00 5,153.679979320000 156.031250000000  \n",
       "2017-11-06 22:00:00 5,153.681163790000 159.031250000000  \n",
       "...                                ...              ...  \n",
       "2017-11-25 12:00:00 5,153.680116650000 251.218750000000  \n",
       "2017-11-25 14:00:00 5,153.679018020000 244.562500000000  \n",
       "2017-11-25 16:00:00 5,153.678968430000 244.062500000000  \n",
       "2017-11-25 18:00:00 5,153.678714750000 248.656250000000  \n",
       "2017-11-25 20:00:00 5,153.680696490000 255.875000000000  \n",
       "2017-11-25 22:00:00 5,153.678533550000 264.312500000000  \n",
       "2017-11-26 12:00:00 5,153.677621840000 273.125000000000  \n",
       "2017-11-26 14:00:00 5,153.676332470000 268.437500000000  \n",
       "2017-11-26 16:00:00 5,153.677089690000 264.906250000000  \n",
       "2017-11-26 18:00:00 5,153.676860810000 267.468750000000  \n",
       "2017-11-26 20:00:00 5,153.679340360000 273.125000000000  \n",
       "2017-11-26 22:00:00 5,153.676721570000 282.656250000000  \n",
       "2017-11-27 12:00:00 5,153.674901960000 286.781250000000  \n",
       "2017-11-27 14:00:00 5,153.673654560000 284.437500000000  \n",
       "2017-11-27 16:00:00 5,153.674737930000 280.156250000000  \n",
       "2017-11-27 18:00:00 5,153.674879070000 281.687500000000  \n",
       "2017-11-27 20:00:00 5,153.677614210000 284.906250000000  \n",
       "2017-11-27 22:00:00 5,153.675252910000 292.593750000000  \n",
       "2017-11-28 12:00:00 5,153.672513960000 288.250000000000  \n",
       "2017-11-28 14:00:00 5,153.671504970000 287.781250000000  \n",
       "2017-11-28 16:00:00 5,153.672332760000 285.187500000000  \n",
       "2017-11-28 18:00:00 5,153.673091890000 286.968750000000  \n",
       "2017-11-28 20:00:00 5,153.675785060000 287.531250000000  \n",
       "2017-11-28 22:00:00 5,153.674497600000 290.468750000000  \n",
       "2017-11-29 12:00:00 5,153.671113970000 275.218750000000  \n",
       "2017-11-29 14:00:00 5,153.670415880000 275.343750000000  \n",
       "2017-11-29 16:00:00 5,153.670558930000 275.750000000000  \n",
       "2017-11-29 18:00:00 5,153.671985630000 279.062500000000  \n",
       "2017-11-29 20:00:00 5,153.674263000000 277.437500000000  \n",
       "2017-11-29 22:00:00 5,153.674684520000 274.031250000000  \n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter number of entries per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "2017-11-25 12:00:00 2017-11-21 12:00:00\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "entry = 6\n",
    "print(df.shape[0])\n",
    "no_of_entries = df.shape[0]//entry\n",
    "valid = (no_of_entries * 70)//100\n",
    "test = (no_of_entries * 85)//100\n",
    "indexes = df.index\n",
    "#print(valid , test , indexes)\n",
    "valid_start_dt = indexes[int(valid)*int(entry)] \n",
    "test_start_dt = indexes [int(test)*int(entry)] \n",
    "test_start_dt = str(test_start_dt)\n",
    "valid_start_dt = str(valid_start_dt)\n",
    "print(test_start_dt,valid_start_dt)\n",
    "print(type(test_start_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter lag and no. of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"total = len(df)\n",
    "t = total*70/100\n",
    "t = round(t)\n",
    "indexes = df.index\n",
    "valid_start_dt = str(indexes[t])\n",
    "t = total*85/100\n",
    "t = round(t)\n",
    "test_start_dt = str(indexes[t])\n",
    "print(valid_start_dt , test_start_dt)\n",
    "\"\"\"\n",
    "T = 6\n",
    "HORIZON = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set containing only the model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 12:00:00</th>\n",
       "      <td>40.031250000000</td>\n",
       "      <td>0.000000004919</td>\n",
       "      <td>0.000002089888</td>\n",
       "      <td>5,153.672128680000</td>\n",
       "      <td>297.031250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 14:00:00</th>\n",
       "      <td>46.562500000000</td>\n",
       "      <td>0.000000004852</td>\n",
       "      <td>0.000002363697</td>\n",
       "      <td>5,153.669368740000</td>\n",
       "      <td>288.656250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 16:00:00</th>\n",
       "      <td>43.843750000000</td>\n",
       "      <td>0.000000004891</td>\n",
       "      <td>0.000002117828</td>\n",
       "      <td>5,153.668636320000</td>\n",
       "      <td>289.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 18:00:00</th>\n",
       "      <td>41.750000000000</td>\n",
       "      <td>0.000000004866</td>\n",
       "      <td>0.000002151355</td>\n",
       "      <td>5,153.668607710000</td>\n",
       "      <td>290.937500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 20:00:00</th>\n",
       "      <td>38.531250000000</td>\n",
       "      <td>0.000000004865</td>\n",
       "      <td>0.000002132729</td>\n",
       "      <td>5,153.669593810000</td>\n",
       "      <td>293.375000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Crs          Del_n            Cuc  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-02 12:00:00 40.031250000000 0.000000004919 0.000002089888   \n",
       "2017-11-02 14:00:00 46.562500000000 0.000000004852 0.000002363697   \n",
       "2017-11-02 16:00:00 43.843750000000 0.000000004891 0.000002117828   \n",
       "2017-11-02 18:00:00 41.750000000000 0.000000004866 0.000002151355   \n",
       "2017-11-02 20:00:00 38.531250000000 0.000000004865 0.000002132729   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-02 12:00:00 5,153.672128680000 297.031250000000  \n",
       "2017-11-02 14:00:00 5,153.669368740000 288.656250000000  \n",
       "2017-11-02 16:00:00 5,153.668636320000 289.531250000000  \n",
       "2017-11-02 18:00:00 5,153.668607710000 290.937500000000  \n",
       "2017-11-02 20:00:00 5,153.669593810000 293.375000000000  "
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.copy()[df.index < valid_start_dt][['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc' ]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-20 12:00:00</th>\n",
       "      <td>-20.406250000000</td>\n",
       "      <td>0.000000004216</td>\n",
       "      <td>-0.000001039356</td>\n",
       "      <td>5,153.679801940000</td>\n",
       "      <td>169.656250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 14:00:00</th>\n",
       "      <td>-14.062500000000</td>\n",
       "      <td>0.000000004161</td>\n",
       "      <td>-0.000000858679</td>\n",
       "      <td>5,153.680685040000</td>\n",
       "      <td>168.312500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 16:00:00</th>\n",
       "      <td>-13.000000000000</td>\n",
       "      <td>0.000000004202</td>\n",
       "      <td>-0.000000847504</td>\n",
       "      <td>5,153.677953720000</td>\n",
       "      <td>179.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 18:00:00</th>\n",
       "      <td>-23.156250000000</td>\n",
       "      <td>0.000000004186</td>\n",
       "      <td>-0.000001130626</td>\n",
       "      <td>5,153.681100850000</td>\n",
       "      <td>187.562500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 20:00:00</th>\n",
       "      <td>-30.343750000000</td>\n",
       "      <td>0.000000004166</td>\n",
       "      <td>-0.000001562759</td>\n",
       "      <td>5,153.679851530000</td>\n",
       "      <td>188.250000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 22:00:00</th>\n",
       "      <td>-34.812500000000</td>\n",
       "      <td>0.000000004077</td>\n",
       "      <td>-0.000001810491</td>\n",
       "      <td>5,153.682205200000</td>\n",
       "      <td>178.343750000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Crs          Del_n             Cuc  \\\n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-20 12:00:00 -20.406250000000 0.000000004216 -0.000001039356   \n",
       "2017-11-20 14:00:00 -14.062500000000 0.000000004161 -0.000000858679   \n",
       "2017-11-20 16:00:00 -13.000000000000 0.000000004202 -0.000000847504   \n",
       "2017-11-20 18:00:00 -23.156250000000 0.000000004186 -0.000001130626   \n",
       "2017-11-20 20:00:00 -30.343750000000 0.000000004166 -0.000001562759   \n",
       "2017-11-20 22:00:00 -34.812500000000 0.000000004077 -0.000001810491   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-20 12:00:00 5,153.679801940000 169.656250000000  \n",
       "2017-11-20 14:00:00 5,153.680685040000 168.312500000000  \n",
       "2017-11-20 16:00:00 5,153.677953720000 179.531250000000  \n",
       "2017-11-20 18:00:00 5,153.681100850000 187.562500000000  \n",
       "2017-11-20 20:00:00 5,153.679851530000 188.250000000000  \n",
       "2017-11-20 22:00:00 5,153.682205200000 178.343750000000  "
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data to be in range (0, 1). This transformation should be calibrated on the training set only. This is to prevent information from the validation or test sets leaking into the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter variable to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_scalar = StandardScaler()\n",
    "y_scalar.fit(train[[var_name]])\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "train[['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc']] = X_scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the TimeSeriesTensor convenience class to:\n",
    "1. Shift the values of the time series to create a Pandas dataframe containing all the data for a single training example\n",
    "2. Discard any samples with missing values\n",
    "3. Transform this Pandas dataframe into a numpy array of shape (samples, time steps, features) for input into Keras\n",
    "\n",
    "The class takes the following parameters:\n",
    "\n",
    "- **dataset**: original time series\n",
    "- **H**: the forecast horizon\n",
    "- **tensor_structure**: a dictionary discribing the tensor structure in the form { 'tensor_name' : (range(max_backward_shift, max_forward_shift), [feature, feature, ...] ) }\n",
    "- **freq**: time series frequency\n",
    "- **drop_incomplete**: (Boolean) whether to drop incomplete samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_structure = {'X':(range(-T+1, 1), ['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc'])}\n",
    "train_inputs = TimeSeriesTensor(train, var_name, HORIZON, {'X':(range(-T+1, 1), ['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc'])} ,freq = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crs</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sqrt_A</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 22:00:00</th>\n",
       "      <td>-0.675754723574</td>\n",
       "      <td>-1.426387417839</td>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>0.974765291006</td>\n",
       "      <td>1.110121111941</td>\n",
       "      <td>1.053776822844</td>\n",
       "      <td>1.010385243884</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.839926159973</td>\n",
       "      <td>-1.846833763407</td>\n",
       "      <td>-1.608749600881</td>\n",
       "      <td>-1.011928788461</td>\n",
       "      <td>1.413241817935</td>\n",
       "      <td>1.233213865528</td>\n",
       "      <td>1.252022756078</td>\n",
       "      <td>1.282251330176</td>\n",
       "      <td>1.334647525280</td>\n",
       "      <td>1.253366248260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 12:00:00</th>\n",
       "      <td>-1.426387417839</td>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>1.110121111941</td>\n",
       "      <td>1.053776822844</td>\n",
       "      <td>1.010385243884</td>\n",
       "      <td>0.943678786676</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.846833763407</td>\n",
       "      <td>-1.608749600881</td>\n",
       "      <td>-1.011928788461</td>\n",
       "      <td>-0.675754723574</td>\n",
       "      <td>1.233213865528</td>\n",
       "      <td>1.252022756078</td>\n",
       "      <td>1.282251330176</td>\n",
       "      <td>1.334647525280</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>0.752243664320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 14:00:00</th>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>1.053776822844</td>\n",
       "      <td>1.010385243884</td>\n",
       "      <td>0.943678786676</td>\n",
       "      <td>1.125016728599</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.608749600881</td>\n",
       "      <td>-1.011928788461</td>\n",
       "      <td>-0.675754723574</td>\n",
       "      <td>-1.426387417839</td>\n",
       "      <td>1.252022756078</td>\n",
       "      <td>1.282251330176</td>\n",
       "      <td>1.334647525280</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>0.752243664320</td>\n",
       "      <td>0.518476024626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 16:00:00</th>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>1.010385243884</td>\n",
       "      <td>0.943678786676</td>\n",
       "      <td>1.125016728599</td>\n",
       "      <td>1.256486736493</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.011928788461</td>\n",
       "      <td>-0.675754723574</td>\n",
       "      <td>-1.426387417839</td>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>1.282251330176</td>\n",
       "      <td>1.334647525280</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>0.752243664320</td>\n",
       "      <td>0.518476024626</td>\n",
       "      <td>0.507056341078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 18:00:00</th>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>0.943678786676</td>\n",
       "      <td>1.125016728599</td>\n",
       "      <td>1.256486736493</td>\n",
       "      <td>1.351041520496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675754723574</td>\n",
       "      <td>-1.426387417839</td>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>1.334647525280</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>0.752243664320</td>\n",
       "      <td>0.518476024626</td>\n",
       "      <td>0.507056341078</td>\n",
       "      <td>0.560124282273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 20:00:00</th>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>1.125016728599</td>\n",
       "      <td>1.256486736493</td>\n",
       "      <td>1.351041520496</td>\n",
       "      <td>1.302468857481</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.426387417839</td>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>0.752243664320</td>\n",
       "      <td>0.518476024626</td>\n",
       "      <td>0.507056341078</td>\n",
       "      <td>0.560124282273</td>\n",
       "      <td>0.647451274112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03 22:00:00</th>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>1.256486736493</td>\n",
       "      <td>1.351041520496</td>\n",
       "      <td>1.302468857481</td>\n",
       "      <td>1.306354670522</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.576512508022</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>0.752243664320</td>\n",
       "      <td>0.518476024626</td>\n",
       "      <td>0.507056341078</td>\n",
       "      <td>0.560124282273</td>\n",
       "      <td>0.647451274112</td>\n",
       "      <td>0.570872219730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 12:00:00</th>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>1.351041520496</td>\n",
       "      <td>1.302468857481</td>\n",
       "      <td>1.306354670522</td>\n",
       "      <td>1.249362745918</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.708220541186</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>0.518476024626</td>\n",
       "      <td>0.507056341078</td>\n",
       "      <td>0.560124282273</td>\n",
       "      <td>0.647451274112</td>\n",
       "      <td>0.570872219730</td>\n",
       "      <td>-0.072660535518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 14:00:00</th>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>1.302468857481</td>\n",
       "      <td>1.306354670522</td>\n",
       "      <td>1.249362745918</td>\n",
       "      <td>1.366584772660</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.398295852747</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>0.507056341078</td>\n",
       "      <td>0.560124282273</td>\n",
       "      <td>0.647451274112</td>\n",
       "      <td>0.570872219730</td>\n",
       "      <td>-0.072660535518</td>\n",
       "      <td>-0.290306269025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 16:00:00</th>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>1.306354670522</td>\n",
       "      <td>1.249362745918</td>\n",
       "      <td>1.366584772660</td>\n",
       "      <td>1.198847176382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986138148336</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>0.560124282273</td>\n",
       "      <td>0.647451274112</td>\n",
       "      <td>0.570872219730</td>\n",
       "      <td>-0.072660535518</td>\n",
       "      <td>-0.290306269025</td>\n",
       "      <td>-0.340015479765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 18:00:00</th>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>1.249362745918</td>\n",
       "      <td>1.366584772660</td>\n",
       "      <td>1.198847176382</td>\n",
       "      <td>1.208561708985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156759739101</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>0.647451274112</td>\n",
       "      <td>0.570872219730</td>\n",
       "      <td>-0.072660535518</td>\n",
       "      <td>-0.290306269025</td>\n",
       "      <td>-0.340015479765</td>\n",
       "      <td>-0.341358971947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 20:00:00</th>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>1.366584772660</td>\n",
       "      <td>1.198847176382</td>\n",
       "      <td>1.208561708985</td>\n",
       "      <td>1.127607270627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.777987739546</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>0.570872219730</td>\n",
       "      <td>-0.072660535518</td>\n",
       "      <td>-0.290306269025</td>\n",
       "      <td>-0.340015479765</td>\n",
       "      <td>-0.341358971947</td>\n",
       "      <td>-0.252688487925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-04 22:00:00</th>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>1.198847176382</td>\n",
       "      <td>1.208561708985</td>\n",
       "      <td>1.127607270627</td>\n",
       "      <td>1.151569784381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999953355422</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>-0.072660535518</td>\n",
       "      <td>-0.290306269025</td>\n",
       "      <td>-0.340015479765</td>\n",
       "      <td>-0.341358971947</td>\n",
       "      <td>-0.252688487925</td>\n",
       "      <td>-0.280230077659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 12:00:00</th>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>1.208561708985</td>\n",
       "      <td>1.127607270627</td>\n",
       "      <td>1.151569784381</td>\n",
       "      <td>1.145093429312</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.044163467163</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>-0.290306269025</td>\n",
       "      <td>-0.340015479765</td>\n",
       "      <td>-0.341358971947</td>\n",
       "      <td>-0.252688487925</td>\n",
       "      <td>-0.280230077659</td>\n",
       "      <td>-0.847183778525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 14:00:00</th>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>1.127607270627</td>\n",
       "      <td>1.151569784381</td>\n",
       "      <td>1.145093429312</td>\n",
       "      <td>1.214390428547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788579720265</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.340015479765</td>\n",
       "      <td>-0.341358971947</td>\n",
       "      <td>-0.252688487925</td>\n",
       "      <td>-0.280230077659</td>\n",
       "      <td>-0.847183778525</td>\n",
       "      <td>-0.972800297555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 16:00:00</th>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.151569784381</td>\n",
       "      <td>1.145093429312</td>\n",
       "      <td>1.214390428547</td>\n",
       "      <td>0.789541536042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544049104567</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.341358971947</td>\n",
       "      <td>-0.252688487925</td>\n",
       "      <td>-0.280230077659</td>\n",
       "      <td>-0.847183778525</td>\n",
       "      <td>-0.972800297555</td>\n",
       "      <td>-1.033929191843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 18:00:00</th>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>1.145093429312</td>\n",
       "      <td>1.214390428547</td>\n",
       "      <td>0.789541536042</td>\n",
       "      <td>0.712472910725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>-0.252688487925</td>\n",
       "      <td>-0.280230077659</td>\n",
       "      <td>-0.847183778525</td>\n",
       "      <td>-0.972800297555</td>\n",
       "      <td>-1.033929191843</td>\n",
       "      <td>-1.144767296870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 20:00:00</th>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.214390428547</td>\n",
       "      <td>0.789541536042</td>\n",
       "      <td>0.712472910725</td>\n",
       "      <td>0.560278566611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106651498474</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>-0.280230077659</td>\n",
       "      <td>-0.847183778525</td>\n",
       "      <td>-0.972800297555</td>\n",
       "      <td>-1.033929191843</td>\n",
       "      <td>-1.144767296870</td>\n",
       "      <td>-1.105134277497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 22:00:00</th>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>0.789541536042</td>\n",
       "      <td>0.712472910725</td>\n",
       "      <td>0.560278566611</td>\n",
       "      <td>0.532430239816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297215150184</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>-0.847183778525</td>\n",
       "      <td>-0.972800297555</td>\n",
       "      <td>-1.033929191843</td>\n",
       "      <td>-1.144767296870</td>\n",
       "      <td>-1.105134277497</td>\n",
       "      <td>-1.070875226852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 12:00:00</th>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>0.712472910725</td>\n",
       "      <td>0.560278566611</td>\n",
       "      <td>0.532430239816</td>\n",
       "      <td>0.583593444859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005251196818</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>-0.972800297555</td>\n",
       "      <td>-1.033929191843</td>\n",
       "      <td>-1.144767296870</td>\n",
       "      <td>-1.105134277497</td>\n",
       "      <td>-1.070875226852</td>\n",
       "      <td>-1.357710807740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 14:00:00</th>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.560278566611</td>\n",
       "      <td>0.532430239816</td>\n",
       "      <td>0.583593444859</td>\n",
       "      <td>0.653538079600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068429103362</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>-1.033929191843</td>\n",
       "      <td>-1.144767296870</td>\n",
       "      <td>-1.105134277497</td>\n",
       "      <td>-1.070875226852</td>\n",
       "      <td>-1.357710807740</td>\n",
       "      <td>-1.344947632010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 16:00:00</th>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>0.532430239816</td>\n",
       "      <td>0.583593444859</td>\n",
       "      <td>0.653538079600</td>\n",
       "      <td>0.130896225559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259541078700</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>-1.144767296870</td>\n",
       "      <td>-1.105134277497</td>\n",
       "      <td>-1.070875226852</td>\n",
       "      <td>-1.357710807740</td>\n",
       "      <td>-1.344947632010</td>\n",
       "      <td>-1.371145729561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 18:00:00</th>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>0.583593444859</td>\n",
       "      <td>0.653538079600</td>\n",
       "      <td>0.130896225559</td>\n",
       "      <td>0.005254937227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873863889868</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>-1.105134277497</td>\n",
       "      <td>-1.070875226852</td>\n",
       "      <td>-1.357710807740</td>\n",
       "      <td>-1.344947632010</td>\n",
       "      <td>-1.371145729561</td>\n",
       "      <td>-1.576700033430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 20:00:00</th>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>0.653538079600</td>\n",
       "      <td>0.130896225559</td>\n",
       "      <td>0.005254937227</td>\n",
       "      <td>-0.227246209738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972412528554</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>-1.070875226852</td>\n",
       "      <td>-1.357710807740</td>\n",
       "      <td>-1.344947632010</td>\n",
       "      <td>-1.371145729561</td>\n",
       "      <td>-1.576700033430</td>\n",
       "      <td>-1.617676544985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 22:00:00</th>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>1.900341990851</td>\n",
       "      <td>0.130896225559</td>\n",
       "      <td>0.005254937227</td>\n",
       "      <td>-0.227246209738</td>\n",
       "      <td>-0.369078385742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331381604613</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>-1.357710807740</td>\n",
       "      <td>-1.344947632010</td>\n",
       "      <td>-1.371145729561</td>\n",
       "      <td>-1.576700033430</td>\n",
       "      <td>-1.617676544985</td>\n",
       "      <td>-1.553188920242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 12:00:00</th>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>1.900341990851</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>0.005254937227</td>\n",
       "      <td>-0.227246209738</td>\n",
       "      <td>-0.369078385742</td>\n",
       "      <td>-0.293952666946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056226072910</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>-1.344947632010</td>\n",
       "      <td>-1.371145729561</td>\n",
       "      <td>-1.576700033430</td>\n",
       "      <td>-1.617676544985</td>\n",
       "      <td>-1.553188920242</td>\n",
       "      <td>-1.473251135405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 14:00:00</th>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>1.900341990851</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>1.838632294958</td>\n",
       "      <td>-0.227246209738</td>\n",
       "      <td>-0.369078385742</td>\n",
       "      <td>-0.293952666946</td>\n",
       "      <td>-0.174140098175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898729813998</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>-1.371145729561</td>\n",
       "      <td>-1.576700033430</td>\n",
       "      <td>-1.617676544985</td>\n",
       "      <td>-1.553188920242</td>\n",
       "      <td>-1.473251135405</td>\n",
       "      <td>-1.327482233642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 16:00:00</th>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>1.900341990851</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>1.838632294958</td>\n",
       "      <td>0.914848360427</td>\n",
       "      <td>-0.369078385742</td>\n",
       "      <td>-0.293952666946</td>\n",
       "      <td>-0.174140098175</td>\n",
       "      <td>-0.594455542132</td>\n",
       "      <td>...</td>\n",
       "      <td>1.184708465331</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>-1.576700033430</td>\n",
       "      <td>-1.617676544985</td>\n",
       "      <td>-1.553188920242</td>\n",
       "      <td>-1.473251135405</td>\n",
       "      <td>-1.327482233642</td>\n",
       "      <td>-1.279788261176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 18:00:00</th>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>1.900341990851</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>1.838632294958</td>\n",
       "      <td>0.914848360427</td>\n",
       "      <td>1.901723028575</td>\n",
       "      <td>-0.293952666946</td>\n",
       "      <td>-0.174140098175</td>\n",
       "      <td>-0.594455542132</td>\n",
       "      <td>-0.711677568875</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140039617486</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>-1.617676544985</td>\n",
       "      <td>-1.553188920242</td>\n",
       "      <td>-1.473251135405</td>\n",
       "      <td>-1.327482233642</td>\n",
       "      <td>-1.279788261176</td>\n",
       "      <td>-1.501464471230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 20:00:00</th>\n",
       "      <td>1.900341990851</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>1.838632294958</td>\n",
       "      <td>0.914848360427</td>\n",
       "      <td>1.901723028575</td>\n",
       "      <td>1.530091058838</td>\n",
       "      <td>-0.174140098175</td>\n",
       "      <td>-0.594455542132</td>\n",
       "      <td>-0.711677568875</td>\n",
       "      <td>-0.995341920882</td>\n",
       "      <td>...</td>\n",
       "      <td>1.594562830398</td>\n",
       "      <td>0.752289101100</td>\n",
       "      <td>1.762648655654</td>\n",
       "      <td>1.434304495819</td>\n",
       "      <td>-1.553188920242</td>\n",
       "      <td>-1.473251135405</td>\n",
       "      <td>-1.327482233642</td>\n",
       "      <td>-1.279788261176</td>\n",
       "      <td>-1.501464471230</td>\n",
       "      <td>-1.609615591892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15 12:00:00</th>\n",
       "      <td>-1.223763574538</td>\n",
       "      <td>-0.862262434602</td>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>0.433989642772</td>\n",
       "      <td>0.525953884748</td>\n",
       "      <td>0.593955612969</td>\n",
       "      <td>0.591365070941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954823356878</td>\n",
       "      <td>-1.123370332833</td>\n",
       "      <td>-1.092516692075</td>\n",
       "      <td>-1.294681799052</td>\n",
       "      <td>1.329273556551</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>1.248664025623</td>\n",
       "      <td>1.190893861790</td>\n",
       "      <td>1.189550369608</td>\n",
       "      <td>0.979965589193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15 14:00:00</th>\n",
       "      <td>-0.862262434602</td>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>0.525953884748</td>\n",
       "      <td>0.593955612969</td>\n",
       "      <td>0.591365070941</td>\n",
       "      <td>0.605613052092</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.123370332833</td>\n",
       "      <td>-1.092516692075</td>\n",
       "      <td>-1.294681799052</td>\n",
       "      <td>-1.223763574538</td>\n",
       "      <td>1.253366248260</td>\n",
       "      <td>1.248664025623</td>\n",
       "      <td>1.190893861790</td>\n",
       "      <td>1.189550369608</td>\n",
       "      <td>0.979965589193</td>\n",
       "      <td>0.995415749288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15 16:00:00</th>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>0.593955612969</td>\n",
       "      <td>0.591365070941</td>\n",
       "      <td>0.605613052092</td>\n",
       "      <td>0.815446956317</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092516692075</td>\n",
       "      <td>-1.294681799052</td>\n",
       "      <td>-1.223763574538</td>\n",
       "      <td>-0.862262434602</td>\n",
       "      <td>1.248664025623</td>\n",
       "      <td>1.190893861790</td>\n",
       "      <td>1.189550369608</td>\n",
       "      <td>0.979965589193</td>\n",
       "      <td>0.995415749288</td>\n",
       "      <td>0.890623359081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15 18:00:00</th>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>0.591365070941</td>\n",
       "      <td>0.605613052092</td>\n",
       "      <td>0.815446956317</td>\n",
       "      <td>0.839409470071</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.294681799052</td>\n",
       "      <td>-1.223763574538</td>\n",
       "      <td>-0.862262434602</td>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>1.190893861790</td>\n",
       "      <td>1.189550369608</td>\n",
       "      <td>0.979965589193</td>\n",
       "      <td>0.995415749288</td>\n",
       "      <td>0.890623359081</td>\n",
       "      <td>0.848975101434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15 20:00:00</th>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>0.605613052092</td>\n",
       "      <td>0.815446956317</td>\n",
       "      <td>0.839409470071</td>\n",
       "      <td>0.900287207716</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.223763574538</td>\n",
       "      <td>-0.862262434602</td>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>1.189550369608</td>\n",
       "      <td>0.979965589193</td>\n",
       "      <td>0.995415749288</td>\n",
       "      <td>0.890623359081</td>\n",
       "      <td>0.848975101434</td>\n",
       "      <td>0.756945886957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15 22:00:00</th>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>0.815446956317</td>\n",
       "      <td>0.839409470071</td>\n",
       "      <td>0.900287207716</td>\n",
       "      <td>0.869848338894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862262434602</td>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>0.979965589193</td>\n",
       "      <td>0.995415749288</td>\n",
       "      <td>0.890623359081</td>\n",
       "      <td>0.848975101434</td>\n",
       "      <td>0.756945886957</td>\n",
       "      <td>0.742839219045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 12:00:00</th>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>0.839409470071</td>\n",
       "      <td>0.900287207716</td>\n",
       "      <td>0.869848338894</td>\n",
       "      <td>0.851714544701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758645966530</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>0.995415749288</td>\n",
       "      <td>0.890623359081</td>\n",
       "      <td>0.848975101434</td>\n",
       "      <td>0.756945886957</td>\n",
       "      <td>0.742839219045</td>\n",
       "      <td>0.466079829523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 14:00:00</th>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>0.900287207716</td>\n",
       "      <td>0.869848338894</td>\n",
       "      <td>0.851714544701</td>\n",
       "      <td>0.886039226565</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034952524167</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>0.890623359081</td>\n",
       "      <td>0.848975101434</td>\n",
       "      <td>0.756945886957</td>\n",
       "      <td>0.742839219045</td>\n",
       "      <td>0.466079829523</td>\n",
       "      <td>0.494293165348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 16:00:00</th>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.869848338894</td>\n",
       "      <td>0.851714544701</td>\n",
       "      <td>0.886039226565</td>\n",
       "      <td>1.029166673583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944231376158</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>0.848975101434</td>\n",
       "      <td>0.756945886957</td>\n",
       "      <td>0.742839219045</td>\n",
       "      <td>0.466079829523</td>\n",
       "      <td>0.494293165348</td>\n",
       "      <td>0.408981411782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 18:00:00</th>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>0.851714544701</td>\n",
       "      <td>0.886039226565</td>\n",
       "      <td>1.029166673583</td>\n",
       "      <td>1.050538645309</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.171264821641</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>0.756945886957</td>\n",
       "      <td>0.742839219045</td>\n",
       "      <td>0.466079829523</td>\n",
       "      <td>0.494293165348</td>\n",
       "      <td>0.408981411782</td>\n",
       "      <td>0.365317915862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 20:00:00</th>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.886039226565</td>\n",
       "      <td>1.029166673583</td>\n",
       "      <td>1.050538645309</td>\n",
       "      <td>1.067377168488</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.072716182955</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>0.742839219045</td>\n",
       "      <td>0.466079829523</td>\n",
       "      <td>0.494293165348</td>\n",
       "      <td>0.408981411782</td>\n",
       "      <td>0.365317915862</td>\n",
       "      <td>0.253136318653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 22:00:00</th>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>1.029166673583</td>\n",
       "      <td>1.050538645309</td>\n",
       "      <td>1.067377168488</td>\n",
       "      <td>0.928135534512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.827263266077</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>0.466079829523</td>\n",
       "      <td>0.494293165348</td>\n",
       "      <td>0.408981411782</td>\n",
       "      <td>0.365317915862</td>\n",
       "      <td>0.253136318653</td>\n",
       "      <td>0.194022662638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17 12:00:00</th>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>1.050538645309</td>\n",
       "      <td>1.067377168488</td>\n",
       "      <td>0.928135534512</td>\n",
       "      <td>0.877619964976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396224939570</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>0.494293165348</td>\n",
       "      <td>0.408981411782</td>\n",
       "      <td>0.365317915862</td>\n",
       "      <td>0.253136318653</td>\n",
       "      <td>0.194022662638</td>\n",
       "      <td>-0.125056730621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17 14:00:00</th>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>1.067377168488</td>\n",
       "      <td>0.928135534512</td>\n",
       "      <td>0.877619964976</td>\n",
       "      <td>0.924249721471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766937022283</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>0.408981411782</td>\n",
       "      <td>0.365317915862</td>\n",
       "      <td>0.253136318653</td>\n",
       "      <td>0.194022662638</td>\n",
       "      <td>-0.125056730621</td>\n",
       "      <td>-0.086095457339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17 16:00:00</th>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.928135534512</td>\n",
       "      <td>0.877619964976</td>\n",
       "      <td>0.924249721471</td>\n",
       "      <td>0.995489627226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544968991810</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.365317915862</td>\n",
       "      <td>0.253136318653</td>\n",
       "      <td>0.194022662638</td>\n",
       "      <td>-0.125056730621</td>\n",
       "      <td>-0.086095457339</td>\n",
       "      <td>-0.106247840071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17 18:00:00</th>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.877619964976</td>\n",
       "      <td>0.924249721471</td>\n",
       "      <td>0.995489627226</td>\n",
       "      <td>1.035643028652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.826802115377</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>0.253136318653</td>\n",
       "      <td>0.194022662638</td>\n",
       "      <td>-0.125056730621</td>\n",
       "      <td>-0.086095457339</td>\n",
       "      <td>-0.106247840071</td>\n",
       "      <td>-0.116324031437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17 20:00:00</th>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.924249721471</td>\n",
       "      <td>0.995489627226</td>\n",
       "      <td>1.035643028652</td>\n",
       "      <td>1.014271056925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675293572874</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.194022662638</td>\n",
       "      <td>-0.125056730621</td>\n",
       "      <td>-0.086095457339</td>\n",
       "      <td>-0.106247840071</td>\n",
       "      <td>-0.116324031437</td>\n",
       "      <td>-0.225818644282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17 22:00:00</th>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.995489627226</td>\n",
       "      <td>1.035643028652</td>\n",
       "      <td>1.014271056925</td>\n",
       "      <td>0.788246265029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645820969839</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.125056730621</td>\n",
       "      <td>-0.086095457339</td>\n",
       "      <td>-0.106247840071</td>\n",
       "      <td>-0.116324031437</td>\n",
       "      <td>-0.225818644282</td>\n",
       "      <td>-0.348076432858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18 12:00:00</th>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>1.035643028652</td>\n",
       "      <td>1.014271056925</td>\n",
       "      <td>0.788246265029</td>\n",
       "      <td>0.697577294067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049548481266</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.086095457339</td>\n",
       "      <td>-0.106247840071</td>\n",
       "      <td>-0.116324031437</td>\n",
       "      <td>-0.225818644282</td>\n",
       "      <td>-0.348076432858</td>\n",
       "      <td>-0.681934240121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18 14:00:00</th>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>1.014271056925</td>\n",
       "      <td>0.788246265029</td>\n",
       "      <td>0.697577294067</td>\n",
       "      <td>0.737083059986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380106393141</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.106247840071</td>\n",
       "      <td>-0.116324031437</td>\n",
       "      <td>-0.225818644282</td>\n",
       "      <td>-0.348076432858</td>\n",
       "      <td>-0.681934240121</td>\n",
       "      <td>-0.646331697294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18 16:00:00</th>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.788246265029</td>\n",
       "      <td>0.697577294067</td>\n",
       "      <td>0.737083059986</td>\n",
       "      <td>0.726073256369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005340784121</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>-0.116324031437</td>\n",
       "      <td>-0.225818644282</td>\n",
       "      <td>-0.348076432858</td>\n",
       "      <td>-0.681934240121</td>\n",
       "      <td>-0.646331697294</td>\n",
       "      <td>-0.573111373367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18 18:00:00</th>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.697577294067</td>\n",
       "      <td>0.737083059986</td>\n",
       "      <td>0.726073256369</td>\n",
       "      <td>0.797960797632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311030357270</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>-0.225818644282</td>\n",
       "      <td>-0.348076432858</td>\n",
       "      <td>-0.681934240121</td>\n",
       "      <td>-0.646331697294</td>\n",
       "      <td>-0.573111373367</td>\n",
       "      <td>-0.524073908719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18 20:00:00</th>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>0.737083059986</td>\n",
       "      <td>0.726073256369</td>\n",
       "      <td>0.797960797632</td>\n",
       "      <td>0.762340844754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108406514189</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>-0.348076432858</td>\n",
       "      <td>-0.681934240121</td>\n",
       "      <td>-0.646331697294</td>\n",
       "      <td>-0.573111373367</td>\n",
       "      <td>-0.524073908719</td>\n",
       "      <td>-0.608713916194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-18 22:00:00</th>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>0.726073256369</td>\n",
       "      <td>0.797960797632</td>\n",
       "      <td>0.762340844754</td>\n",
       "      <td>0.492924473897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341425261705</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>-0.681934240121</td>\n",
       "      <td>-0.646331697294</td>\n",
       "      <td>-0.573111373367</td>\n",
       "      <td>-0.524073908719</td>\n",
       "      <td>-0.608713916194</td>\n",
       "      <td>-0.790085360783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19 12:00:00</th>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>0.855903154796</td>\n",
       "      <td>0.797960797632</td>\n",
       "      <td>0.762340844754</td>\n",
       "      <td>0.492924473897</td>\n",
       "      <td>0.366635550058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501309618293</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>-0.646331697294</td>\n",
       "      <td>-0.573111373367</td>\n",
       "      <td>-0.524073908719</td>\n",
       "      <td>-0.608713916194</td>\n",
       "      <td>-0.790085360783</td>\n",
       "      <td>-1.105806023588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19 14:00:00</th>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>0.855903154796</td>\n",
       "      <td>1.069118978596</td>\n",
       "      <td>0.762340844754</td>\n",
       "      <td>0.492924473897</td>\n",
       "      <td>0.366635550058</td>\n",
       "      <td>0.375054811648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062904952029</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>-0.573111373367</td>\n",
       "      <td>-0.524073908719</td>\n",
       "      <td>-0.608713916194</td>\n",
       "      <td>-0.790085360783</td>\n",
       "      <td>-1.105806023588</td>\n",
       "      <td>-1.093042847857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19 16:00:00</th>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>0.855903154796</td>\n",
       "      <td>1.069118978596</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>0.492924473897</td>\n",
       "      <td>0.366635550058</td>\n",
       "      <td>0.375054811648</td>\n",
       "      <td>0.274023672576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581438785582</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>-0.524073908719</td>\n",
       "      <td>-0.608713916194</td>\n",
       "      <td>-0.790085360783</td>\n",
       "      <td>-1.105806023588</td>\n",
       "      <td>-1.093042847857</td>\n",
       "      <td>-0.923762832907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19 18:00:00</th>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>0.855903154796</td>\n",
       "      <td>1.069118978596</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>0.366635550058</td>\n",
       "      <td>0.375054811648</td>\n",
       "      <td>0.274023672576</td>\n",
       "      <td>0.380883531209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282106078082</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>-0.608713916194</td>\n",
       "      <td>-0.790085360783</td>\n",
       "      <td>-1.105806023588</td>\n",
       "      <td>-1.093042847857</td>\n",
       "      <td>-0.923762832907</td>\n",
       "      <td>-0.808222505242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19 20:00:00</th>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>0.855903154796</td>\n",
       "      <td>1.069118978596</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>0.867876173239</td>\n",
       "      <td>0.375054811648</td>\n",
       "      <td>0.274023672576</td>\n",
       "      <td>0.380883531209</td>\n",
       "      <td>0.360159194990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510520561288</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>-0.790085360783</td>\n",
       "      <td>-1.105806023588</td>\n",
       "      <td>-1.093042847857</td>\n",
       "      <td>-0.923762832907</td>\n",
       "      <td>-0.808222505242</td>\n",
       "      <td>-0.847855524616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-19 22:00:00</th>\n",
       "      <td>0.855903154796</td>\n",
       "      <td>1.069118978596</td>\n",
       "      <td>0.409668583260</td>\n",
       "      <td>1.169512220301</td>\n",
       "      <td>0.867876173239</td>\n",
       "      <td>1.436146684243</td>\n",
       "      <td>0.274023672576</td>\n",
       "      <td>0.380883531209</td>\n",
       "      <td>0.360159194990</td>\n",
       "      <td>0.098514450216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028366933984</td>\n",
       "      <td>0.887679096954</td>\n",
       "      <td>0.493940864159</td>\n",
       "      <td>1.085698675945</td>\n",
       "      <td>-1.105806023588</td>\n",
       "      <td>-1.093042847857</td>\n",
       "      <td>-0.923762832907</td>\n",
       "      <td>-0.808222505242</td>\n",
       "      <td>-0.847855524616</td>\n",
       "      <td>-1.064157765941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                       target                                  \\\n",
       "feature                           y                                   \n",
       "time step                       t+1             t+2             t+3   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 22:00:00 -0.675754723574 -1.426387417839 -1.576512508022   \n",
       "2017-11-03 12:00:00 -1.426387417839 -1.576512508022 -1.708220541186   \n",
       "2017-11-03 14:00:00 -1.576512508022 -1.708220541186 -1.398295852747   \n",
       "2017-11-03 16:00:00 -1.708220541186 -1.398295852747 -0.986138148336   \n",
       "2017-11-03 18:00:00 -1.398295852747 -0.986138148336 -0.156759739101   \n",
       "2017-11-03 20:00:00 -0.986138148336 -0.156759739101 -0.777987739546   \n",
       "2017-11-03 22:00:00 -0.156759739101 -0.777987739546 -0.999953355422   \n",
       "2017-11-04 12:00:00 -0.777987739546 -0.999953355422 -1.044163467163   \n",
       "2017-11-04 14:00:00 -0.999953355422 -1.044163467163 -0.788579720265   \n",
       "2017-11-04 16:00:00 -1.044163467163 -0.788579720265 -0.544049104567   \n",
       "2017-11-04 18:00:00 -0.788579720265 -0.544049104567  0.409668583260   \n",
       "2017-11-04 20:00:00 -0.544049104567  0.409668583260  0.106651498474   \n",
       "2017-11-04 22:00:00  0.409668583260  0.106651498474 -0.297215150184   \n",
       "2017-11-05 12:00:00  0.106651498474 -0.297215150184 -0.005251196818   \n",
       "2017-11-05 14:00:00 -0.297215150184 -0.005251196818  0.068429103362   \n",
       "2017-11-05 16:00:00 -0.005251196818  0.068429103362  0.259541078700   \n",
       "2017-11-05 18:00:00  0.068429103362  0.259541078700  0.873863889868   \n",
       "2017-11-05 20:00:00  0.259541078700  0.873863889868  0.972412528554   \n",
       "2017-11-05 22:00:00  0.873863889868  0.972412528554  0.331381604613   \n",
       "2017-11-06 12:00:00  0.972412528554  0.331381604613  1.056226072910   \n",
       "2017-11-06 14:00:00  0.331381604613  1.056226072910  0.898729813998   \n",
       "2017-11-06 16:00:00  1.056226072910  0.898729813998  1.184708465331   \n",
       "2017-11-06 18:00:00  0.898729813998  1.184708465331  1.140039617486   \n",
       "2017-11-06 20:00:00  1.184708465331  1.140039617486  1.594562830398   \n",
       "2017-11-06 22:00:00  1.140039617486  1.594562830398  0.752289101100   \n",
       "2017-11-07 12:00:00  1.594562830398  0.752289101100  1.762648655654   \n",
       "2017-11-07 14:00:00  0.752289101100  1.762648655654  1.434304495819   \n",
       "2017-11-07 16:00:00  1.762648655654  1.434304495819  1.900341990851   \n",
       "2017-11-07 18:00:00  1.434304495819  1.900341990851  1.169512220301   \n",
       "2017-11-07 20:00:00  1.900341990851  1.169512220301  1.838632294958   \n",
       "...                             ...             ...             ...   \n",
       "2017-11-15 12:00:00 -1.223763574538 -0.862262434602 -0.758645966530   \n",
       "2017-11-15 14:00:00 -0.862262434602 -0.758645966530 -1.034952524167   \n",
       "2017-11-15 16:00:00 -0.758645966530 -1.034952524167 -0.944231376158   \n",
       "2017-11-15 18:00:00 -1.034952524167 -0.944231376158 -1.171264821641   \n",
       "2017-11-15 20:00:00 -0.944231376158 -1.171264821641 -1.072716182955   \n",
       "2017-11-15 22:00:00 -1.171264821641 -1.072716182955 -0.827263266077   \n",
       "2017-11-16 12:00:00 -1.072716182955 -0.827263266077 -0.396224939570   \n",
       "2017-11-16 14:00:00 -0.827263266077 -0.396224939570 -0.766937022283   \n",
       "2017-11-16 16:00:00 -0.396224939570 -0.766937022283 -0.544968991810   \n",
       "2017-11-16 18:00:00 -0.766937022283 -0.544968991810 -0.826802115377   \n",
       "2017-11-16 20:00:00 -0.544968991810 -0.826802115377 -0.675293572874   \n",
       "2017-11-16 22:00:00 -0.826802115377 -0.675293572874 -0.645820969839   \n",
       "2017-11-17 12:00:00 -0.675293572874 -0.645820969839  0.049548481266   \n",
       "2017-11-17 14:00:00 -0.645820969839  0.049548481266 -0.380106393141   \n",
       "2017-11-17 16:00:00  0.049548481266 -0.380106393141  0.005340784121   \n",
       "2017-11-17 18:00:00 -0.380106393141  0.005340784121 -0.311030357270   \n",
       "2017-11-17 20:00:00  0.005340784121 -0.311030357270 -0.108406514189   \n",
       "2017-11-17 22:00:00 -0.311030357270 -0.108406514189 -0.341425261705   \n",
       "2017-11-18 12:00:00 -0.108406514189 -0.341425261705  0.501309618293   \n",
       "2017-11-18 14:00:00 -0.341425261705  0.501309618293  0.062904952029   \n",
       "2017-11-18 16:00:00  0.501309618293  0.062904952029  0.581438785582   \n",
       "2017-11-18 18:00:00  0.062904952029  0.581438785582  0.282106078082   \n",
       "2017-11-18 20:00:00  0.581438785582  0.282106078082  0.510520561288   \n",
       "2017-11-18 22:00:00  0.282106078082  0.510520561288  0.028366933984   \n",
       "2017-11-19 12:00:00  0.510520561288  0.028366933984  0.887679096954   \n",
       "2017-11-19 14:00:00  0.028366933984  0.887679096954  0.493940864159   \n",
       "2017-11-19 16:00:00  0.887679096954  0.493940864159  1.085698675945   \n",
       "2017-11-19 18:00:00  0.493940864159  1.085698675945  0.855903154796   \n",
       "2017-11-19 20:00:00  1.085698675945  0.855903154796  1.069118978596   \n",
       "2017-11-19 22:00:00  0.855903154796  1.069118978596  0.409668583260   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                       t+4             t+5             t+6   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 22:00:00 -1.708220541186 -1.398295852747 -0.986138148336   \n",
       "2017-11-03 12:00:00 -1.398295852747 -0.986138148336 -0.156759739101   \n",
       "2017-11-03 14:00:00 -0.986138148336 -0.156759739101 -0.777987739546   \n",
       "2017-11-03 16:00:00 -0.156759739101 -0.777987739546 -0.999953355422   \n",
       "2017-11-03 18:00:00 -0.777987739546 -0.999953355422 -1.044163467163   \n",
       "2017-11-03 20:00:00 -0.999953355422 -1.044163467163 -0.788579720265   \n",
       "2017-11-03 22:00:00 -1.044163467163 -0.788579720265 -0.544049104567   \n",
       "2017-11-04 12:00:00 -0.788579720265 -0.544049104567  0.409668583260   \n",
       "2017-11-04 14:00:00 -0.544049104567  0.409668583260  0.106651498474   \n",
       "2017-11-04 16:00:00  0.409668583260  0.106651498474 -0.297215150184   \n",
       "2017-11-04 18:00:00  0.106651498474 -0.297215150184 -0.005251196818   \n",
       "2017-11-04 20:00:00 -0.297215150184 -0.005251196818  0.068429103362   \n",
       "2017-11-04 22:00:00 -0.005251196818  0.068429103362  0.259541078700   \n",
       "2017-11-05 12:00:00  0.068429103362  0.259541078700  0.873863889868   \n",
       "2017-11-05 14:00:00  0.259541078700  0.873863889868  0.972412528554   \n",
       "2017-11-05 16:00:00  0.873863889868  0.972412528554  0.331381604613   \n",
       "2017-11-05 18:00:00  0.972412528554  0.331381604613  1.056226072910   \n",
       "2017-11-05 20:00:00  0.331381604613  1.056226072910  0.898729813998   \n",
       "2017-11-05 22:00:00  1.056226072910  0.898729813998  1.184708465331   \n",
       "2017-11-06 12:00:00  0.898729813998  1.184708465331  1.140039617486   \n",
       "2017-11-06 14:00:00  1.184708465331  1.140039617486  1.594562830398   \n",
       "2017-11-06 16:00:00  1.140039617486  1.594562830398  0.752289101100   \n",
       "2017-11-06 18:00:00  1.594562830398  0.752289101100  1.762648655654   \n",
       "2017-11-06 20:00:00  0.752289101100  1.762648655654  1.434304495819   \n",
       "2017-11-06 22:00:00  1.762648655654  1.434304495819  1.900341990851   \n",
       "2017-11-07 12:00:00  1.434304495819  1.900341990851  1.169512220301   \n",
       "2017-11-07 14:00:00  1.900341990851  1.169512220301  1.838632294958   \n",
       "2017-11-07 16:00:00  1.169512220301  1.838632294958  0.914848360427   \n",
       "2017-11-07 18:00:00  1.838632294958  0.914848360427  1.901723028575   \n",
       "2017-11-07 20:00:00  0.914848360427  1.901723028575  1.530091058838   \n",
       "...                             ...             ...             ...   \n",
       "2017-11-15 12:00:00 -1.034952524167 -0.944231376158 -1.171264821641   \n",
       "2017-11-15 14:00:00 -0.944231376158 -1.171264821641 -1.072716182955   \n",
       "2017-11-15 16:00:00 -1.171264821641 -1.072716182955 -0.827263266077   \n",
       "2017-11-15 18:00:00 -1.072716182955 -0.827263266077 -0.396224939570   \n",
       "2017-11-15 20:00:00 -0.827263266077 -0.396224939570 -0.766937022283   \n",
       "2017-11-15 22:00:00 -0.396224939570 -0.766937022283 -0.544968991810   \n",
       "2017-11-16 12:00:00 -0.766937022283 -0.544968991810 -0.826802115377   \n",
       "2017-11-16 14:00:00 -0.544968991810 -0.826802115377 -0.675293572874   \n",
       "2017-11-16 16:00:00 -0.826802115377 -0.675293572874 -0.645820969839   \n",
       "2017-11-16 18:00:00 -0.675293572874 -0.645820969839  0.049548481266   \n",
       "2017-11-16 20:00:00 -0.645820969839  0.049548481266 -0.380106393141   \n",
       "2017-11-16 22:00:00  0.049548481266 -0.380106393141  0.005340784121   \n",
       "2017-11-17 12:00:00 -0.380106393141  0.005340784121 -0.311030357270   \n",
       "2017-11-17 14:00:00  0.005340784121 -0.311030357270 -0.108406514189   \n",
       "2017-11-17 16:00:00 -0.311030357270 -0.108406514189 -0.341425261705   \n",
       "2017-11-17 18:00:00 -0.108406514189 -0.341425261705  0.501309618293   \n",
       "2017-11-17 20:00:00 -0.341425261705  0.501309618293  0.062904952029   \n",
       "2017-11-17 22:00:00  0.501309618293  0.062904952029  0.581438785582   \n",
       "2017-11-18 12:00:00  0.062904952029  0.581438785582  0.282106078082   \n",
       "2017-11-18 14:00:00  0.581438785582  0.282106078082  0.510520561288   \n",
       "2017-11-18 16:00:00  0.282106078082  0.510520561288  0.028366933984   \n",
       "2017-11-18 18:00:00  0.510520561288  0.028366933984  0.887679096954   \n",
       "2017-11-18 20:00:00  0.028366933984  0.887679096954  0.493940864159   \n",
       "2017-11-18 22:00:00  0.887679096954  0.493940864159  1.085698675945   \n",
       "2017-11-19 12:00:00  0.493940864159  1.085698675945  0.855903154796   \n",
       "2017-11-19 14:00:00  1.085698675945  0.855903154796  1.069118978596   \n",
       "2017-11-19 16:00:00  0.855903154796  1.069118978596  0.409668583260   \n",
       "2017-11-19 18:00:00  1.069118978596  0.409668583260  1.169512220301   \n",
       "2017-11-19 20:00:00  0.409668583260  1.169512220301  0.867876173239   \n",
       "2017-11-19 22:00:00  1.169512220301  0.867876173239  1.436146684243   \n",
       "\n",
       "tensor                            X                                  \\\n",
       "feature                         Crs                                   \n",
       "time step                       t-5             t-4             t-3   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 22:00:00  0.974765291006  1.110121111941  1.053776822844   \n",
       "2017-11-03 12:00:00  1.110121111941  1.053776822844  1.010385243884   \n",
       "2017-11-03 14:00:00  1.053776822844  1.010385243884  0.943678786676   \n",
       "2017-11-03 16:00:00  1.010385243884  0.943678786676  1.125016728599   \n",
       "2017-11-03 18:00:00  0.943678786676  1.125016728599  1.256486736493   \n",
       "2017-11-03 20:00:00  1.125016728599  1.256486736493  1.351041520496   \n",
       "2017-11-03 22:00:00  1.256486736493  1.351041520496  1.302468857481   \n",
       "2017-11-04 12:00:00  1.351041520496  1.302468857481  1.306354670522   \n",
       "2017-11-04 14:00:00  1.302468857481  1.306354670522  1.249362745918   \n",
       "2017-11-04 16:00:00  1.306354670522  1.249362745918  1.366584772660   \n",
       "2017-11-04 18:00:00  1.249362745918  1.366584772660  1.198847176382   \n",
       "2017-11-04 20:00:00  1.366584772660  1.198847176382  1.208561708985   \n",
       "2017-11-04 22:00:00  1.198847176382  1.208561708985  1.127607270627   \n",
       "2017-11-05 12:00:00  1.208561708985  1.127607270627  1.151569784381   \n",
       "2017-11-05 14:00:00  1.127607270627  1.151569784381  1.145093429312   \n",
       "2017-11-05 16:00:00  1.151569784381  1.145093429312  1.214390428547   \n",
       "2017-11-05 18:00:00  1.145093429312  1.214390428547  0.789541536042   \n",
       "2017-11-05 20:00:00  1.214390428547  0.789541536042  0.712472910725   \n",
       "2017-11-05 22:00:00  0.789541536042  0.712472910725  0.560278566611   \n",
       "2017-11-06 12:00:00  0.712472910725  0.560278566611  0.532430239816   \n",
       "2017-11-06 14:00:00  0.560278566611  0.532430239816  0.583593444859   \n",
       "2017-11-06 16:00:00  0.532430239816  0.583593444859  0.653538079600   \n",
       "2017-11-06 18:00:00  0.583593444859  0.653538079600  0.130896225559   \n",
       "2017-11-06 20:00:00  0.653538079600  0.130896225559  0.005254937227   \n",
       "2017-11-06 22:00:00  0.130896225559  0.005254937227 -0.227246209738   \n",
       "2017-11-07 12:00:00  0.005254937227 -0.227246209738 -0.369078385742   \n",
       "2017-11-07 14:00:00 -0.227246209738 -0.369078385742 -0.293952666946   \n",
       "2017-11-07 16:00:00 -0.369078385742 -0.293952666946 -0.174140098175   \n",
       "2017-11-07 18:00:00 -0.293952666946 -0.174140098175 -0.594455542132   \n",
       "2017-11-07 20:00:00 -0.174140098175 -0.594455542132 -0.711677568875   \n",
       "...                             ...             ...             ...   \n",
       "2017-11-15 12:00:00  0.433989642772  0.525953884748  0.593955612969   \n",
       "2017-11-15 14:00:00  0.525953884748  0.593955612969  0.591365070941   \n",
       "2017-11-15 16:00:00  0.593955612969  0.591365070941  0.605613052092   \n",
       "2017-11-15 18:00:00  0.591365070941  0.605613052092  0.815446956317   \n",
       "2017-11-15 20:00:00  0.605613052092  0.815446956317  0.839409470071   \n",
       "2017-11-15 22:00:00  0.815446956317  0.839409470071  0.900287207716   \n",
       "2017-11-16 12:00:00  0.839409470071  0.900287207716  0.869848338894   \n",
       "2017-11-16 14:00:00  0.900287207716  0.869848338894  0.851714544701   \n",
       "2017-11-16 16:00:00  0.869848338894  0.851714544701  0.886039226565   \n",
       "2017-11-16 18:00:00  0.851714544701  0.886039226565  1.029166673583   \n",
       "2017-11-16 20:00:00  0.886039226565  1.029166673583  1.050538645309   \n",
       "2017-11-16 22:00:00  1.029166673583  1.050538645309  1.067377168488   \n",
       "2017-11-17 12:00:00  1.050538645309  1.067377168488  0.928135534512   \n",
       "2017-11-17 14:00:00  1.067377168488  0.928135534512  0.877619964976   \n",
       "2017-11-17 16:00:00  0.928135534512  0.877619964976  0.924249721471   \n",
       "2017-11-17 18:00:00  0.877619964976  0.924249721471  0.995489627226   \n",
       "2017-11-17 20:00:00  0.924249721471  0.995489627226  1.035643028652   \n",
       "2017-11-17 22:00:00  0.995489627226  1.035643028652  1.014271056925   \n",
       "2017-11-18 12:00:00  1.035643028652  1.014271056925  0.788246265029   \n",
       "2017-11-18 14:00:00  1.014271056925  0.788246265029  0.697577294067   \n",
       "2017-11-18 16:00:00  0.788246265029  0.697577294067  0.737083059986   \n",
       "2017-11-18 18:00:00  0.697577294067  0.737083059986  0.726073256369   \n",
       "2017-11-18 20:00:00  0.737083059986  0.726073256369  0.797960797632   \n",
       "2017-11-18 22:00:00  0.726073256369  0.797960797632  0.762340844754   \n",
       "2017-11-19 12:00:00  0.797960797632  0.762340844754  0.492924473897   \n",
       "2017-11-19 14:00:00  0.762340844754  0.492924473897  0.366635550058   \n",
       "2017-11-19 16:00:00  0.492924473897  0.366635550058  0.375054811648   \n",
       "2017-11-19 18:00:00  0.366635550058  0.375054811648  0.274023672576   \n",
       "2017-11-19 20:00:00  0.375054811648  0.274023672576  0.380883531209   \n",
       "2017-11-19 22:00:00  0.274023672576  0.380883531209  0.360159194990   \n",
       "\n",
       "tensor                               ...                                  \\\n",
       "feature                              ...          sqrt_A                   \n",
       "time step                       t-2  ...             t-3             t-2   \n",
       "Epoch_Time_of_Clock                  ...                                   \n",
       "2017-11-02 22:00:00  1.010385243884  ... -1.839926159973 -1.846833763407   \n",
       "2017-11-03 12:00:00  0.943678786676  ... -1.846833763407 -1.608749600881   \n",
       "2017-11-03 14:00:00  1.125016728599  ... -1.608749600881 -1.011928788461   \n",
       "2017-11-03 16:00:00  1.256486736493  ... -1.011928788461 -0.675754723574   \n",
       "2017-11-03 18:00:00  1.351041520496  ... -0.675754723574 -1.426387417839   \n",
       "2017-11-03 20:00:00  1.302468857481  ... -1.426387417839 -1.576512508022   \n",
       "2017-11-03 22:00:00  1.306354670522  ... -1.576512508022 -1.708220541186   \n",
       "2017-11-04 12:00:00  1.249362745918  ... -1.708220541186 -1.398295852747   \n",
       "2017-11-04 14:00:00  1.366584772660  ... -1.398295852747 -0.986138148336   \n",
       "2017-11-04 16:00:00  1.198847176382  ... -0.986138148336 -0.156759739101   \n",
       "2017-11-04 18:00:00  1.208561708985  ... -0.156759739101 -0.777987739546   \n",
       "2017-11-04 20:00:00  1.127607270627  ... -0.777987739546 -0.999953355422   \n",
       "2017-11-04 22:00:00  1.151569784381  ... -0.999953355422 -1.044163467163   \n",
       "2017-11-05 12:00:00  1.145093429312  ... -1.044163467163 -0.788579720265   \n",
       "2017-11-05 14:00:00  1.214390428547  ... -0.788579720265 -0.544049104567   \n",
       "2017-11-05 16:00:00  0.789541536042  ... -0.544049104567  0.409668583260   \n",
       "2017-11-05 18:00:00  0.712472910725  ...  0.409668583260  0.106651498474   \n",
       "2017-11-05 20:00:00  0.560278566611  ...  0.106651498474 -0.297215150184   \n",
       "2017-11-05 22:00:00  0.532430239816  ... -0.297215150184 -0.005251196818   \n",
       "2017-11-06 12:00:00  0.583593444859  ... -0.005251196818  0.068429103362   \n",
       "2017-11-06 14:00:00  0.653538079600  ...  0.068429103362  0.259541078700   \n",
       "2017-11-06 16:00:00  0.130896225559  ...  0.259541078700  0.873863889868   \n",
       "2017-11-06 18:00:00  0.005254937227  ...  0.873863889868  0.972412528554   \n",
       "2017-11-06 20:00:00 -0.227246209738  ...  0.972412528554  0.331381604613   \n",
       "2017-11-06 22:00:00 -0.369078385742  ...  0.331381604613  1.056226072910   \n",
       "2017-11-07 12:00:00 -0.293952666946  ...  1.056226072910  0.898729813998   \n",
       "2017-11-07 14:00:00 -0.174140098175  ...  0.898729813998  1.184708465331   \n",
       "2017-11-07 16:00:00 -0.594455542132  ...  1.184708465331  1.140039617486   \n",
       "2017-11-07 18:00:00 -0.711677568875  ...  1.140039617486  1.594562830398   \n",
       "2017-11-07 20:00:00 -0.995341920882  ...  1.594562830398  0.752289101100   \n",
       "...                             ...  ...             ...             ...   \n",
       "2017-11-15 12:00:00  0.591365070941  ... -0.954823356878 -1.123370332833   \n",
       "2017-11-15 14:00:00  0.605613052092  ... -1.123370332833 -1.092516692075   \n",
       "2017-11-15 16:00:00  0.815446956317  ... -1.092516692075 -1.294681799052   \n",
       "2017-11-15 18:00:00  0.839409470071  ... -1.294681799052 -1.223763574538   \n",
       "2017-11-15 20:00:00  0.900287207716  ... -1.223763574538 -0.862262434602   \n",
       "2017-11-15 22:00:00  0.869848338894  ... -0.862262434602 -0.758645966530   \n",
       "2017-11-16 12:00:00  0.851714544701  ... -0.758645966530 -1.034952524167   \n",
       "2017-11-16 14:00:00  0.886039226565  ... -1.034952524167 -0.944231376158   \n",
       "2017-11-16 16:00:00  1.029166673583  ... -0.944231376158 -1.171264821641   \n",
       "2017-11-16 18:00:00  1.050538645309  ... -1.171264821641 -1.072716182955   \n",
       "2017-11-16 20:00:00  1.067377168488  ... -1.072716182955 -0.827263266077   \n",
       "2017-11-16 22:00:00  0.928135534512  ... -0.827263266077 -0.396224939570   \n",
       "2017-11-17 12:00:00  0.877619964976  ... -0.396224939570 -0.766937022283   \n",
       "2017-11-17 14:00:00  0.924249721471  ... -0.766937022283 -0.544968991810   \n",
       "2017-11-17 16:00:00  0.995489627226  ... -0.544968991810 -0.826802115377   \n",
       "2017-11-17 18:00:00  1.035643028652  ... -0.826802115377 -0.675293572874   \n",
       "2017-11-17 20:00:00  1.014271056925  ... -0.675293572874 -0.645820969839   \n",
       "2017-11-17 22:00:00  0.788246265029  ... -0.645820969839  0.049548481266   \n",
       "2017-11-18 12:00:00  0.697577294067  ...  0.049548481266 -0.380106393141   \n",
       "2017-11-18 14:00:00  0.737083059986  ... -0.380106393141  0.005340784121   \n",
       "2017-11-18 16:00:00  0.726073256369  ...  0.005340784121 -0.311030357270   \n",
       "2017-11-18 18:00:00  0.797960797632  ... -0.311030357270 -0.108406514189   \n",
       "2017-11-18 20:00:00  0.762340844754  ... -0.108406514189 -0.341425261705   \n",
       "2017-11-18 22:00:00  0.492924473897  ... -0.341425261705  0.501309618293   \n",
       "2017-11-19 12:00:00  0.366635550058  ...  0.501309618293  0.062904952029   \n",
       "2017-11-19 14:00:00  0.375054811648  ...  0.062904952029  0.581438785582   \n",
       "2017-11-19 16:00:00  0.274023672576  ...  0.581438785582  0.282106078082   \n",
       "2017-11-19 18:00:00  0.380883531209  ...  0.282106078082  0.510520561288   \n",
       "2017-11-19 20:00:00  0.360159194990  ...  0.510520561288  0.028366933984   \n",
       "2017-11-19 22:00:00  0.098514450216  ...  0.028366933984  0.887679096954   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                         Crc   \n",
       "time step                       t-1               t             t-5   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 22:00:00 -1.608749600881 -1.011928788461  1.413241817935   \n",
       "2017-11-03 12:00:00 -1.011928788461 -0.675754723574  1.233213865528   \n",
       "2017-11-03 14:00:00 -0.675754723574 -1.426387417839  1.252022756078   \n",
       "2017-11-03 16:00:00 -1.426387417839 -1.576512508022  1.282251330176   \n",
       "2017-11-03 18:00:00 -1.576512508022 -1.708220541186  1.334647525280   \n",
       "2017-11-03 20:00:00 -1.708220541186 -1.398295852747  1.253366248260   \n",
       "2017-11-03 22:00:00 -1.398295852747 -0.986138148336  0.752243664320   \n",
       "2017-11-04 12:00:00 -0.986138148336 -0.156759739101  0.518476024626   \n",
       "2017-11-04 14:00:00 -0.156759739101 -0.777987739546  0.507056341078   \n",
       "2017-11-04 16:00:00 -0.777987739546 -0.999953355422  0.560124282273   \n",
       "2017-11-04 18:00:00 -0.999953355422 -1.044163467163  0.647451274112   \n",
       "2017-11-04 20:00:00 -1.044163467163 -0.788579720265  0.570872219730   \n",
       "2017-11-04 22:00:00 -0.788579720265 -0.544049104567 -0.072660535518   \n",
       "2017-11-05 12:00:00 -0.544049104567  0.409668583260 -0.290306269025   \n",
       "2017-11-05 14:00:00  0.409668583260  0.106651498474 -0.340015479765   \n",
       "2017-11-05 16:00:00  0.106651498474 -0.297215150184 -0.341358971947   \n",
       "2017-11-05 18:00:00 -0.297215150184 -0.005251196818 -0.252688487925   \n",
       "2017-11-05 20:00:00 -0.005251196818  0.068429103362 -0.280230077659   \n",
       "2017-11-05 22:00:00  0.068429103362  0.259541078700 -0.847183778525   \n",
       "2017-11-06 12:00:00  0.259541078700  0.873863889868 -0.972800297555   \n",
       "2017-11-06 14:00:00  0.873863889868  0.972412528554 -1.033929191843   \n",
       "2017-11-06 16:00:00  0.972412528554  0.331381604613 -1.144767296870   \n",
       "2017-11-06 18:00:00  0.331381604613  1.056226072910 -1.105134277497   \n",
       "2017-11-06 20:00:00  1.056226072910  0.898729813998 -1.070875226852   \n",
       "2017-11-06 22:00:00  0.898729813998  1.184708465331 -1.357710807740   \n",
       "2017-11-07 12:00:00  1.184708465331  1.140039617486 -1.344947632010   \n",
       "2017-11-07 14:00:00  1.140039617486  1.594562830398 -1.371145729561   \n",
       "2017-11-07 16:00:00  1.594562830398  0.752289101100 -1.576700033430   \n",
       "2017-11-07 18:00:00  0.752289101100  1.762648655654 -1.617676544985   \n",
       "2017-11-07 20:00:00  1.762648655654  1.434304495819 -1.553188920242   \n",
       "...                             ...             ...             ...   \n",
       "2017-11-15 12:00:00 -1.092516692075 -1.294681799052  1.329273556551   \n",
       "2017-11-15 14:00:00 -1.294681799052 -1.223763574538  1.253366248260   \n",
       "2017-11-15 16:00:00 -1.223763574538 -0.862262434602  1.248664025623   \n",
       "2017-11-15 18:00:00 -0.862262434602 -0.758645966530  1.190893861790   \n",
       "2017-11-15 20:00:00 -0.758645966530 -1.034952524167  1.189550369608   \n",
       "2017-11-15 22:00:00 -1.034952524167 -0.944231376158  0.979965589193   \n",
       "2017-11-16 12:00:00 -0.944231376158 -1.171264821641  0.995415749288   \n",
       "2017-11-16 14:00:00 -1.171264821641 -1.072716182955  0.890623359081   \n",
       "2017-11-16 16:00:00 -1.072716182955 -0.827263266077  0.848975101434   \n",
       "2017-11-16 18:00:00 -0.827263266077 -0.396224939570  0.756945886957   \n",
       "2017-11-16 20:00:00 -0.396224939570 -0.766937022283  0.742839219045   \n",
       "2017-11-16 22:00:00 -0.766937022283 -0.544968991810  0.466079829523   \n",
       "2017-11-17 12:00:00 -0.544968991810 -0.826802115377  0.494293165348   \n",
       "2017-11-17 14:00:00 -0.826802115377 -0.675293572874  0.408981411782   \n",
       "2017-11-17 16:00:00 -0.675293572874 -0.645820969839  0.365317915862   \n",
       "2017-11-17 18:00:00 -0.645820969839  0.049548481266  0.253136318653   \n",
       "2017-11-17 20:00:00  0.049548481266 -0.380106393141  0.194022662638   \n",
       "2017-11-17 22:00:00 -0.380106393141  0.005340784121 -0.125056730621   \n",
       "2017-11-18 12:00:00  0.005340784121 -0.311030357270 -0.086095457339   \n",
       "2017-11-18 14:00:00 -0.311030357270 -0.108406514189 -0.106247840071   \n",
       "2017-11-18 16:00:00 -0.108406514189 -0.341425261705 -0.116324031437   \n",
       "2017-11-18 18:00:00 -0.341425261705  0.501309618293 -0.225818644282   \n",
       "2017-11-18 20:00:00  0.501309618293  0.062904952029 -0.348076432858   \n",
       "2017-11-18 22:00:00  0.062904952029  0.581438785582 -0.681934240121   \n",
       "2017-11-19 12:00:00  0.581438785582  0.282106078082 -0.646331697294   \n",
       "2017-11-19 14:00:00  0.282106078082  0.510520561288 -0.573111373367   \n",
       "2017-11-19 16:00:00  0.510520561288  0.028366933984 -0.524073908719   \n",
       "2017-11-19 18:00:00  0.028366933984  0.887679096954 -0.608713916194   \n",
       "2017-11-19 20:00:00  0.887679096954  0.493940864159 -0.790085360783   \n",
       "2017-11-19 22:00:00  0.493940864159  1.085698675945 -1.105806023588   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                       t-4             t-3             t-2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 22:00:00  1.233213865528  1.252022756078  1.282251330176   \n",
       "2017-11-03 12:00:00  1.252022756078  1.282251330176  1.334647525280   \n",
       "2017-11-03 14:00:00  1.282251330176  1.334647525280  1.253366248260   \n",
       "2017-11-03 16:00:00  1.334647525280  1.253366248260  0.752243664320   \n",
       "2017-11-03 18:00:00  1.253366248260  0.752243664320  0.518476024626   \n",
       "2017-11-03 20:00:00  0.752243664320  0.518476024626  0.507056341078   \n",
       "2017-11-03 22:00:00  0.518476024626  0.507056341078  0.560124282273   \n",
       "2017-11-04 12:00:00  0.507056341078  0.560124282273  0.647451274112   \n",
       "2017-11-04 14:00:00  0.560124282273  0.647451274112  0.570872219730   \n",
       "2017-11-04 16:00:00  0.647451274112  0.570872219730 -0.072660535518   \n",
       "2017-11-04 18:00:00  0.570872219730 -0.072660535518 -0.290306269025   \n",
       "2017-11-04 20:00:00 -0.072660535518 -0.290306269025 -0.340015479765   \n",
       "2017-11-04 22:00:00 -0.290306269025 -0.340015479765 -0.341358971947   \n",
       "2017-11-05 12:00:00 -0.340015479765 -0.341358971947 -0.252688487925   \n",
       "2017-11-05 14:00:00 -0.341358971947 -0.252688487925 -0.280230077659   \n",
       "2017-11-05 16:00:00 -0.252688487925 -0.280230077659 -0.847183778525   \n",
       "2017-11-05 18:00:00 -0.280230077659 -0.847183778525 -0.972800297555   \n",
       "2017-11-05 20:00:00 -0.847183778525 -0.972800297555 -1.033929191843   \n",
       "2017-11-05 22:00:00 -0.972800297555 -1.033929191843 -1.144767296870   \n",
       "2017-11-06 12:00:00 -1.033929191843 -1.144767296870 -1.105134277497   \n",
       "2017-11-06 14:00:00 -1.144767296870 -1.105134277497 -1.070875226852   \n",
       "2017-11-06 16:00:00 -1.105134277497 -1.070875226852 -1.357710807740   \n",
       "2017-11-06 18:00:00 -1.070875226852 -1.357710807740 -1.344947632010   \n",
       "2017-11-06 20:00:00 -1.357710807740 -1.344947632010 -1.371145729561   \n",
       "2017-11-06 22:00:00 -1.344947632010 -1.371145729561 -1.576700033430   \n",
       "2017-11-07 12:00:00 -1.371145729561 -1.576700033430 -1.617676544985   \n",
       "2017-11-07 14:00:00 -1.576700033430 -1.617676544985 -1.553188920242   \n",
       "2017-11-07 16:00:00 -1.617676544985 -1.553188920242 -1.473251135405   \n",
       "2017-11-07 18:00:00 -1.553188920242 -1.473251135405 -1.327482233642   \n",
       "2017-11-07 20:00:00 -1.473251135405 -1.327482233642 -1.279788261176   \n",
       "...                             ...             ...             ...   \n",
       "2017-11-15 12:00:00  1.253366248260  1.248664025623  1.190893861790   \n",
       "2017-11-15 14:00:00  1.248664025623  1.190893861790  1.189550369608   \n",
       "2017-11-15 16:00:00  1.190893861790  1.189550369608  0.979965589193   \n",
       "2017-11-15 18:00:00  1.189550369608  0.979965589193  0.995415749288   \n",
       "2017-11-15 20:00:00  0.979965589193  0.995415749288  0.890623359081   \n",
       "2017-11-15 22:00:00  0.995415749288  0.890623359081  0.848975101434   \n",
       "2017-11-16 12:00:00  0.890623359081  0.848975101434  0.756945886957   \n",
       "2017-11-16 14:00:00  0.848975101434  0.756945886957  0.742839219045   \n",
       "2017-11-16 16:00:00  0.756945886957  0.742839219045  0.466079829523   \n",
       "2017-11-16 18:00:00  0.742839219045  0.466079829523  0.494293165348   \n",
       "2017-11-16 20:00:00  0.466079829523  0.494293165348  0.408981411782   \n",
       "2017-11-16 22:00:00  0.494293165348  0.408981411782  0.365317915862   \n",
       "2017-11-17 12:00:00  0.408981411782  0.365317915862  0.253136318653   \n",
       "2017-11-17 14:00:00  0.365317915862  0.253136318653  0.194022662638   \n",
       "2017-11-17 16:00:00  0.253136318653  0.194022662638 -0.125056730621   \n",
       "2017-11-17 18:00:00  0.194022662638 -0.125056730621 -0.086095457339   \n",
       "2017-11-17 20:00:00 -0.125056730621 -0.086095457339 -0.106247840071   \n",
       "2017-11-17 22:00:00 -0.086095457339 -0.106247840071 -0.116324031437   \n",
       "2017-11-18 12:00:00 -0.106247840071 -0.116324031437 -0.225818644282   \n",
       "2017-11-18 14:00:00 -0.116324031437 -0.225818644282 -0.348076432858   \n",
       "2017-11-18 16:00:00 -0.225818644282 -0.348076432858 -0.681934240121   \n",
       "2017-11-18 18:00:00 -0.348076432858 -0.681934240121 -0.646331697294   \n",
       "2017-11-18 20:00:00 -0.681934240121 -0.646331697294 -0.573111373367   \n",
       "2017-11-18 22:00:00 -0.646331697294 -0.573111373367 -0.524073908719   \n",
       "2017-11-19 12:00:00 -0.573111373367 -0.524073908719 -0.608713916194   \n",
       "2017-11-19 14:00:00 -0.524073908719 -0.608713916194 -0.790085360783   \n",
       "2017-11-19 16:00:00 -0.608713916194 -0.790085360783 -1.105806023588   \n",
       "2017-11-19 18:00:00 -0.790085360783 -1.105806023588 -1.093042847857   \n",
       "2017-11-19 20:00:00 -1.105806023588 -1.093042847857 -0.923762832907   \n",
       "2017-11-19 22:00:00 -1.093042847857 -0.923762832907 -0.808222505242   \n",
       "\n",
       "tensor                                               \n",
       "feature                                              \n",
       "time step                       t-1               t  \n",
       "Epoch_Time_of_Clock                                  \n",
       "2017-11-02 22:00:00  1.334647525280  1.253366248260  \n",
       "2017-11-03 12:00:00  1.253366248260  0.752243664320  \n",
       "2017-11-03 14:00:00  0.752243664320  0.518476024626  \n",
       "2017-11-03 16:00:00  0.518476024626  0.507056341078  \n",
       "2017-11-03 18:00:00  0.507056341078  0.560124282273  \n",
       "2017-11-03 20:00:00  0.560124282273  0.647451274112  \n",
       "2017-11-03 22:00:00  0.647451274112  0.570872219730  \n",
       "2017-11-04 12:00:00  0.570872219730 -0.072660535518  \n",
       "2017-11-04 14:00:00 -0.072660535518 -0.290306269025  \n",
       "2017-11-04 16:00:00 -0.290306269025 -0.340015479765  \n",
       "2017-11-04 18:00:00 -0.340015479765 -0.341358971947  \n",
       "2017-11-04 20:00:00 -0.341358971947 -0.252688487925  \n",
       "2017-11-04 22:00:00 -0.252688487925 -0.280230077659  \n",
       "2017-11-05 12:00:00 -0.280230077659 -0.847183778525  \n",
       "2017-11-05 14:00:00 -0.847183778525 -0.972800297555  \n",
       "2017-11-05 16:00:00 -0.972800297555 -1.033929191843  \n",
       "2017-11-05 18:00:00 -1.033929191843 -1.144767296870  \n",
       "2017-11-05 20:00:00 -1.144767296870 -1.105134277497  \n",
       "2017-11-05 22:00:00 -1.105134277497 -1.070875226852  \n",
       "2017-11-06 12:00:00 -1.070875226852 -1.357710807740  \n",
       "2017-11-06 14:00:00 -1.357710807740 -1.344947632010  \n",
       "2017-11-06 16:00:00 -1.344947632010 -1.371145729561  \n",
       "2017-11-06 18:00:00 -1.371145729561 -1.576700033430  \n",
       "2017-11-06 20:00:00 -1.576700033430 -1.617676544985  \n",
       "2017-11-06 22:00:00 -1.617676544985 -1.553188920242  \n",
       "2017-11-07 12:00:00 -1.553188920242 -1.473251135405  \n",
       "2017-11-07 14:00:00 -1.473251135405 -1.327482233642  \n",
       "2017-11-07 16:00:00 -1.327482233642 -1.279788261176  \n",
       "2017-11-07 18:00:00 -1.279788261176 -1.501464471230  \n",
       "2017-11-07 20:00:00 -1.501464471230 -1.609615591892  \n",
       "...                             ...             ...  \n",
       "2017-11-15 12:00:00  1.189550369608  0.979965589193  \n",
       "2017-11-15 14:00:00  0.979965589193  0.995415749288  \n",
       "2017-11-15 16:00:00  0.995415749288  0.890623359081  \n",
       "2017-11-15 18:00:00  0.890623359081  0.848975101434  \n",
       "2017-11-15 20:00:00  0.848975101434  0.756945886957  \n",
       "2017-11-15 22:00:00  0.756945886957  0.742839219045  \n",
       "2017-11-16 12:00:00  0.742839219045  0.466079829523  \n",
       "2017-11-16 14:00:00  0.466079829523  0.494293165348  \n",
       "2017-11-16 16:00:00  0.494293165348  0.408981411782  \n",
       "2017-11-16 18:00:00  0.408981411782  0.365317915862  \n",
       "2017-11-16 20:00:00  0.365317915862  0.253136318653  \n",
       "2017-11-16 22:00:00  0.253136318653  0.194022662638  \n",
       "2017-11-17 12:00:00  0.194022662638 -0.125056730621  \n",
       "2017-11-17 14:00:00 -0.125056730621 -0.086095457339  \n",
       "2017-11-17 16:00:00 -0.086095457339 -0.106247840071  \n",
       "2017-11-17 18:00:00 -0.106247840071 -0.116324031437  \n",
       "2017-11-17 20:00:00 -0.116324031437 -0.225818644282  \n",
       "2017-11-17 22:00:00 -0.225818644282 -0.348076432858  \n",
       "2017-11-18 12:00:00 -0.348076432858 -0.681934240121  \n",
       "2017-11-18 14:00:00 -0.681934240121 -0.646331697294  \n",
       "2017-11-18 16:00:00 -0.646331697294 -0.573111373367  \n",
       "2017-11-18 18:00:00 -0.573111373367 -0.524073908719  \n",
       "2017-11-18 20:00:00 -0.524073908719 -0.608713916194  \n",
       "2017-11-18 22:00:00 -0.608713916194 -0.790085360783  \n",
       "2017-11-19 12:00:00 -0.790085360783 -1.105806023588  \n",
       "2017-11-19 14:00:00 -1.105806023588 -1.093042847857  \n",
       "2017-11-19 16:00:00 -1.093042847857 -0.923762832907  \n",
       "2017-11-19 18:00:00 -0.923762832907 -0.808222505242  \n",
       "2017-11-19 20:00:00 -0.808222505242 -0.847855524616  \n",
       "2017-11-19 22:00:00 -0.847855524616 -1.064157765941  \n",
       "\n",
       "[103 rows x 36 columns]"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 6)"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct validation set (keeping T hours from the training set in order to construct initial features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crs</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sqrt_A</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-21 22:00:00</th>\n",
       "      <td>1.575682208083</td>\n",
       "      <td>1.632785225290</td>\n",
       "      <td>0.964585037877</td>\n",
       "      <td>1.335294706214</td>\n",
       "      <td>1.321018348428</td>\n",
       "      <td>1.564629076663</td>\n",
       "      <td>-0.831490137645</td>\n",
       "      <td>-0.696781952217</td>\n",
       "      <td>-0.617770420379</td>\n",
       "      <td>-0.748592792766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736631705371</td>\n",
       "      <td>1.317795121842</td>\n",
       "      <td>1.150170447505</td>\n",
       "      <td>1.602390321075</td>\n",
       "      <td>-1.309345089183</td>\n",
       "      <td>-1.388611127929</td>\n",
       "      <td>-1.119912691500</td>\n",
       "      <td>-0.912343149359</td>\n",
       "      <td>-0.841138063705</td>\n",
       "      <td>-1.009746332564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 12:00:00</th>\n",
       "      <td>1.632785225290</td>\n",
       "      <td>0.964585037877</td>\n",
       "      <td>1.335294706214</td>\n",
       "      <td>1.321018348428</td>\n",
       "      <td>1.564629076663</td>\n",
       "      <td>1.600548132432</td>\n",
       "      <td>-0.696781952217</td>\n",
       "      <td>-0.617770420379</td>\n",
       "      <td>-0.748592792766</td>\n",
       "      <td>-0.878119894139</td>\n",
       "      <td>...</td>\n",
       "      <td>1.317795121842</td>\n",
       "      <td>1.150170447505</td>\n",
       "      <td>1.602390321075</td>\n",
       "      <td>1.575682208083</td>\n",
       "      <td>-1.388611127929</td>\n",
       "      <td>-1.119912691500</td>\n",
       "      <td>-0.912343149359</td>\n",
       "      <td>-0.841138063705</td>\n",
       "      <td>-1.009746332564</td>\n",
       "      <td>-1.069531734670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 14:00:00</th>\n",
       "      <td>0.964585037877</td>\n",
       "      <td>1.335294706214</td>\n",
       "      <td>1.321018348428</td>\n",
       "      <td>1.564629076663</td>\n",
       "      <td>1.600548132432</td>\n",
       "      <td>1.540683039558</td>\n",
       "      <td>-0.617770420379</td>\n",
       "      <td>-0.748592792766</td>\n",
       "      <td>-0.878119894139</td>\n",
       "      <td>-1.012180444061</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150170447505</td>\n",
       "      <td>1.602390321075</td>\n",
       "      <td>1.575682208083</td>\n",
       "      <td>1.632785225290</td>\n",
       "      <td>-1.119912691500</td>\n",
       "      <td>-0.912343149359</td>\n",
       "      <td>-0.841138063705</td>\n",
       "      <td>-1.009746332564</td>\n",
       "      <td>-1.069531734670</td>\n",
       "      <td>-1.195819999791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 16:00:00</th>\n",
       "      <td>1.335294706214</td>\n",
       "      <td>1.321018348428</td>\n",
       "      <td>1.564629076663</td>\n",
       "      <td>1.600548132432</td>\n",
       "      <td>1.540683039558</td>\n",
       "      <td>1.040568677181</td>\n",
       "      <td>-0.748592792766</td>\n",
       "      <td>-0.878119894139</td>\n",
       "      <td>-1.012180444061</td>\n",
       "      <td>-1.296492431575</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602390321075</td>\n",
       "      <td>1.575682208083</td>\n",
       "      <td>1.632785225290</td>\n",
       "      <td>0.964585037877</td>\n",
       "      <td>-0.912343149359</td>\n",
       "      <td>-0.841138063705</td>\n",
       "      <td>-1.009746332564</td>\n",
       "      <td>-1.069531734670</td>\n",
       "      <td>-1.195819999791</td>\n",
       "      <td>-0.949960930459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22 18:00:00</th>\n",
       "      <td>1.321018348428</td>\n",
       "      <td>1.564629076663</td>\n",
       "      <td>1.600548132432</td>\n",
       "      <td>1.540683039558</td>\n",
       "      <td>1.040568677181</td>\n",
       "      <td>1.210957841780</td>\n",
       "      <td>-0.878119894139</td>\n",
       "      <td>-1.012180444061</td>\n",
       "      <td>-1.296492431575</td>\n",
       "      <td>-1.182508582367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.575682208083</td>\n",
       "      <td>1.632785225290</td>\n",
       "      <td>0.964585037877</td>\n",
       "      <td>1.335294706214</td>\n",
       "      <td>-0.841138063705</td>\n",
       "      <td>-1.009746332564</td>\n",
       "      <td>-1.069531734670</td>\n",
       "      <td>-1.195819999791</td>\n",
       "      <td>-0.949960930459</td>\n",
       "      <td>-0.737017419589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                      target                                \\\n",
       "feature                          y                                 \n",
       "time step                      t+1            t+2            t+3   \n",
       "Epoch_Time_of_Clock                                                \n",
       "2017-11-21 22:00:00 1.575682208083 1.632785225290 0.964585037877   \n",
       "2017-11-22 12:00:00 1.632785225290 0.964585037877 1.335294706214   \n",
       "2017-11-22 14:00:00 0.964585037877 1.335294706214 1.321018348428   \n",
       "2017-11-22 16:00:00 1.335294706214 1.321018348428 1.564629076663   \n",
       "2017-11-22 18:00:00 1.321018348428 1.564629076663 1.600548132432   \n",
       "\n",
       "tensor                                                            \\\n",
       "feature                                                            \n",
       "time step                      t+4            t+5            t+6   \n",
       "Epoch_Time_of_Clock                                                \n",
       "2017-11-21 22:00:00 1.335294706214 1.321018348428 1.564629076663   \n",
       "2017-11-22 12:00:00 1.321018348428 1.564629076663 1.600548132432   \n",
       "2017-11-22 14:00:00 1.564629076663 1.600548132432 1.540683039558   \n",
       "2017-11-22 16:00:00 1.600548132432 1.540683039558 1.040568677181   \n",
       "2017-11-22 18:00:00 1.540683039558 1.040568677181 1.210957841780   \n",
       "\n",
       "tensor                            X                                  \\\n",
       "feature                         Crs                                   \n",
       "time step                       t-5             t-4             t-3   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-21 22:00:00 -0.831490137645 -0.696781952217 -0.617770420379   \n",
       "2017-11-22 12:00:00 -0.696781952217 -0.617770420379 -0.748592792766   \n",
       "2017-11-22 14:00:00 -0.617770420379 -0.748592792766 -0.878119894139   \n",
       "2017-11-22 16:00:00 -0.748592792766 -0.878119894139 -1.012180444061   \n",
       "2017-11-22 18:00:00 -0.878119894139 -1.012180444061 -1.296492431575   \n",
       "\n",
       "tensor                               ...                                \\\n",
       "feature                              ...         sqrt_A                  \n",
       "time step                       t-2  ...            t-3            t-2   \n",
       "Epoch_Time_of_Clock                  ...                                 \n",
       "2017-11-21 22:00:00 -0.748592792766  ... 0.736631705371 1.317795121842   \n",
       "2017-11-22 12:00:00 -0.878119894139  ... 1.317795121842 1.150170447505   \n",
       "2017-11-22 14:00:00 -1.012180444061  ... 1.150170447505 1.602390321075   \n",
       "2017-11-22 16:00:00 -1.296492431575  ... 1.602390321075 1.575682208083   \n",
       "2017-11-22 18:00:00 -1.182508582367  ... 1.575682208083 1.632785225290   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                       Crc   \n",
       "time step                      t-1              t             t-5   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-21 22:00:00 1.150170447505 1.602390321075 -1.309345089183   \n",
       "2017-11-22 12:00:00 1.602390321075 1.575682208083 -1.388611127929   \n",
       "2017-11-22 14:00:00 1.575682208083 1.632785225290 -1.119912691500   \n",
       "2017-11-22 16:00:00 1.632785225290 0.964585037877 -0.912343149359   \n",
       "2017-11-22 18:00:00 0.964585037877 1.335294706214 -0.841138063705   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                       t-4             t-3             t-2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-21 22:00:00 -1.388611127929 -1.119912691500 -0.912343149359   \n",
       "2017-11-22 12:00:00 -1.119912691500 -0.912343149359 -0.841138063705   \n",
       "2017-11-22 14:00:00 -0.912343149359 -0.841138063705 -1.009746332564   \n",
       "2017-11-22 16:00:00 -0.841138063705 -1.009746332564 -1.069531734670   \n",
       "2017-11-22 18:00:00 -1.009746332564 -1.069531734670 -1.195819999791   \n",
       "\n",
       "tensor                                               \n",
       "feature                                              \n",
       "time step                       t-1               t  \n",
       "Epoch_Time_of_Clock                                  \n",
       "2017-11-21 22:00:00 -0.841138063705 -1.009746332564  \n",
       "2017-11-22 12:00:00 -1.009746332564 -1.069531734670  \n",
       "2017-11-22 14:00:00 -1.069531734670 -1.195819999791  \n",
       "2017-11-22 16:00:00 -1.195819999791 -0.949960930459  \n",
       "2017-11-22 18:00:00 -0.949960930459 -0.737017419589  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back_dt = dt.datetime.strptime(valid_start_dt, '%Y-%m-%d %H:%M:%S') - dt.timedelta(hours=T-1)\n",
    "valid = df.copy()[(df.index >=look_back_dt) & (df.index < test_start_dt)][['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc']]\n",
    "valid[['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc']] = X_scaler.transform(valid)\n",
    "valid_inputs = TimeSeriesTensor(valid, var_name, HORIZON, tensor_structure,freq = None)\n",
    "valid_inputs.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a RNN forecasting model with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('./images/simple_encoder_decoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Flatten\n",
    "from keras.callbacks import EarlyStopping ,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(LATENT_DIM, input_shape=(T,5 ) , return_sequences = True))\n",
    "model.add(LSTM(LATENT_DIM))\n",
    "model.add(RepeatVector(HORIZON))\n",
    "model.add(LSTM(LATENT_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_39 (LSTM)               (None, 6, 64)             17920     \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "repeat_vector_16 (RepeatVect (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 6, 64)             33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 6, 1)              65        \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 84,033\n",
      "Trainable params: 84,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = ModelCheckpoint(str(sat_var) +'_' +  var_name + '_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 103 samples, validate on 13 samples\n",
      "Epoch 1/1000\n",
      "103/103 [==============================] - 8s 74ms/step - loss: 0.7986 - val_loss: 0.5718\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 0s 668us/step - loss: 0.4011 - val_loss: 0.2746\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 0s 717us/step - loss: 0.2360 - val_loss: 0.3060\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.2064 - val_loss: 0.3007\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1978 - val_loss: 0.2732\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1848 - val_loss: 0.2587\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.2504\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.2418\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 0s 898us/step - loss: 0.1554 - val_loss: 0.2425\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1451 - val_loss: 0.2301\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1437 - val_loss: 0.2444\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1362 - val_loss: 0.1942\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1444 - val_loss: 0.1889\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1235 - val_loss: 0.1711\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 0s 909us/step - loss: 0.1275 - val_loss: 0.1758\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.1659\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1841\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1142 - val_loss: 0.1589\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1258 - val_loss: 0.1754\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1127 - val_loss: 0.1414\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 0s 742us/step - loss: 0.1204 - val_loss: 0.1578\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1093 - val_loss: 0.1256\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 0s 860us/step - loss: 0.1171 - val_loss: 0.1521\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1080 - val_loss: 0.1138\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 0s 937us/step - loss: 0.1161 - val_loss: 0.1451\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1069 - val_loss: 0.1048\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 0s 689us/step - loss: 0.1135 - val_loss: 0.1363\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.0987\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1117 - val_loss: 0.1328\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1037 - val_loss: 0.0950\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 0s 754us/step - loss: 0.1107 - val_loss: 0.1296\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.0922\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 0s 973us/step - loss: 0.1093 - val_loss: 0.1255\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1015 - val_loss: 0.0897\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 0s 973us/step - loss: 0.1081 - val_loss: 0.1224\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1006 - val_loss: 0.0873\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1072 - val_loss: 0.1192\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0998 - val_loss: 0.0852\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 0s 909us/step - loss: 0.1062 - val_loss: 0.1159\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.0831\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 0s 788us/step - loss: 0.1053 - val_loss: 0.1128\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.0813\n",
      "Epoch 43/1000\n",
      "103/103 [==============================] - 0s 986us/step - loss: 0.1045 - val_loss: 0.1099\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0977 - val_loss: 0.0796\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1038 - val_loss: 0.1071\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.0780\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1045\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.0765\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1025 - val_loss: 0.1020\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.0751\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.0996\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.0737\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1013 - val_loss: 0.0973\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.0724\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.1008 - val_loss: 0.0951\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0711\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 0s 819us/step - loss: 0.1003 - val_loss: 0.0929\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0952 - val_loss: 0.0698\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0907\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0950 - val_loss: 0.0686\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.0886\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.0675\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 0s 784us/step - loss: 0.0989 - val_loss: 0.0866\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.0665\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 0s 800us/step - loss: 0.0985 - val_loss: 0.0850\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 0s 836us/step - loss: 0.0944 - val_loss: 0.0658\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 0s 910us/step - loss: 0.0982 - val_loss: 0.0841\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.0660\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.0850\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.0681\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.0892\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0735\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.0951\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0798\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.0965\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0783\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.0830\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0958 - val_loss: 0.0626\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0472\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 0s 836us/step - loss: 0.0934 - val_loss: 0.0525\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 0s 850us/step - loss: 0.0935 - val_loss: 0.0420\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.0555\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.0456\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.0770\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0681\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.0982\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.1030\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0997 - val_loss: 0.1109\n",
      "Epoch 90/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0888\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0974 - val_loss: 0.0858\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0699\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0940 - val_loss: 0.0801\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 0s 801us/step - loss: 0.0921 - val_loss: 0.0619\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.0814\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.0672\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0854\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0777\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.0751\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0972 - val_loss: 0.0624\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.0541\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0454\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0518\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 0s 782us/step - loss: 0.0910 - val_loss: 0.0415\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.0636\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 0s 974us/step - loss: 0.0896 - val_loss: 0.0545\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.0814\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.0815\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1029\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 0s 856us/step - loss: 0.0888 - val_loss: 0.0998\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.0914\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.0799\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0839\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 0s 749us/step - loss: 0.0874 - val_loss: 0.0653\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.0801\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 0s 992us/step - loss: 0.0875 - val_loss: 0.0698\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0796\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0734\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0703\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.0590\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0642\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0511\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0685\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0575\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0790\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 0s 944us/step - loss: 0.0851 - val_loss: 0.0727\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.0774\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 0s 985us/step - loss: 0.0847 - val_loss: 0.0644\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0680\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0476\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0503\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 0s 869us/step - loss: 0.0885 - val_loss: 0.0546\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 0s 917us/step - loss: 0.0835 - val_loss: 0.0611\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0512\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0662\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0788\n",
      "Epoch 137/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0889\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0767\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 0s 922us/step - loss: 0.0946 - val_loss: 0.0681\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 0s 923us/step - loss: 0.0865 - val_loss: 0.0584\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0627\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0612\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0701\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0545\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0677\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0597\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0616\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0660\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 0s 894us/step - loss: 0.0857 - val_loss: 0.0719\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 0s 724us/step - loss: 0.0824 - val_loss: 0.0583\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 0s 960us/step - loss: 0.0834 - val_loss: 0.0684\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 0s 875us/step - loss: 0.0810 - val_loss: 0.0666\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 0s 831us/step - loss: 0.0872 - val_loss: 0.0689\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0646\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0602\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0498\n",
      "Epoch 157/1000\n",
      "103/103 [==============================] - 0s 705us/step - loss: 0.0819 - val_loss: 0.0538\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0612\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0648\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 0s 914us/step - loss: 0.0842 - val_loss: 0.0583\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0639\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0589\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0714\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.0647\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 0s 971us/step - loss: 0.0897 - val_loss: 0.0650\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 0s 850us/step - loss: 0.0861 - val_loss: 0.0735\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 0s 853us/step - loss: 0.0836 - val_loss: 0.0686\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0617\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 0s 948us/step - loss: 0.0810 - val_loss: 0.0547\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0494\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0595\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 0s 938us/step - loss: 0.0839 - val_loss: 0.0662\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 0s 974us/step - loss: 0.0848 - val_loss: 0.0699\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 0s 993us/step - loss: 0.0798 - val_loss: 0.0588\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.0606\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0562\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0635\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0638\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 0s 786us/step - loss: 0.0830 - val_loss: 0.0650\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0623\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 0s 833us/step - loss: 0.0817 - val_loss: 0.0577\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0523\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0562\n",
      "Epoch 184/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0542\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0600\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.0706\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 0s 880us/step - loss: 0.0852 - val_loss: 0.0697\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0662\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0669\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0707\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 0s 877us/step - loss: 0.0822 - val_loss: 0.0694\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.084 - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0625\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0631\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0626\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 0s 907us/step - loss: 0.0813 - val_loss: 0.0548\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0511\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0585\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0567\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0711\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0665\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0782\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0724\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0750\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0694\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0728\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 0s 901us/step - loss: 0.0812 - val_loss: 0.0725\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0608\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 0s 822us/step - loss: 0.0804 - val_loss: 0.0522\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 0s 917us/step - loss: 0.0780 - val_loss: 0.0481\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0422\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0516\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0551\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 0s 849us/step - loss: 0.0822 - val_loss: 0.0583\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 0s 980us/step - loss: 0.0832 - val_loss: 0.0488\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 0s 977us/step - loss: 0.0831 - val_loss: 0.0469\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0486\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0580\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0604\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0686\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 0s 735us/step - loss: 0.0828 - val_loss: 0.0644\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0751\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0761\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 0s 886us/step - loss: 0.0787 - val_loss: 0.0836\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0833\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0782 - val_loss: 0.0816\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 0s 797us/step - loss: 0.0844 - val_loss: 0.0733\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0596\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0540\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 0s 865us/step - loss: 0.0759 - val_loss: 0.0541\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0783 - val_loss: 0.0495\n",
      "Epoch 231/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0647\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 0s 870us/step - loss: 0.0776 - val_loss: 0.0637\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0745\n",
      "Epoch 234/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0734\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0875 - val_loss: 0.0630\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0585\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 0s 773us/step - loss: 0.0742 - val_loss: 0.0671\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0676\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0663\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 0s 992us/step - loss: 0.0826 - val_loss: 0.0544\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 0s 993us/step - loss: 0.0807 - val_loss: 0.0619\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 0s 825us/step - loss: 0.0796 - val_loss: 0.0549\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 0s 809us/step - loss: 0.0789 - val_loss: 0.0722\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0764\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 0s 869us/step - loss: 0.0754 - val_loss: 0.0870\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 0s 828us/step - loss: 0.0790 - val_loss: 0.0688\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 0s 908us/step - loss: 0.0822 - val_loss: 0.0620\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0503\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 0s 729us/step - loss: 0.0764 - val_loss: 0.0662\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 0s 971us/step - loss: 0.0759 - val_loss: 0.0634\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0590\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0788\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.0680\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 0s 967us/step - loss: 0.0823 - val_loss: 0.0503\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 0s 857us/step - loss: 0.0770 - val_loss: 0.0635\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 0s 956us/step - loss: 0.0757 - val_loss: 0.0542\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0635\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0528\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.0746\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 0s 916us/step - loss: 0.0802 - val_loss: 0.0817\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0956\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0597\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0531\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0447\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.0642\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 0s 866us/step - loss: 0.0768 - val_loss: 0.0807\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0633\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 0s 963us/step - loss: 0.0739 - val_loss: 0.0464\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 0s 984us/step - loss: 0.0762 - val_loss: 0.0455\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0893\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.1051\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0975\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 0s 998us/step - loss: 0.0814 - val_loss: 0.0540\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 0s 921us/step - loss: 0.0742 - val_loss: 0.0941\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0773\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0614\n",
      "Epoch 278/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.1306\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0804\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0839\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0423\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.1019\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.1139\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.1683\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.1763\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0408\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.1190\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0985\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.2344\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0597\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.2238\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0812\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.1000\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.1382\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.1930\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.1496\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.1383\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.2536\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0533\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0663\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.1242\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.2491\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.3393\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.4074\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.3824\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0764\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.1963\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.2823\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0804\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0774 - val_loss: 0.2143\n",
      "Epoch 311/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.1674\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.2972\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0657\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 901us/step - loss: 0.0706 - val_loss: 0.2012\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.2116\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.1496\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.1238\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.3534\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.3025\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0758\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.2425\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.1319\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.1990\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.1335\n",
      "Epoch 325/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.2263\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0993\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 0s 965us/step - loss: 0.0704 - val_loss: 0.2478\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.2624\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.1988\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 0s 975us/step - loss: 0.0641 - val_loss: 0.1722\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.2164\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0955\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.1916\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.1616\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.1741\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.2814\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.1916\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.1555\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.1735\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.2100\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.1848\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.1615\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.2078\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.1627\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.1733\n",
      "Epoch 346/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.2629\n",
      "Epoch 347/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.1587\n",
      "Epoch 348/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.1982\n",
      "Epoch 349/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.2352\n",
      "Epoch 350/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0589 - val_loss: 0.1693\n",
      "Epoch 351/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.2246\n",
      "Epoch 352/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.1364\n",
      "Epoch 353/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.2190\n",
      "Epoch 354/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.2834\n",
      "Epoch 355/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.1943\n",
      "Epoch 356/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.1581\n",
      "Epoch 357/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.1437\n",
      "Epoch 358/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.2712\n",
      "Epoch 359/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.2961\n",
      "Epoch 360/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.2378\n",
      "Epoch 361/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0990\n",
      "Epoch 362/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.1860\n",
      "Epoch 363/1000\n",
      "103/103 [==============================] - 0s 925us/step - loss: 0.0592 - val_loss: 0.3033\n",
      "Epoch 364/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.2768\n",
      "Epoch 365/1000\n",
      "103/103 [==============================] - 0s 879us/step - loss: 0.0599 - val_loss: 0.1655\n",
      "Epoch 366/1000\n",
      "103/103 [==============================] - 0s 972us/step - loss: 0.0610 - val_loss: 0.2125\n",
      "Epoch 367/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.2063\n",
      "Epoch 368/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.1424\n",
      "Epoch 369/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.1990\n",
      "Epoch 370/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.2412\n",
      "Epoch 371/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.1825\n",
      "Epoch 372/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.1336\n",
      "Epoch 373/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.2166\n",
      "Epoch 374/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.2392\n",
      "Epoch 375/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.1716\n",
      "Epoch 376/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.1846\n",
      "Epoch 377/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.1361\n",
      "Epoch 378/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.1658\n",
      "Epoch 379/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.2310\n",
      "Epoch 380/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.1624\n",
      "Epoch 381/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.1983\n",
      "Epoch 382/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.2411\n",
      "Epoch 383/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.1397\n",
      "Epoch 384/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.1737\n",
      "Epoch 385/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.2100\n",
      "Epoch 386/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.1768\n",
      "Epoch 387/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.1414\n",
      "Epoch 388/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.2107\n",
      "Epoch 389/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.2847\n",
      "Epoch 390/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.2533\n",
      "Epoch 391/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.3188\n",
      "Epoch 392/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.1497\n",
      "Epoch 394/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.1654\n",
      "Epoch 395/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.1810\n",
      "Epoch 396/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.1700\n",
      "Epoch 397/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.1677\n",
      "Epoch 398/1000\n",
      "103/103 [==============================] - 0s 953us/step - loss: 0.0522 - val_loss: 0.1822\n",
      "Epoch 399/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.1937\n",
      "Epoch 400/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.1978\n",
      "Epoch 401/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.2367\n",
      "Epoch 402/1000\n",
      "103/103 [==============================] - 0s 769us/step - loss: 0.0547 - val_loss: 0.1916\n",
      "Epoch 403/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.1607\n",
      "Epoch 404/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.2130\n",
      "Epoch 405/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.1662\n",
      "Epoch 406/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.1554\n",
      "Epoch 407/1000\n",
      "103/103 [==============================] - 0s 994us/step - loss: 0.0544 - val_loss: 0.1527\n",
      "Epoch 408/1000\n",
      "103/103 [==============================] - 0s 869us/step - loss: 0.0531 - val_loss: 0.2229\n",
      "Epoch 409/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.1887\n",
      "Epoch 410/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.1570\n",
      "Epoch 411/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.1487\n",
      "Epoch 412/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.2521\n",
      "Epoch 413/1000\n",
      "103/103 [==============================] - 0s 964us/step - loss: 0.0532 - val_loss: 0.1988\n",
      "Epoch 414/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.2913\n",
      "Epoch 415/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.1684\n",
      "Epoch 416/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.1411\n",
      "Epoch 417/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.1418\n",
      "Epoch 418/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.1656\n",
      "Epoch 419/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.1761\n",
      "Epoch 420/1000\n",
      "103/103 [==============================] - 0s 969us/step - loss: 0.0576 - val_loss: 0.1432\n",
      "Epoch 421/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.1276\n",
      "Epoch 422/1000\n",
      "103/103 [==============================] - 0s 940us/step - loss: 0.0501 - val_loss: 0.1862\n",
      "Epoch 423/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.1724\n",
      "Epoch 424/1000\n",
      "103/103 [==============================] - 0s 915us/step - loss: 0.0561 - val_loss: 0.1282\n",
      "Epoch 425/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.2064\n",
      "Epoch 426/1000\n",
      "103/103 [==============================] - 0s 987us/step - loss: 0.0509 - val_loss: 0.1946\n",
      "Epoch 427/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.1700\n",
      "Epoch 428/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.1702\n",
      "Epoch 429/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.1156\n",
      "Epoch 430/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.1806\n",
      "Epoch 431/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.1636\n",
      "Epoch 432/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.2373\n",
      "Epoch 433/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.1615\n",
      "Epoch 434/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.2296\n",
      "Epoch 435/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.1531\n",
      "Epoch 436/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.1810\n",
      "Epoch 437/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.1583\n",
      "Epoch 438/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.1373\n",
      "Epoch 439/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0995\n",
      "Epoch 440/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.2241\n",
      "Epoch 441/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.1379\n",
      "Epoch 442/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.1609\n",
      "Epoch 443/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.1154\n",
      "Epoch 444/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.2013\n",
      "Epoch 445/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.1568\n",
      "Epoch 446/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.1821\n",
      "Epoch 447/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.1592\n",
      "Epoch 448/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.1625\n",
      "Epoch 449/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0465 - val_loss: 0.1828\n",
      "Epoch 450/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.1534\n",
      "Epoch 451/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.1990\n",
      "Epoch 452/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.1705\n",
      "Epoch 453/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.1252\n",
      "Epoch 454/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.2142\n",
      "Epoch 455/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.1173\n",
      "Epoch 456/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.1664\n",
      "Epoch 457/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.1321\n",
      "Epoch 458/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.1516\n",
      "Epoch 459/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.1282\n",
      "Epoch 460/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0470 - val_loss: 0.1780\n",
      "Epoch 461/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.1717\n",
      "Epoch 462/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0486 - val_loss: 0.1760\n",
      "Epoch 463/1000\n",
      "103/103 [==============================] - 0s 995us/step - loss: 0.0563 - val_loss: 0.1802\n",
      "Epoch 464/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.1206\n",
      "Epoch 465/1000\n",
      "103/103 [==============================] - 0s 927us/step - loss: 0.0584 - val_loss: 0.2083\n",
      "Epoch 466/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.1489\n",
      "Epoch 467/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0478 - val_loss: 0.1695\n",
      "Epoch 468/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.1330\n",
      "Epoch 469/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0465 - val_loss: 0.1196\n",
      "Epoch 470/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.2098\n",
      "Epoch 471/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.1299\n",
      "Epoch 472/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.1743\n",
      "Epoch 473/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.2023\n",
      "Epoch 474/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.1522\n",
      "Epoch 475/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.1519\n",
      "Epoch 476/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.1048\n",
      "Epoch 477/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.1991\n",
      "Epoch 478/1000\n",
      "103/103 [==============================] - 0s 680us/step - loss: 0.0481 - val_loss: 0.1266\n",
      "Epoch 479/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.2051\n",
      "Epoch 480/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.1397\n",
      "Epoch 481/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.1245\n",
      "Epoch 482/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.1906\n",
      "Epoch 483/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.1235\n",
      "Epoch 484/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.2174\n",
      "Epoch 485/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.1386\n",
      "Epoch 486/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.2024\n",
      "Epoch 487/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.1481\n",
      "Epoch 488/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.1499\n",
      "Epoch 489/1000\n",
      "103/103 [==============================] - 0s 999us/step - loss: 0.0616 - val_loss: 0.1657\n",
      "Epoch 490/1000\n",
      "103/103 [==============================] - 0s 983us/step - loss: 0.0484 - val_loss: 0.1963\n",
      "Epoch 491/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.1832\n",
      "Epoch 492/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.1398\n",
      "Epoch 493/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.1606\n",
      "Epoch 494/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0874\n",
      "Epoch 495/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.1805\n",
      "Epoch 496/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.1224\n",
      "Epoch 497/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.1910\n",
      "Epoch 498/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.1474\n",
      "Epoch 499/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.1611\n",
      "Epoch 500/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.1508\n",
      "Epoch 501/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.1777\n",
      "Epoch 502/1000\n",
      "103/103 [==============================] - 0s 986us/step - loss: 0.0453 - val_loss: 0.1611\n",
      "Epoch 503/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.1752\n",
      "Epoch 504/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.1310\n",
      "Epoch 505/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.1554\n",
      "Epoch 506/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.1165\n",
      "Epoch 507/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.1939\n",
      "Epoch 508/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.1515\n",
      "Epoch 509/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.1335\n",
      "Epoch 510/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.1717\n",
      "Epoch 511/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0985\n",
      "Epoch 512/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.1890\n",
      "Epoch 513/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.1462\n",
      "Epoch 514/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.2010\n",
      "Epoch 515/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.1208\n",
      "Epoch 516/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.1402\n",
      "Epoch 517/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.1384\n",
      "Epoch 518/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.1674\n",
      "Epoch 519/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.1437\n",
      "Epoch 520/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.1930\n",
      "Epoch 521/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.1172\n",
      "Epoch 522/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.1493\n",
      "Epoch 523/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.1168\n",
      "Epoch 524/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.1809\n",
      "Epoch 525/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.1499\n",
      "Epoch 526/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.2199\n",
      "Epoch 527/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.1660\n",
      "Epoch 528/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.1702\n",
      "Epoch 529/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.1100\n",
      "Epoch 530/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.1402\n",
      "Epoch 531/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.1170\n",
      "Epoch 532/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.1726\n",
      "Epoch 533/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.1130\n",
      "Epoch 534/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.1558\n",
      "Epoch 535/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.1314\n",
      "Epoch 536/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.2387\n",
      "Epoch 537/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.1688\n",
      "Epoch 538/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.1584\n",
      "Epoch 539/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.1405\n",
      "Epoch 540/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.1729\n",
      "Epoch 541/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.2332\n",
      "Epoch 542/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.1993\n",
      "Epoch 543/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.1506\n",
      "Epoch 544/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.1001\n",
      "Epoch 545/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.1867\n",
      "Epoch 546/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.1334\n",
      "Epoch 547/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.1586\n",
      "Epoch 548/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.1296\n",
      "Epoch 549/1000\n",
      "103/103 [==============================] - 0s 969us/step - loss: 0.0400 - val_loss: 0.1588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0374 - val_loss: 0.1421\n",
      "Epoch 551/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.1753\n",
      "Epoch 552/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.1654\n",
      "Epoch 553/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.2204\n",
      "Epoch 554/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.1562\n",
      "Epoch 555/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.1617\n",
      "Epoch 556/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.1337\n",
      "Epoch 557/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.1922\n",
      "Epoch 558/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.1608\n",
      "Epoch 559/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.1238\n",
      "Epoch 560/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.1723\n",
      "Epoch 561/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.1313\n",
      "Epoch 562/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.1931\n",
      "Epoch 563/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.1531\n",
      "Epoch 564/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.1649\n",
      "Epoch 565/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.1200\n",
      "Epoch 566/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.1616\n",
      "Epoch 567/1000\n",
      "103/103 [==============================] - 0s 935us/step - loss: 0.0375 - val_loss: 0.1231\n",
      "Epoch 568/1000\n",
      "103/103 [==============================] - 0s 487us/step - loss: 0.0364 - val_loss: 0.2190\n",
      "Epoch 569/1000\n",
      "103/103 [==============================] - 0s 494us/step - loss: 0.0461 - val_loss: 0.1330\n",
      "Epoch 570/1000\n",
      "103/103 [==============================] - 0s 446us/step - loss: 0.0396 - val_loss: 0.1368\n",
      "Epoch 571/1000\n",
      "103/103 [==============================] - 0s 521us/step - loss: 0.0406 - val_loss: 0.1354\n",
      "Epoch 572/1000\n",
      "103/103 [==============================] - 0s 521us/step - loss: 0.0391 - val_loss: 0.1969\n",
      "Epoch 573/1000\n",
      "103/103 [==============================] - 0s 482us/step - loss: 0.0382 - val_loss: 0.1551\n",
      "Epoch 574/1000\n",
      "103/103 [==============================] - 0s 500us/step - loss: 0.0381 - val_loss: 0.1642\n",
      "Epoch 575/1000\n",
      "103/103 [==============================] - 0s 477us/step - loss: 0.0405 - val_loss: 0.1323\n",
      "Epoch 576/1000\n",
      "103/103 [==============================] - 0s 491us/step - loss: 0.0367 - val_loss: 0.1444\n",
      "Epoch 577/1000\n",
      "103/103 [==============================] - 0s 671us/step - loss: 0.0378 - val_loss: 0.1840\n",
      "Epoch 578/1000\n",
      "103/103 [==============================] - 0s 460us/step - loss: 0.0355 - val_loss: 0.1974\n",
      "Epoch 579/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0425 - val_loss: 0.1294\n",
      "Epoch 580/1000\n",
      "103/103 [==============================] - 0s 442us/step - loss: 0.0365 - val_loss: 0.1488\n",
      "Epoch 581/1000\n",
      "103/103 [==============================] - 0s 440us/step - loss: 0.0323 - val_loss: 0.1206\n",
      "Epoch 582/1000\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.0345 - val_loss: 0.1745\n",
      "Epoch 583/1000\n",
      "103/103 [==============================] - 0s 777us/step - loss: 0.0394 - val_loss: 0.1944\n",
      "Epoch 584/1000\n",
      "103/103 [==============================] - 0s 853us/step - loss: 0.0418 - val_loss: 0.1713\n",
      "Epoch 585/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.1378\n",
      "Epoch 586/1000\n",
      "103/103 [==============================] - 0s 506us/step - loss: 0.0360 - val_loss: 0.1354\n",
      "Epoch 587/1000\n",
      "103/103 [==============================] - 0s 464us/step - loss: 0.0310 - val_loss: 0.1447\n",
      "Epoch 588/1000\n",
      "103/103 [==============================] - 0s 522us/step - loss: 0.0342 - val_loss: 0.1817\n",
      "Epoch 589/1000\n",
      "103/103 [==============================] - 0s 436us/step - loss: 0.0441 - val_loss: 0.1488\n",
      "Epoch 590/1000\n",
      "103/103 [==============================] - 0s 458us/step - loss: 0.0492 - val_loss: 0.1917\n",
      "Epoch 591/1000\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.0344 - val_loss: 0.1400\n",
      "Epoch 592/1000\n",
      "103/103 [==============================] - 0s 450us/step - loss: 0.0375 - val_loss: 0.1370\n",
      "Epoch 593/1000\n",
      "103/103 [==============================] - 0s 526us/step - loss: 0.0355 - val_loss: 0.1196\n",
      "Epoch 594/1000\n",
      "103/103 [==============================] - 0s 626us/step - loss: 0.0314 - val_loss: 0.1527\n",
      "Epoch 595/1000\n",
      "103/103 [==============================] - 0s 481us/step - loss: 0.0303 - val_loss: 0.1190\n",
      "Epoch 596/1000\n",
      "103/103 [==============================] - 0s 486us/step - loss: 0.0377 - val_loss: 0.1708\n",
      "Epoch 597/1000\n",
      "103/103 [==============================] - 0s 484us/step - loss: 0.0385 - val_loss: 0.1258\n",
      "Epoch 598/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.1917\n",
      "Epoch 599/1000\n",
      "103/103 [==============================] - 0s 935us/step - loss: 0.0480 - val_loss: 0.1623\n",
      "Epoch 600/1000\n",
      "103/103 [==============================] - 0s 704us/step - loss: 0.0359 - val_loss: 0.1891\n",
      "Epoch 601/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.1392\n",
      "Epoch 602/1000\n",
      "103/103 [==============================] - 0s 505us/step - loss: 0.0351 - val_loss: 0.1472\n",
      "Epoch 603/1000\n",
      "103/103 [==============================] - 0s 469us/step - loss: 0.0345 - val_loss: 0.1283\n",
      "Epoch 604/1000\n",
      "103/103 [==============================] - 0s 438us/step - loss: 0.0319 - val_loss: 0.1531\n",
      "Epoch 605/1000\n",
      "103/103 [==============================] - 0s 442us/step - loss: 0.0456 - val_loss: 0.1527\n",
      "Epoch 606/1000\n",
      "103/103 [==============================] - 0s 495us/step - loss: 0.0395 - val_loss: 0.2050\n",
      "Epoch 607/1000\n",
      "103/103 [==============================] - 0s 502us/step - loss: 0.0381 - val_loss: 0.1232\n",
      "Epoch 608/1000\n",
      "103/103 [==============================] - 0s 499us/step - loss: 0.0324 - val_loss: 0.1537\n",
      "Epoch 609/1000\n",
      "103/103 [==============================] - 0s 506us/step - loss: 0.0306 - val_loss: 0.1365\n",
      "Epoch 610/1000\n",
      "103/103 [==============================] - 0s 494us/step - loss: 0.0293 - val_loss: 0.1819\n",
      "Epoch 611/1000\n",
      "103/103 [==============================] - 0s 508us/step - loss: 0.0318 - val_loss: 0.1926\n",
      "Epoch 612/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.1446\n",
      "Epoch 613/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.1598\n",
      "Epoch 614/1000\n",
      "103/103 [==============================] - 0s 925us/step - loss: 0.0366 - val_loss: 0.1559\n",
      "Epoch 615/1000\n",
      "103/103 [==============================] - 0s 488us/step - loss: 0.0335 - val_loss: 0.1971\n",
      "Epoch 616/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.1547\n",
      "Epoch 617/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.1225\n",
      "Epoch 618/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.1369\n",
      "Epoch 619/1000\n",
      "103/103 [==============================] - 0s 762us/step - loss: 0.0290 - val_loss: 0.1324\n",
      "Epoch 620/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.1685\n",
      "Epoch 621/1000\n",
      "103/103 [==============================] - 0s 485us/step - loss: 0.0373 - val_loss: 0.1422\n",
      "Epoch 622/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.2040\n",
      "Epoch 623/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.1661\n",
      "Epoch 624/1000\n",
      "103/103 [==============================] - 0s 873us/step - loss: 0.0364 - val_loss: 0.1877\n",
      "Epoch 625/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.1315\n",
      "Epoch 626/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.1425\n",
      "Epoch 627/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.1365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.1399\n",
      "Epoch 629/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.1192\n",
      "Epoch 630/1000\n",
      "103/103 [==============================] - 0s 446us/step - loss: 0.0392 - val_loss: 0.1918\n",
      "Epoch 631/1000\n",
      "103/103 [==============================] - 0s 440us/step - loss: 0.0393 - val_loss: 0.1790\n",
      "Epoch 632/1000\n",
      "103/103 [==============================] - 0s 429us/step - loss: 0.0284 - val_loss: 0.1544\n",
      "Epoch 633/1000\n",
      "103/103 [==============================] - 0s 504us/step - loss: 0.0288 - val_loss: 0.1411\n",
      "Epoch 634/1000\n",
      "103/103 [==============================] - 0s 512us/step - loss: 0.0321 - val_loss: 0.1755\n",
      "Epoch 635/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.1469\n",
      "Epoch 636/1000\n",
      "103/103 [==============================] - 0s 659us/step - loss: 0.0306 - val_loss: 0.1617\n",
      "Epoch 637/1000\n",
      "103/103 [==============================] - 0s 479us/step - loss: 0.0320 - val_loss: 0.1248\n",
      "Epoch 638/1000\n",
      "103/103 [==============================] - 0s 458us/step - loss: 0.0290 - val_loss: 0.1899\n",
      "Epoch 639/1000\n",
      "103/103 [==============================] - 0s 442us/step - loss: 0.0284 - val_loss: 0.1837\n",
      "Epoch 640/1000\n",
      "103/103 [==============================] - 0s 477us/step - loss: 0.0351 - val_loss: 0.1453\n",
      "Epoch 641/1000\n",
      "103/103 [==============================] - 0s 519us/step - loss: 0.0336 - val_loss: 0.1485\n",
      "Epoch 642/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.1283\n",
      "Epoch 643/1000\n",
      "103/103 [==============================] - 0s 937us/step - loss: 0.0340 - val_loss: 0.1909\n",
      "Epoch 644/1000\n",
      "103/103 [==============================] - 0s 487us/step - loss: 0.0369 - val_loss: 0.1427\n",
      "Epoch 645/1000\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.0324 - val_loss: 0.1468\n",
      "Epoch 646/1000\n",
      "103/103 [==============================] - 0s 549us/step - loss: 0.0294 - val_loss: 0.1374\n",
      "Epoch 647/1000\n",
      "103/103 [==============================] - 0s 513us/step - loss: 0.0283 - val_loss: 0.1798\n",
      "Epoch 648/1000\n",
      "103/103 [==============================] - 0s 496us/step - loss: 0.0266 - val_loss: 0.1778\n",
      "Epoch 649/1000\n",
      "103/103 [==============================] - 0s 489us/step - loss: 0.0292 - val_loss: 0.1586\n",
      "Epoch 650/1000\n",
      "103/103 [==============================] - 0s 529us/step - loss: 0.0379 - val_loss: 0.1408\n",
      "Epoch 651/1000\n",
      "103/103 [==============================] - 0s 479us/step - loss: 0.0293 - val_loss: 0.1676\n",
      "Epoch 652/1000\n",
      "103/103 [==============================] - 0s 532us/step - loss: 0.0367 - val_loss: 0.1525\n",
      "Epoch 653/1000\n",
      "103/103 [==============================] - 0s 475us/step - loss: 0.0355 - val_loss: 0.1339\n",
      "Epoch 654/1000\n",
      "103/103 [==============================] - 0s 510us/step - loss: 0.0281 - val_loss: 0.1478\n",
      "Epoch 655/1000\n",
      "103/103 [==============================] - 0s 639us/step - loss: 0.0235 - val_loss: 0.1172\n",
      "Epoch 656/1000\n",
      "103/103 [==============================] - 0s 479us/step - loss: 0.0234 - val_loss: 0.1798\n",
      "Epoch 657/1000\n",
      "103/103 [==============================] - 0s 487us/step - loss: 0.0268 - val_loss: 0.1670\n",
      "Epoch 658/1000\n",
      "103/103 [==============================] - 0s 479us/step - loss: 0.0328 - val_loss: 0.2081\n",
      "Epoch 659/1000\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.0340 - val_loss: 0.1620\n",
      "Epoch 660/1000\n",
      "103/103 [==============================] - 0s 473us/step - loss: 0.0311 - val_loss: 0.0991\n",
      "Epoch 661/1000\n",
      "103/103 [==============================] - 0s 908us/step - loss: 0.0316 - val_loss: 0.2140\n",
      "Epoch 662/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.1586\n",
      "Epoch 663/1000\n",
      "103/103 [==============================] - 0s 460us/step - loss: 0.0290 - val_loss: 0.1371\n",
      "Epoch 664/1000\n",
      "103/103 [==============================] - 0s 451us/step - loss: 0.0255 - val_loss: 0.1394\n",
      "Epoch 665/1000\n",
      "103/103 [==============================] - 0s 801us/step - loss: 0.0289 - val_loss: 0.1771\n",
      "Epoch 666/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.1976\n",
      "Epoch 667/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.1341\n",
      "Epoch 668/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.1009\n",
      "Epoch 669/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.2240\n",
      "Epoch 670/1000\n",
      "103/103 [==============================] - 0s 443us/step - loss: 0.0320 - val_loss: 0.1763\n",
      "Epoch 671/1000\n",
      "103/103 [==============================] - 0s 453us/step - loss: 0.0274 - val_loss: 0.1296\n",
      "Epoch 672/1000\n",
      "103/103 [==============================] - 0s 447us/step - loss: 0.0253 - val_loss: 0.1190\n",
      "Epoch 673/1000\n",
      "103/103 [==============================] - 0s 441us/step - loss: 0.0346 - val_loss: 0.1773\n",
      "Epoch 674/1000\n",
      "103/103 [==============================] - 0s 448us/step - loss: 0.0326 - val_loss: 0.2109\n",
      "Epoch 675/1000\n",
      "103/103 [==============================] - 0s 453us/step - loss: 0.0267 - val_loss: 0.1313\n",
      "Epoch 676/1000\n",
      "103/103 [==============================] - 0s 437us/step - loss: 0.0254 - val_loss: 0.1231\n",
      "Epoch 677/1000\n",
      "103/103 [==============================] - 0s 482us/step - loss: 0.0242 - val_loss: 0.1908\n",
      "Epoch 678/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.1498\n",
      "Epoch 679/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.1522\n",
      "Epoch 680/1000\n",
      "103/103 [==============================] - 0s 467us/step - loss: 0.0241 - val_loss: 0.1054\n",
      "Epoch 681/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.2071\n",
      "Epoch 682/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.1683\n",
      "Epoch 683/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.1451\n",
      "Epoch 684/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.1719\n",
      "Epoch 685/1000\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.1815\n",
      "Epoch 686/1000\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.1617\n",
      "Epoch 687/1000\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.1184\n",
      "Epoch 688/1000\n",
      "103/103 [==============================] - 0s 676us/step - loss: 0.0236 - val_loss: 0.1590\n",
      "Epoch 689/1000\n",
      "103/103 [==============================] - 0s 462us/step - loss: 0.0339 - val_loss: 0.2067\n",
      "Epoch 690/1000\n",
      "103/103 [==============================] - 0s 446us/step - loss: 0.0347 - val_loss: 0.2029\n",
      "Epoch 691/1000\n",
      "103/103 [==============================] - 0s 453us/step - loss: 0.0250 - val_loss: 0.1368\n",
      "Epoch 692/1000\n",
      "103/103 [==============================] - 0s 474us/step - loss: 0.0242 - val_loss: 0.1459\n",
      "Epoch 693/1000\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.0256 - val_loss: 0.2043\n",
      "Epoch 694/1000\n",
      "103/103 [==============================] - 0s 499us/step - loss: 0.0264 - val_loss: 0.1548\n",
      "Epoch 695/1000\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.0281 - val_loss: 0.1119\n",
      "Epoch 696/1000\n",
      "103/103 [==============================] - 0s 466us/step - loss: 0.0252 - val_loss: 0.1991\n",
      "Epoch 697/1000\n",
      "103/103 [==============================] - 0s 467us/step - loss: 0.0292 - val_loss: 0.1822\n",
      "Epoch 698/1000\n",
      "103/103 [==============================] - 0s 459us/step - loss: 0.0288 - val_loss: 0.1709\n",
      "Epoch 699/1000\n",
      "103/103 [==============================] - 0s 466us/step - loss: 0.0217 - val_loss: 0.1175\n",
      "Epoch 700/1000\n",
      "103/103 [==============================] - 0s 505us/step - loss: 0.0225 - val_loss: 0.1562\n",
      "Epoch 701/1000\n",
      "103/103 [==============================] - 0s 509us/step - loss: 0.0247 - val_loss: 0.2333\n",
      "Epoch 702/1000\n",
      "103/103 [==============================] - 0s 502us/step - loss: 0.0403 - val_loss: 0.1953\n",
      "Epoch 703/1000\n",
      "103/103 [==============================] - 0s 490us/step - loss: 0.0273 - val_loss: 0.1541\n",
      "Epoch 704/1000\n",
      "103/103 [==============================] - 0s 483us/step - loss: 0.0214 - val_loss: 0.1382\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 453us/step - loss: 0.0256 - val_loss: 0.1357\n",
      "Epoch 706/1000\n",
      "103/103 [==============================] - 0s 462us/step - loss: 0.0243 - val_loss: 0.2083\n",
      "Epoch 707/1000\n",
      "103/103 [==============================] - 0s 451us/step - loss: 0.0216 - val_loss: 0.1141\n",
      "Epoch 708/1000\n",
      "103/103 [==============================] - 0s 476us/step - loss: 0.0261 - val_loss: 0.2058\n",
      "Epoch 709/1000\n",
      "103/103 [==============================] - 0s 470us/step - loss: 0.0265 - val_loss: 0.1782\n",
      "Epoch 710/1000\n",
      "103/103 [==============================] - 0s 477us/step - loss: 0.0308 - val_loss: 0.1877\n",
      "Epoch 711/1000\n",
      "103/103 [==============================] - 0s 472us/step - loss: 0.0239 - val_loss: 0.1864\n",
      "Epoch 712/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0266 - val_loss: 0.1689\n",
      "Epoch 713/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0247 - val_loss: 0.1600\n",
      "Epoch 714/1000\n",
      "103/103 [==============================] - 0s 467us/step - loss: 0.0243 - val_loss: 0.1381\n",
      "Epoch 715/1000\n",
      "103/103 [==============================] - 0s 481us/step - loss: 0.0208 - val_loss: 0.1797\n",
      "Epoch 716/1000\n",
      "103/103 [==============================] - 0s 476us/step - loss: 0.0228 - val_loss: 0.2349\n",
      "Epoch 717/1000\n",
      "103/103 [==============================] - 0s 458us/step - loss: 0.0252 - val_loss: 0.1432\n",
      "Epoch 718/1000\n",
      "103/103 [==============================] - 0s 468us/step - loss: 0.0307 - val_loss: 0.1691\n",
      "Epoch 719/1000\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.0280 - val_loss: 0.2179\n",
      "Epoch 720/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0231 - val_loss: 0.1826\n",
      "Epoch 721/1000\n",
      "103/103 [==============================] - 0s 463us/step - loss: 0.0247 - val_loss: 0.1411\n",
      "Epoch 722/1000\n",
      "103/103 [==============================] - 0s 467us/step - loss: 0.0221 - val_loss: 0.1732\n",
      "Epoch 723/1000\n",
      "103/103 [==============================] - 0s 461us/step - loss: 0.0281 - val_loss: 0.1909\n",
      "Epoch 724/1000\n",
      "103/103 [==============================] - 0s 565us/step - loss: 0.0274 - val_loss: 0.2213\n",
      "Epoch 725/1000\n",
      "103/103 [==============================] - 0s 698us/step - loss: 0.0278 - val_loss: 0.1209\n",
      "Epoch 726/1000\n",
      "103/103 [==============================] - 0s 433us/step - loss: 0.0242 - val_loss: 0.1946\n",
      "Epoch 727/1000\n",
      "103/103 [==============================] - 0s 533us/step - loss: 0.0215 - val_loss: 0.1827\n",
      "Epoch 728/1000\n",
      "103/103 [==============================] - 0s 579us/step - loss: 0.0198 - val_loss: 0.2133\n",
      "Epoch 729/1000\n",
      "103/103 [==============================] - 0s 453us/step - loss: 0.0253 - val_loss: 0.1494\n",
      "Epoch 730/1000\n",
      "103/103 [==============================] - 0s 459us/step - loss: 0.0229 - val_loss: 0.1338\n",
      "Epoch 731/1000\n",
      "103/103 [==============================] - 0s 445us/step - loss: 0.0234 - val_loss: 0.2107\n",
      "Epoch 732/1000\n",
      "103/103 [==============================] - 0s 437us/step - loss: 0.0246 - val_loss: 0.2148\n",
      "Epoch 733/1000\n",
      "103/103 [==============================] - 0s 448us/step - loss: 0.0327 - val_loss: 0.1653\n",
      "Epoch 734/1000\n",
      "103/103 [==============================] - 0s 475us/step - loss: 0.0214 - val_loss: 0.1783\n",
      "Epoch 735/1000\n",
      "103/103 [==============================] - 0s 440us/step - loss: 0.0201 - val_loss: 0.1803\n",
      "Epoch 736/1000\n",
      "103/103 [==============================] - 0s 449us/step - loss: 0.0222 - val_loss: 0.1659\n",
      "Epoch 737/1000\n",
      "103/103 [==============================] - 0s 434us/step - loss: 0.0257 - val_loss: 0.1700\n",
      "Epoch 738/1000\n",
      "103/103 [==============================] - 0s 444us/step - loss: 0.0237 - val_loss: 0.1350\n",
      "Epoch 739/1000\n",
      "103/103 [==============================] - 0s 443us/step - loss: 0.0236 - val_loss: 0.1977\n",
      "Epoch 740/1000\n",
      "103/103 [==============================] - 0s 438us/step - loss: 0.0232 - val_loss: 0.2540\n",
      "Epoch 741/1000\n",
      "103/103 [==============================] - 0s 450us/step - loss: 0.0292 - val_loss: 0.1589\n",
      "Epoch 742/1000\n",
      "103/103 [==============================] - 0s 449us/step - loss: 0.0236 - val_loss: 0.1679\n",
      "Epoch 743/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0219 - val_loss: 0.2094\n",
      "Epoch 744/1000\n",
      "103/103 [==============================] - 0s 433us/step - loss: 0.0197 - val_loss: 0.1947\n",
      "Epoch 745/1000\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.0203 - val_loss: 0.1140\n",
      "Epoch 746/1000\n",
      "103/103 [==============================] - 0s 432us/step - loss: 0.0200 - val_loss: 0.2229\n",
      "Epoch 747/1000\n",
      "103/103 [==============================] - 0s 433us/step - loss: 0.0257 - val_loss: 0.1450\n",
      "Epoch 748/1000\n",
      "103/103 [==============================] - 0s 438us/step - loss: 0.0297 - val_loss: 0.2343\n",
      "Epoch 749/1000\n",
      "103/103 [==============================] - 0s 450us/step - loss: 0.0374 - val_loss: 0.1733\n",
      "Epoch 750/1000\n",
      "103/103 [==============================] - 0s 440us/step - loss: 0.0222 - val_loss: 0.1858\n",
      "Epoch 751/1000\n",
      "103/103 [==============================] - 0s 462us/step - loss: 0.0200 - val_loss: 0.1885\n",
      "Epoch 752/1000\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.0183 - val_loss: 0.1504\n",
      "Epoch 753/1000\n",
      "103/103 [==============================] - 0s 442us/step - loss: 0.0178 - val_loss: 0.1819\n",
      "Epoch 754/1000\n",
      "103/103 [==============================] - 0s 460us/step - loss: 0.0190 - val_loss: 0.1804\n",
      "Epoch 755/1000\n",
      "103/103 [==============================] - 0s 463us/step - loss: 0.0231 - val_loss: 0.1489\n",
      "Epoch 756/1000\n",
      "103/103 [==============================] - 0s 478us/step - loss: 0.0259 - val_loss: 0.2137\n",
      "Epoch 757/1000\n",
      "103/103 [==============================] - 0s 479us/step - loss: 0.0221 - val_loss: 0.1891\n",
      "Epoch 758/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0237 - val_loss: 0.1803\n",
      "Epoch 759/1000\n",
      "103/103 [==============================] - 0s 469us/step - loss: 0.0263 - val_loss: 0.1825\n",
      "Epoch 760/1000\n",
      "103/103 [==============================] - 0s 463us/step - loss: 0.0283 - val_loss: 0.1667\n",
      "Epoch 761/1000\n",
      "103/103 [==============================] - 0s 443us/step - loss: 0.0206 - val_loss: 0.1882\n",
      "Epoch 762/1000\n",
      "103/103 [==============================] - 0s 457us/step - loss: 0.0189 - val_loss: 0.1803\n",
      "Epoch 763/1000\n",
      "103/103 [==============================] - 0s 463us/step - loss: 0.0181 - val_loss: 0.1574\n",
      "Epoch 764/1000\n",
      "103/103 [==============================] - 0s 539us/step - loss: 0.0189 - val_loss: 0.1871\n",
      "Epoch 765/1000\n",
      "103/103 [==============================] - 0s 501us/step - loss: 0.0232 - val_loss: 0.1341\n",
      "Epoch 766/1000\n",
      "103/103 [==============================] - 0s 463us/step - loss: 0.0256 - val_loss: 0.1920\n",
      "Epoch 767/1000\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.0259 - val_loss: 0.2428\n",
      "Epoch 768/1000\n",
      "103/103 [==============================] - 0s 480us/step - loss: 0.0272 - val_loss: 0.1963\n",
      "Epoch 769/1000\n",
      "103/103 [==============================] - 0s 471us/step - loss: 0.0216 - val_loss: 0.1689\n",
      "Epoch 770/1000\n",
      "103/103 [==============================] - 0s 472us/step - loss: 0.0236 - val_loss: 0.1403\n",
      "Epoch 771/1000\n",
      "103/103 [==============================] - 0s 455us/step - loss: 0.0214 - val_loss: 0.1560\n",
      "Epoch 772/1000\n",
      "103/103 [==============================] - 0s 457us/step - loss: 0.0185 - val_loss: 0.1653\n",
      "Epoch 773/1000\n",
      "103/103 [==============================] - 0s 477us/step - loss: 0.0202 - val_loss: 0.1848\n",
      "Epoch 774/1000\n",
      "103/103 [==============================] - 0s 459us/step - loss: 0.0196 - val_loss: 0.1584\n",
      "Epoch 775/1000\n",
      "103/103 [==============================] - 0s 459us/step - loss: 0.0202 - val_loss: 0.1962\n",
      "Epoch 776/1000\n",
      "103/103 [==============================] - 0s 536us/step - loss: 0.0229 - val_loss: 0.2062\n",
      "Epoch 777/1000\n",
      "103/103 [==============================] - 0s 440us/step - loss: 0.0249 - val_loss: 0.1581\n",
      "Epoch 778/1000\n",
      "103/103 [==============================] - 0s 462us/step - loss: 0.0245 - val_loss: 0.1988\n",
      "Epoch 779/1000\n",
      "103/103 [==============================] - 0s 457us/step - loss: 0.0244 - val_loss: 0.1793\n",
      "Epoch 780/1000\n",
      "103/103 [==============================] - 0s 454us/step - loss: 0.0206 - val_loss: 0.1602\n",
      "Epoch 781/1000\n",
      "103/103 [==============================] - 0s 465us/step - loss: 0.0245 - val_loss: 0.1763\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 462us/step - loss: 0.0250 - val_loss: 0.1504\n",
      "Epoch 783/1000\n",
      "103/103 [==============================] - 0s 464us/step - loss: 0.0172 - val_loss: 0.1663\n",
      "Epoch 784/1000\n",
      "103/103 [==============================] - 0s 457us/step - loss: 0.0172 - val_loss: 0.1346\n",
      "Epoch 785/1000\n",
      "103/103 [==============================] - 0s 458us/step - loss: 0.0180 - val_loss: 0.2148\n",
      "Epoch 786/1000\n",
      "103/103 [==============================] - 0s 508us/step - loss: 0.0182 - val_loss: 0.1616\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_inputs['X'],\n",
    "          train_inputs['target'],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(valid_inputs['X'], valid_inputs['target']),\n",
    "          callbacks=[earlystop ,best_val],\n",
    "          verbose=1 , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model.load_weights(str(sat_var) +'_' +  var_name + '_{:02d}.h5'.format(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0345\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0410\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0474\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0406\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0339\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0332\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0293\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0319\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0307\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0380\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0417\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0360\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0391\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0337\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0302\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0351\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0309\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0341\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0304\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0289\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0289\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0382\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0327\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0335\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0323\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0316\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0303\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0330\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0304\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0344\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0310\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0323\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0334\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0309\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0322\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0334\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0289\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0307\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0305\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0286\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0347\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0306\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0313\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0276\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0324\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0314\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0294\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57ea212780>"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(valid_inputs['X'],\n",
    "          valid_inputs['target'],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=100,\n",
    "          callbacks=[earlystop ,best_val],\n",
    "          verbose=1 , shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crs</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sqrt_A</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-25 22:00:00</th>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-1.536117569116</td>\n",
       "      <td>-1.573680428514</td>\n",
       "      <td>-1.448686775689</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654660349438</td>\n",
       "      <td>0.593411804245</td>\n",
       "      <td>1.071883468639</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.428462048423</td>\n",
       "      <td>0.285380131024</td>\n",
       "      <td>0.274632193567</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 12:00:00</th>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-1.573680428514</td>\n",
       "      <td>-1.448686775689</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593411804245</td>\n",
       "      <td>1.071883468639</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.285380131024</td>\n",
       "      <td>0.274632193567</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 14:00:00</th>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-1.448686775689</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071883468639</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.274632193567</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 16:00:00</th>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>-1.169555872229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 18:00:00</th>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>-1.169555872229</td>\n",
       "      <td>-1.245976862040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "      <td>0.777770015780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                      target                                 \\\n",
       "feature                          y                                  \n",
       "time step                      t+1            t+2             t+3   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-25 22:00:00 0.329539415970 0.018233689588  0.201057023550   \n",
       "2017-11-26 12:00:00 0.018233689588 0.201057023550  0.145796194985   \n",
       "2017-11-26 14:00:00 0.201057023550 0.145796194985  0.744459196048   \n",
       "2017-11-26 16:00:00 0.145796194985 0.744459196048  0.112178064184   \n",
       "2017-11-26 18:00:00 0.744459196048 0.112178064184 -0.327148903700   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                       t+4             t+5             t+6   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.145796194985  0.744459196048  0.112178064184   \n",
       "2017-11-26 12:00:00  0.744459196048  0.112178064184 -0.327148903700   \n",
       "2017-11-26 14:00:00  0.112178064184 -0.327148903700 -0.628321385686   \n",
       "2017-11-26 16:00:00 -0.327148903700 -0.628321385686 -0.366752336535   \n",
       "2017-11-26 18:00:00 -0.628321385686 -0.366752336535 -0.332675469409   \n",
       "\n",
       "tensor                            X                                  \\\n",
       "feature                         Crs                                   \n",
       "time step                       t-5             t-4             t-3   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -1.536117569116 -1.573680428514 -1.448686775689   \n",
       "2017-11-26 12:00:00 -1.573680428514 -1.448686775689 -1.355427262700   \n",
       "2017-11-26 14:00:00 -1.448686775689 -1.355427262700 -1.253748488122   \n",
       "2017-11-26 16:00:00 -1.355427262700 -1.253748488122 -1.280301543903   \n",
       "2017-11-26 18:00:00 -1.253748488122 -1.280301543903 -1.169555872229   \n",
       "\n",
       "tensor                               ...                                \\\n",
       "feature                              ...         sqrt_A                  \n",
       "time step                       t-2  ...            t-3            t-2   \n",
       "Epoch_Time_of_Clock                  ...                                 \n",
       "2017-11-25 22:00:00 -1.355427262700  ... 0.654660349438 0.593411804245   \n",
       "2017-11-26 12:00:00 -1.253748488122  ... 0.593411804245 1.071883468639   \n",
       "2017-11-26 14:00:00 -1.280301543903  ... 1.071883468639 0.549662843424   \n",
       "2017-11-26 16:00:00 -1.169555872229  ... 0.549662843424 0.329539415970   \n",
       "2017-11-26 18:00:00 -1.245976862040  ... 0.329539415970 0.018233689588   \n",
       "\n",
       "tensor                                                            \\\n",
       "feature                                                      Crc   \n",
       "time step                      t-1              t            t-5   \n",
       "Epoch_Time_of_Clock                                                \n",
       "2017-11-25 22:00:00 1.071883468639 0.549662843424 0.428462048423   \n",
       "2017-11-26 12:00:00 0.549662843424 0.329539415970 0.285380131024   \n",
       "2017-11-26 14:00:00 0.329539415970 0.018233689588 0.274632193567   \n",
       "2017-11-26 16:00:00 0.018233689588 0.201057023550 0.373378868955   \n",
       "2017-11-26 18:00:00 0.201057023550 0.145796194985 0.528552215992   \n",
       "\n",
       "tensor                                                            \\\n",
       "feature                                                            \n",
       "time step                      t-4            t-3            t-2   \n",
       "Epoch_Time_of_Clock                                                \n",
       "2017-11-25 22:00:00 0.285380131024 0.274632193567 0.373378868955   \n",
       "2017-11-26 12:00:00 0.274632193567 0.373378868955 0.528552215992   \n",
       "2017-11-26 14:00:00 0.373378868955 0.528552215992 0.709923660582   \n",
       "2017-11-26 16:00:00 0.528552215992 0.709923660582 0.899356058265   \n",
       "2017-11-26 18:00:00 0.709923660582 0.899356058265 0.798594144604   \n",
       "\n",
       "tensor                                             \n",
       "feature                                            \n",
       "time step                      t-1              t  \n",
       "Epoch_Time_of_Clock                                \n",
       "2017-11-25 22:00:00 0.528552215992 0.709923660582  \n",
       "2017-11-26 12:00:00 0.709923660582 0.899356058265  \n",
       "2017-11-26 14:00:00 0.899356058265 0.798594144604  \n",
       "2017-11-26 16:00:00 0.798594144604 0.722686836313  \n",
       "2017-11-26 18:00:00 0.722686836313 0.777770015780  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back_dt = dt.datetime.strptime(test_start_dt, '%Y-%m-%d %H:%M:%S') - dt.timedelta(hours=T-1)\n",
    "test = df.copy()[test_start_dt:][['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc']]\n",
    "test[['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc']] = X_scaler.transform(test)\n",
    "test_inputs = TimeSeriesTensor(test, var_name, HORIZON, tensor_structure,freq =None)\n",
    "test_inputs.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"6\" halign=\"left\">target</th>\n",
       "      <th colspan=\"15\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"6\" halign=\"left\">y</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Crs</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sqrt_A</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>...</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-25 22:00:00</th>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-1.536117569116</td>\n",
       "      <td>-1.573680428514</td>\n",
       "      <td>-1.448686775689</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654660349438</td>\n",
       "      <td>0.593411804245</td>\n",
       "      <td>1.071883468639</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.428462048423</td>\n",
       "      <td>0.285380131024</td>\n",
       "      <td>0.274632193567</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 12:00:00</th>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-1.573680428514</td>\n",
       "      <td>-1.448686775689</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593411804245</td>\n",
       "      <td>1.071883468639</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.285380131024</td>\n",
       "      <td>0.274632193567</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 14:00:00</th>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-1.448686775689</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071883468639</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.274632193567</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 16:00:00</th>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-1.355427262700</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>-1.169555872229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549662843424</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.373378868955</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 18:00:00</th>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>-1.253748488122</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>-1.169555872229</td>\n",
       "      <td>-1.245976862040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329539415970</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.528552215992</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "      <td>0.777770015780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 20:00:00</th>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-1.280301543903</td>\n",
       "      <td>-1.169555872229</td>\n",
       "      <td>-1.245976862040</td>\n",
       "      <td>-1.183803853380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018233689588</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.709923660582</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "      <td>0.777770015780</td>\n",
       "      <td>0.899356058265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-26 22:00:00</th>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-1.169555872229</td>\n",
       "      <td>-1.245976862040</td>\n",
       "      <td>-1.183803853380</td>\n",
       "      <td>-1.114506854146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201057023550</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "      <td>0.777770015780</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>1.104238616042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 12:00:00</th>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.245976862040</td>\n",
       "      <td>-1.183803853380</td>\n",
       "      <td>-1.114506854146</td>\n",
       "      <td>-0.953893248443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145796194985</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>0.798594144604</td>\n",
       "      <td>0.722686836313</td>\n",
       "      <td>0.777770015780</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>1.104238616042</td>\n",
       "      <td>1.192909100063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 14:00:00</th>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-1.183803853380</td>\n",
       "      <td>-1.114506854146</td>\n",
       "      <td>-0.953893248443</td>\n",
       "      <td>-0.905968220935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744459196048</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>0.722686836313</td>\n",
       "      <td>0.777770015780</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>1.104238616042</td>\n",
       "      <td>1.192909100063</td>\n",
       "      <td>1.142528143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 16:00:00</th>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-1.114506854146</td>\n",
       "      <td>-0.953893248443</td>\n",
       "      <td>-0.905968220935</td>\n",
       "      <td>-0.632666037037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112178064184</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>0.777770015780</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>1.104238616042</td>\n",
       "      <td>1.192909100063</td>\n",
       "      <td>1.142528143233</td>\n",
       "      <td>1.050498928756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 18:00:00</th>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.953893248443</td>\n",
       "      <td>-0.905968220935</td>\n",
       "      <td>-0.632666037037</td>\n",
       "      <td>-0.723982643505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327148903700</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.899356058265</td>\n",
       "      <td>1.104238616042</td>\n",
       "      <td>1.192909100063</td>\n",
       "      <td>1.142528143233</td>\n",
       "      <td>1.050498928756</td>\n",
       "      <td>1.083414487219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 20:00:00</th>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.905968220935</td>\n",
       "      <td>-0.632666037037</td>\n",
       "      <td>-0.723982643505</td>\n",
       "      <td>-0.729163727560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628321385686</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>1.104238616042</td>\n",
       "      <td>1.192909100063</td>\n",
       "      <td>1.142528143233</td>\n",
       "      <td>1.050498928756</td>\n",
       "      <td>1.083414487219</td>\n",
       "      <td>1.152604334599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27 22:00:00</th>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>-0.632666037037</td>\n",
       "      <td>-0.723982643505</td>\n",
       "      <td>-0.729163727560</td>\n",
       "      <td>-0.711677568875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366752336535</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>1.192909100063</td>\n",
       "      <td>1.142528143233</td>\n",
       "      <td>1.050498928756</td>\n",
       "      <td>1.083414487219</td>\n",
       "      <td>1.152604334599</td>\n",
       "      <td>1.317853873003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>-1.241721895234</td>\n",
       "      <td>-0.723982643505</td>\n",
       "      <td>-0.729163727560</td>\n",
       "      <td>-0.711677568875</td>\n",
       "      <td>-0.513501103773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332675469409</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>1.142528143233</td>\n",
       "      <td>1.050498928756</td>\n",
       "      <td>1.083414487219</td>\n",
       "      <td>1.152604334599</td>\n",
       "      <td>1.317853873003</td>\n",
       "      <td>1.224481166344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>-1.241721895234</td>\n",
       "      <td>-1.410268871190</td>\n",
       "      <td>-0.729163727560</td>\n",
       "      <td>-0.711677568875</td>\n",
       "      <td>-0.513501103773</td>\n",
       "      <td>-0.407288880647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327697227327</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>1.050498928756</td>\n",
       "      <td>1.083414487219</td>\n",
       "      <td>1.152604334599</td>\n",
       "      <td>1.317853873003</td>\n",
       "      <td>1.224481166344</td>\n",
       "      <td>1.214404974978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>-1.241721895234</td>\n",
       "      <td>-1.410268871190</td>\n",
       "      <td>-1.375730853365</td>\n",
       "      <td>-0.711677568875</td>\n",
       "      <td>-0.513501103773</td>\n",
       "      <td>-0.407288880647</td>\n",
       "      <td>-0.017412305514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242415472100</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>1.083414487219</td>\n",
       "      <td>1.152604334599</td>\n",
       "      <td>1.317853873003</td>\n",
       "      <td>1.224481166344</td>\n",
       "      <td>1.214404974978</td>\n",
       "      <td>1.158650049419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>-1.241721895234</td>\n",
       "      <td>-1.410268871190</td>\n",
       "      <td>-1.375730853365</td>\n",
       "      <td>-1.031268147101</td>\n",
       "      <td>-0.513501103773</td>\n",
       "      <td>-0.407288880647</td>\n",
       "      <td>-0.017412305514</td>\n",
       "      <td>-0.097719108365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.903708056080</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>1.152604334599</td>\n",
       "      <td>1.317853873003</td>\n",
       "      <td>1.224481166344</td>\n",
       "      <td>1.214404974978</td>\n",
       "      <td>1.158650049419</td>\n",
       "      <td>1.196939576610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>-1.241721895234</td>\n",
       "      <td>-1.410268871190</td>\n",
       "      <td>-1.375730853365</td>\n",
       "      <td>-1.031268147101</td>\n",
       "      <td>-0.481419521869</td>\n",
       "      <td>-0.407288880647</td>\n",
       "      <td>-0.017412305514</td>\n",
       "      <td>-0.097719108365</td>\n",
       "      <td>-0.146291771380</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.147318784535</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>1.317853873003</td>\n",
       "      <td>1.224481166344</td>\n",
       "      <td>1.214404974978</td>\n",
       "      <td>1.158650049419</td>\n",
       "      <td>1.196939576610</td>\n",
       "      <td>1.209031006249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>-1.241721895234</td>\n",
       "      <td>-1.410268871190</td>\n",
       "      <td>-1.375730853365</td>\n",
       "      <td>-1.031268147101</td>\n",
       "      <td>-0.481419521869</td>\n",
       "      <td>-0.379647656817</td>\n",
       "      <td>-0.017412305514</td>\n",
       "      <td>-0.097719108365</td>\n",
       "      <td>-0.146291771380</td>\n",
       "      <td>-0.190330985847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.947457016901</td>\n",
       "      <td>-0.764172532240</td>\n",
       "      <td>-0.113933079899</td>\n",
       "      <td>-0.424777655362</td>\n",
       "      <td>1.224481166344</td>\n",
       "      <td>1.214404974978</td>\n",
       "      <td>1.158650049419</td>\n",
       "      <td>1.196939576610</td>\n",
       "      <td>1.209031006249</td>\n",
       "      <td>1.272175138810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                       target                                  \\\n",
       "feature                           y                                   \n",
       "time step                       t+1             t+2             t+3   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.329539415970  0.018233689588  0.201057023550   \n",
       "2017-11-26 12:00:00  0.018233689588  0.201057023550  0.145796194985   \n",
       "2017-11-26 14:00:00  0.201057023550  0.145796194985  0.744459196048   \n",
       "2017-11-26 16:00:00  0.145796194985  0.744459196048  0.112178064184   \n",
       "2017-11-26 18:00:00  0.744459196048  0.112178064184 -0.327148903700   \n",
       "2017-11-26 20:00:00  0.112178064184 -0.327148903700 -0.628321385686   \n",
       "2017-11-26 22:00:00 -0.327148903700 -0.628321385686 -0.366752336535   \n",
       "2017-11-27 12:00:00 -0.628321385686 -0.366752336535 -0.332675469409   \n",
       "2017-11-27 14:00:00 -0.366752336535 -0.332675469409  0.327697227327   \n",
       "2017-11-27 16:00:00 -0.332675469409  0.327697227327 -0.242415472100   \n",
       "2017-11-27 18:00:00  0.327697227327 -0.242415472100 -0.903708056080   \n",
       "2017-11-27 20:00:00 -0.242415472100 -0.903708056080 -1.147318784535   \n",
       "2017-11-27 22:00:00 -0.903708056080 -1.147318784535 -0.947457016901   \n",
       "2017-11-28 12:00:00 -1.147318784535 -0.947457016901 -0.764172532240   \n",
       "2017-11-28 14:00:00 -0.947457016901 -0.764172532240 -0.113933079899   \n",
       "2017-11-28 16:00:00 -0.764172532240 -0.113933079899 -0.424777655362   \n",
       "2017-11-28 18:00:00 -0.113933079899 -0.424777655362 -1.241721895234   \n",
       "2017-11-28 20:00:00 -0.424777655362 -1.241721895234 -1.410268871190   \n",
       "2017-11-28 22:00:00 -1.241721895234 -1.410268871190 -1.375730853365   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                       t+4             t+5             t+6   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00  0.145796194985  0.744459196048  0.112178064184   \n",
       "2017-11-26 12:00:00  0.744459196048  0.112178064184 -0.327148903700   \n",
       "2017-11-26 14:00:00  0.112178064184 -0.327148903700 -0.628321385686   \n",
       "2017-11-26 16:00:00 -0.327148903700 -0.628321385686 -0.366752336535   \n",
       "2017-11-26 18:00:00 -0.628321385686 -0.366752336535 -0.332675469409   \n",
       "2017-11-26 20:00:00 -0.366752336535 -0.332675469409  0.327697227327   \n",
       "2017-11-26 22:00:00 -0.332675469409  0.327697227327 -0.242415472100   \n",
       "2017-11-27 12:00:00  0.327697227327 -0.242415472100 -0.903708056080   \n",
       "2017-11-27 14:00:00 -0.242415472100 -0.903708056080 -1.147318784535   \n",
       "2017-11-27 16:00:00 -0.903708056080 -1.147318784535 -0.947457016901   \n",
       "2017-11-27 18:00:00 -1.147318784535 -0.947457016901 -0.764172532240   \n",
       "2017-11-27 20:00:00 -0.947457016901 -0.764172532240 -0.113933079899   \n",
       "2017-11-27 22:00:00 -0.764172532240 -0.113933079899 -0.424777655362   \n",
       "2017-11-28 12:00:00 -0.113933079899 -0.424777655362 -1.241721895234   \n",
       "2017-11-28 14:00:00 -0.424777655362 -1.241721895234 -1.410268871190   \n",
       "2017-11-28 16:00:00 -1.241721895234 -1.410268871190 -1.375730853365   \n",
       "2017-11-28 18:00:00 -1.410268871190 -1.375730853365 -1.031268147101   \n",
       "2017-11-28 20:00:00 -1.375730853365 -1.031268147101 -0.481419521869   \n",
       "2017-11-28 22:00:00 -1.031268147101 -0.481419521869 -0.379647656817   \n",
       "\n",
       "tensor                            X                                  \\\n",
       "feature                         Crs                                   \n",
       "time step                       t-5             t-4             t-3   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-25 22:00:00 -1.536117569116 -1.573680428514 -1.448686775689   \n",
       "2017-11-26 12:00:00 -1.573680428514 -1.448686775689 -1.355427262700   \n",
       "2017-11-26 14:00:00 -1.448686775689 -1.355427262700 -1.253748488122   \n",
       "2017-11-26 16:00:00 -1.355427262700 -1.253748488122 -1.280301543903   \n",
       "2017-11-26 18:00:00 -1.253748488122 -1.280301543903 -1.169555872229   \n",
       "2017-11-26 20:00:00 -1.280301543903 -1.169555872229 -1.245976862040   \n",
       "2017-11-26 22:00:00 -1.169555872229 -1.245976862040 -1.183803853380   \n",
       "2017-11-27 12:00:00 -1.245976862040 -1.183803853380 -1.114506854146   \n",
       "2017-11-27 14:00:00 -1.183803853380 -1.114506854146 -0.953893248443   \n",
       "2017-11-27 16:00:00 -1.114506854146 -0.953893248443 -0.905968220935   \n",
       "2017-11-27 18:00:00 -0.953893248443 -0.905968220935 -0.632666037037   \n",
       "2017-11-27 20:00:00 -0.905968220935 -0.632666037037 -0.723982643505   \n",
       "2017-11-27 22:00:00 -0.632666037037 -0.723982643505 -0.729163727560   \n",
       "2017-11-28 12:00:00 -0.723982643505 -0.729163727560 -0.711677568875   \n",
       "2017-11-28 14:00:00 -0.729163727560 -0.711677568875 -0.513501103773   \n",
       "2017-11-28 16:00:00 -0.711677568875 -0.513501103773 -0.407288880647   \n",
       "2017-11-28 18:00:00 -0.513501103773 -0.407288880647 -0.017412305514   \n",
       "2017-11-28 20:00:00 -0.407288880647 -0.017412305514 -0.097719108365   \n",
       "2017-11-28 22:00:00 -0.017412305514 -0.097719108365 -0.146291771380   \n",
       "\n",
       "tensor                               ...                                  \\\n",
       "feature                              ...          sqrt_A                   \n",
       "time step                       t-2  ...             t-3             t-2   \n",
       "Epoch_Time_of_Clock                  ...                                   \n",
       "2017-11-25 22:00:00 -1.355427262700  ...  0.654660349438  0.593411804245   \n",
       "2017-11-26 12:00:00 -1.253748488122  ...  0.593411804245  1.071883468639   \n",
       "2017-11-26 14:00:00 -1.280301543903  ...  1.071883468639  0.549662843424   \n",
       "2017-11-26 16:00:00 -1.169555872229  ...  0.549662843424  0.329539415970   \n",
       "2017-11-26 18:00:00 -1.245976862040  ...  0.329539415970  0.018233689588   \n",
       "2017-11-26 20:00:00 -1.183803853380  ...  0.018233689588  0.201057023550   \n",
       "2017-11-26 22:00:00 -1.114506854146  ...  0.201057023550  0.145796194985   \n",
       "2017-11-27 12:00:00 -0.953893248443  ...  0.145796194985  0.744459196048   \n",
       "2017-11-27 14:00:00 -0.905968220935  ...  0.744459196048  0.112178064184   \n",
       "2017-11-27 16:00:00 -0.632666037037  ...  0.112178064184 -0.327148903700   \n",
       "2017-11-27 18:00:00 -0.723982643505  ... -0.327148903700 -0.628321385686   \n",
       "2017-11-27 20:00:00 -0.729163727560  ... -0.628321385686 -0.366752336535   \n",
       "2017-11-27 22:00:00 -0.711677568875  ... -0.366752336535 -0.332675469409   \n",
       "2017-11-28 12:00:00 -0.513501103773  ... -0.332675469409  0.327697227327   \n",
       "2017-11-28 14:00:00 -0.407288880647  ...  0.327697227327 -0.242415472100   \n",
       "2017-11-28 16:00:00 -0.017412305514  ... -0.242415472100 -0.903708056080   \n",
       "2017-11-28 18:00:00 -0.097719108365  ... -0.903708056080 -1.147318784535   \n",
       "2017-11-28 20:00:00 -0.146291771380  ... -1.147318784535 -0.947457016901   \n",
       "2017-11-28 22:00:00 -0.190330985847  ... -0.947457016901 -0.764172532240   \n",
       "\n",
       "tensor                                                              \\\n",
       "feature                                                        Crc   \n",
       "time step                       t-1               t            t-5   \n",
       "Epoch_Time_of_Clock                                                  \n",
       "2017-11-25 22:00:00  1.071883468639  0.549662843424 0.428462048423   \n",
       "2017-11-26 12:00:00  0.549662843424  0.329539415970 0.285380131024   \n",
       "2017-11-26 14:00:00  0.329539415970  0.018233689588 0.274632193567   \n",
       "2017-11-26 16:00:00  0.018233689588  0.201057023550 0.373378868955   \n",
       "2017-11-26 18:00:00  0.201057023550  0.145796194985 0.528552215992   \n",
       "2017-11-26 20:00:00  0.145796194985  0.744459196048 0.709923660582   \n",
       "2017-11-26 22:00:00  0.744459196048  0.112178064184 0.899356058265   \n",
       "2017-11-27 12:00:00  0.112178064184 -0.327148903700 0.798594144604   \n",
       "2017-11-27 14:00:00 -0.327148903700 -0.628321385686 0.722686836313   \n",
       "2017-11-27 16:00:00 -0.628321385686 -0.366752336535 0.777770015780   \n",
       "2017-11-27 18:00:00 -0.366752336535 -0.332675469409 0.899356058265   \n",
       "2017-11-27 20:00:00 -0.332675469409  0.327697227327 1.104238616042   \n",
       "2017-11-27 22:00:00  0.327697227327 -0.242415472100 1.192909100063   \n",
       "2017-11-28 12:00:00 -0.242415472100 -0.903708056080 1.142528143233   \n",
       "2017-11-28 14:00:00 -0.903708056080 -1.147318784535 1.050498928756   \n",
       "2017-11-28 16:00:00 -1.147318784535 -0.947457016901 1.083414487219   \n",
       "2017-11-28 18:00:00 -0.947457016901 -0.764172532240 1.152604334599   \n",
       "2017-11-28 20:00:00 -0.764172532240 -0.113933079899 1.317853873003   \n",
       "2017-11-28 22:00:00 -0.113933079899 -0.424777655362 1.224481166344   \n",
       "\n",
       "tensor                                                            \\\n",
       "feature                                                            \n",
       "time step                      t-4            t-3            t-2   \n",
       "Epoch_Time_of_Clock                                                \n",
       "2017-11-25 22:00:00 0.285380131024 0.274632193567 0.373378868955   \n",
       "2017-11-26 12:00:00 0.274632193567 0.373378868955 0.528552215992   \n",
       "2017-11-26 14:00:00 0.373378868955 0.528552215992 0.709923660582   \n",
       "2017-11-26 16:00:00 0.528552215992 0.709923660582 0.899356058265   \n",
       "2017-11-26 18:00:00 0.709923660582 0.899356058265 0.798594144604   \n",
       "2017-11-26 20:00:00 0.899356058265 0.798594144604 0.722686836313   \n",
       "2017-11-26 22:00:00 0.798594144604 0.722686836313 0.777770015780   \n",
       "2017-11-27 12:00:00 0.722686836313 0.777770015780 0.899356058265   \n",
       "2017-11-27 14:00:00 0.777770015780 0.899356058265 1.104238616042   \n",
       "2017-11-27 16:00:00 0.899356058265 1.104238616042 1.192909100063   \n",
       "2017-11-27 18:00:00 1.104238616042 1.192909100063 1.142528143233   \n",
       "2017-11-27 20:00:00 1.192909100063 1.142528143233 1.050498928756   \n",
       "2017-11-27 22:00:00 1.142528143233 1.050498928756 1.083414487219   \n",
       "2017-11-28 12:00:00 1.050498928756 1.083414487219 1.152604334599   \n",
       "2017-11-28 14:00:00 1.083414487219 1.152604334599 1.317853873003   \n",
       "2017-11-28 16:00:00 1.152604334599 1.317853873003 1.224481166344   \n",
       "2017-11-28 18:00:00 1.317853873003 1.224481166344 1.214404974978   \n",
       "2017-11-28 20:00:00 1.224481166344 1.214404974978 1.158650049419   \n",
       "2017-11-28 22:00:00 1.214404974978 1.158650049419 1.196939576610   \n",
       "\n",
       "tensor                                             \n",
       "feature                                            \n",
       "time step                      t-1              t  \n",
       "Epoch_Time_of_Clock                                \n",
       "2017-11-25 22:00:00 0.528552215992 0.709923660582  \n",
       "2017-11-26 12:00:00 0.709923660582 0.899356058265  \n",
       "2017-11-26 14:00:00 0.899356058265 0.798594144604  \n",
       "2017-11-26 16:00:00 0.798594144604 0.722686836313  \n",
       "2017-11-26 18:00:00 0.722686836313 0.777770015780  \n",
       "2017-11-26 20:00:00 0.777770015780 0.899356058265  \n",
       "2017-11-26 22:00:00 0.899356058265 1.104238616042  \n",
       "2017-11-27 12:00:00 1.104238616042 1.192909100063  \n",
       "2017-11-27 14:00:00 1.192909100063 1.142528143233  \n",
       "2017-11-27 16:00:00 1.142528143233 1.050498928756  \n",
       "2017-11-27 18:00:00 1.050498928756 1.083414487219  \n",
       "2017-11-27 20:00:00 1.083414487219 1.152604334599  \n",
       "2017-11-27 22:00:00 1.152604334599 1.317853873003  \n",
       "2017-11-28 12:00:00 1.317853873003 1.224481166344  \n",
       "2017-11-28 14:00:00 1.224481166344 1.214404974978  \n",
       "2017-11-28 16:00:00 1.214404974978 1.158650049419  \n",
       "2017-11-28 18:00:00 1.158650049419 1.196939576610  \n",
       "2017-11-28 20:00:00 1.196939576610 1.209031006249  \n",
       "2017-11-28 22:00:00 1.209031006249 1.272175138810  \n",
       "\n",
       "[19 rows x 36 columns]"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.dataframe.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 36)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.9523295e-01,  6.4525291e-02,  3.2252744e-01,  9.2291608e-02,\n",
       "         1.6125304e-01, -2.1307507e-01],\n",
       "       [ 7.9024777e-02,  2.7002031e-01,  2.2530787e-01,  2.2932312e-01,\n",
       "         3.6219660e-02, -8.3716959e-04],\n",
       "       [ 1.8830797e-01,  2.1658339e-02,  2.0841354e-01,  9.5799221e-03,\n",
       "         3.1525005e-02, -3.2365134e-01],\n",
       "       [ 2.1434596e-01, -1.4544243e-01,  8.8306025e-02, -8.8593751e-02,\n",
       "        -9.2784688e-02, -4.2568845e-01],\n",
       "       [ 2.3696394e-01, -2.6540101e-01, -2.4137467e-02, -1.7427079e-01,\n",
       "        -2.1514784e-01, -4.9797401e-01],\n",
       "       [ 1.1172703e-01, -3.2287627e-01, -1.6391514e-01, -3.1983590e-01,\n",
       "        -3.6314633e-01, -5.6551820e-01],\n",
       "       [-1.7033124e-01, -2.7541885e-01, -2.6643953e-01, -3.3307067e-01,\n",
       "        -4.1832441e-01, -5.3394133e-01],\n",
       "       [-4.5704946e-01, -2.4091789e-01, -1.7643741e-01, -2.3838881e-01,\n",
       "        -3.1392372e-01, -3.8005587e-01],\n",
       "       [-3.4611124e-01, -2.9084399e-01, -3.3835796e-01, -3.2544938e-01,\n",
       "        -5.0555503e-01, -5.9155411e-01],\n",
       "       [-2.9823360e-01, -4.3088320e-01, -3.8904086e-01, -4.7106692e-01,\n",
       "        -5.9308541e-01, -7.7904636e-01],\n",
       "       [-1.6771980e-01, -5.6777549e-01, -4.4909832e-01, -6.2477553e-01,\n",
       "        -6.8899775e-01, -9.1941231e-01],\n",
       "       [-2.4576423e-01, -6.4553112e-01, -6.5826923e-01, -7.7469045e-01,\n",
       "        -8.4131813e-01, -9.3894380e-01],\n",
       "       [-7.5750268e-01, -7.7180928e-01, -7.3119587e-01, -6.8697673e-01,\n",
       "        -6.6654843e-01, -6.5975410e-01],\n",
       "       [-9.4251883e-01, -8.3543456e-01, -5.8419353e-01, -4.7887540e-01,\n",
       "        -5.7766587e-01, -6.2967390e-01],\n",
       "       [-9.0712804e-01, -5.4701781e-01, -6.2449735e-01, -6.3925618e-01,\n",
       "        -7.7104515e-01, -8.5631686e-01],\n",
       "       [-8.0574244e-01, -5.2643228e-01, -7.9095393e-01, -6.3317984e-01,\n",
       "        -1.0217738e+00, -9.6704417e-01],\n",
       "       [-4.8144379e-01, -7.0738286e-01, -7.9668576e-01, -9.0604937e-01,\n",
       "        -1.0514954e+00, -1.1708217e+00],\n",
       "       [-4.8101386e-01, -9.2752606e-01, -1.0631075e+00, -1.1136026e+00,\n",
       "        -1.1047366e+00, -1.0601528e+00],\n",
       "       [-1.1267238e+00, -1.2344683e+00, -1.2209716e+00, -9.9331826e-01,\n",
       "        -5.8704245e-01, -5.1023000e-01]], dtype=float32)"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp    h         prediction             actual\n",
      "0 2017-11-25 22:00:00  t+1 5,153.677893930293 5,153.677621840000\n",
      "1 2017-11-26 12:00:00  t+1 5,153.676584255295 5,153.676332470000\n",
      "2 2017-11-26 14:00:00  t+1 5,153.677036885812 5,153.677089690000\n",
      "3 2017-11-26 16:00:00  t+1 5,153.677144730293 5,153.676860810000\n",
      "4 2017-11-26 18:00:00  t+1 5,153.677238409732 5,153.679340360000\n",
      "              timestamp    h         prediction             actual\n",
      "109 2017-11-28 14:00:00  t+6 5,153.672710245438 5,153.670415880000\n",
      "110 2017-11-28 16:00:00  t+6 5,153.672251633662 5,153.670558930000\n",
      "111 2017-11-28 18:00:00  t+6 5,153.671407625465 5,153.671985630000\n",
      "112 2017-11-28 20:00:00  t+6 5,153.671865995307 5,153.674263000000\n",
      "113 2017-11-28 22:00:00  t+6 5,153.674143672377 5,153.674684520000\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "eval_df = create_evaluation_df(predictions, test_inputs, HORIZON, y_scalar)\n",
    "print(eval_df.head())\n",
    "print(eval_df.tail())\n",
    "print(eval_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h\n",
       "t+1   0.000000108677\n",
       "t+2   0.000000222641\n",
       "t+3   0.000000243685\n",
       "t+4   0.000000222390\n",
       "t+5   0.000000249938\n",
       "t+6   0.000000306738\n",
       "Name: APE, dtype: float64"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']\n",
    "eval_df.groupby('h')['APE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001163070432731298"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(eval_df['prediction'], eval_df['actual'])\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "a = mean_absolute_error(eval_df['prediction'], eval_df['actual'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5,153.677893930293\n",
       "1     5,153.676584255295\n",
       "2     5,153.677036885812\n",
       "3     5,153.677144730293\n",
       "4     5,153.677238409732\n",
       "5     5,153.676719701897\n",
       "6     5,153.675551469387\n",
       "7     5,153.674363936234\n",
       "8     5,153.674823421564\n",
       "9     5,153.675021721778\n",
       "10    5,153.675562285496\n",
       "11    5,153.675239040091\n",
       "12    5,153.673119515299\n",
       "13    5,153.672353213044\n",
       "14    5,153.672499795084\n",
       "15    5,153.672919715219\n",
       "16    5,153.674262899475\n",
       "17    5,153.674264680158\n",
       "18    5,153.671590270706\n",
       "19    5,153.676524201142\n",
       "20    5,153.677375322997\n",
       "21    5,153.676346654254\n",
       "22    5,153.675654554190\n",
       "23    5,153.675157708226\n",
       "24    5,153.674919656430\n",
       "25    5,153.675116216201\n",
       "26    5,153.675259112700\n",
       "27    5,153.675052328137\n",
       "28    5,153.674472311982\n",
       "29    5,153.673905329766\n",
       "             ...        \n",
       "84    5,153.674163035232\n",
       "85    5,153.673800500817\n",
       "86    5,153.673403249884\n",
       "87    5,153.672772367384\n",
       "88    5,153.673496230739\n",
       "89    5,153.673864365675\n",
       "90    5,153.673063424912\n",
       "91    5,153.672024953744\n",
       "92    5,153.671901852372\n",
       "93    5,153.671681337570\n",
       "94    5,153.673825529615\n",
       "95    5,153.675374432443\n",
       "96    5,153.676253482074\n",
       "97    5,153.674916446239\n",
       "98    5,153.674493827678\n",
       "99    5,153.674194434418\n",
       "100   5,153.673914679028\n",
       "101   5,153.674045464516\n",
       "102   5,153.674682829238\n",
       "103   5,153.673806843188\n",
       "104   5,153.673030285406\n",
       "105   5,153.672448915902\n",
       "106   5,153.672368020136\n",
       "107   5,153.673524371596\n",
       "108   5,153.673648958146\n",
       "109   5,153.672710245438\n",
       "110   5,153.672251633662\n",
       "111   5,153.671407625465\n",
       "112   5,153.671865995307\n",
       "113   5,153.674143672377\n",
       "Name: prediction, Length: 114, dtype: float64"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot actuals vs predictions at each horizon for first week of the test period. As is to be expected, predictions for one step ahead (*t+1*) are more accurate than those for 2 or 3 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]\n",
    "for t in range(1, HORIZON+1):\n",
    "    plot_df['t+'+str(t)] = eval_df[ (eval_df.h=='t+'+str(t))]['prediction'].values\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+1'], color='blue', linewidth=4.0, alpha=0.75)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+2'], color='blue', linewidth=3.0, alpha=0.5)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+3'], color='blue', linewidth=2.0, alpha=0.25)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>-7.843750000000</td>\n",
       "      <td>0.000000004682</td>\n",
       "      <td>-0.000000456348</td>\n",
       "      <td>5,153.672513960000</td>\n",
       "      <td>288.250000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>-11.718750000000</td>\n",
       "      <td>0.000000004718</td>\n",
       "      <td>-0.000000722706</td>\n",
       "      <td>5,153.671504970000</td>\n",
       "      <td>287.781250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>-14.062500000000</td>\n",
       "      <td>0.000000004688</td>\n",
       "      <td>-0.000000778586</td>\n",
       "      <td>5,153.672332760000</td>\n",
       "      <td>285.187500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>-16.187500000000</td>\n",
       "      <td>0.000000004695</td>\n",
       "      <td>-0.000000737607</td>\n",
       "      <td>5,153.673091890000</td>\n",
       "      <td>286.968750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>-6.312500000000</td>\n",
       "      <td>0.000000004596</td>\n",
       "      <td>-0.000000370666</td>\n",
       "      <td>5,153.675785060000</td>\n",
       "      <td>287.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>-0.562500000000</td>\n",
       "      <td>0.000000004587</td>\n",
       "      <td>-0.000000091270</td>\n",
       "      <td>5,153.674497600000</td>\n",
       "      <td>290.468750000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Crs          Del_n             Cuc  \\\n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-28 12:00:00  -7.843750000000 0.000000004682 -0.000000456348   \n",
       "2017-11-28 14:00:00 -11.718750000000 0.000000004718 -0.000000722706   \n",
       "2017-11-28 16:00:00 -14.062500000000 0.000000004688 -0.000000778586   \n",
       "2017-11-28 18:00:00 -16.187500000000 0.000000004695 -0.000000737607   \n",
       "2017-11-28 20:00:00  -6.312500000000 0.000000004596 -0.000000370666   \n",
       "2017-11-28 22:00:00  -0.562500000000 0.000000004587 -0.000000091270   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-28 12:00:00 5,153.672513960000 288.250000000000  \n",
       "2017-11-28 14:00:00 5,153.671504970000 287.781250000000  \n",
       "2017-11-28 16:00:00 5,153.672332760000 285.187500000000  \n",
       "2017-11-28 18:00:00 5,153.673091890000 286.968750000000  \n",
       "2017-11-28 20:00:00 5,153.675785060000 287.531250000000  \n",
       "2017-11-28 22:00:00 5,153.674497600000 290.468750000000  "
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.iloc[156:162  , :]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key , value in enumerate(columns):\n",
    "    new_df[value] = a[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna( how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>-7.843750000000</td>\n",
       "      <td>0.000000004682</td>\n",
       "      <td>-0.000000456348</td>\n",
       "      <td>5,153.672513960000</td>\n",
       "      <td>288.250000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>-11.718750000000</td>\n",
       "      <td>0.000000004718</td>\n",
       "      <td>-0.000000722706</td>\n",
       "      <td>5,153.671504970000</td>\n",
       "      <td>287.781250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>-14.062500000000</td>\n",
       "      <td>0.000000004688</td>\n",
       "      <td>-0.000000778586</td>\n",
       "      <td>5,153.672332760000</td>\n",
       "      <td>285.187500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>-16.187500000000</td>\n",
       "      <td>0.000000004695</td>\n",
       "      <td>-0.000000737607</td>\n",
       "      <td>5,153.673091890000</td>\n",
       "      <td>286.968750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>-6.312500000000</td>\n",
       "      <td>0.000000004596</td>\n",
       "      <td>-0.000000370666</td>\n",
       "      <td>5,153.675785060000</td>\n",
       "      <td>287.531250000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>-0.562500000000</td>\n",
       "      <td>0.000000004587</td>\n",
       "      <td>-0.000000091270</td>\n",
       "      <td>5,153.674497600000</td>\n",
       "      <td>290.468750000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Crs          Del_n             Cuc  \\\n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-28 12:00:00  -7.843750000000 0.000000004682 -0.000000456348   \n",
       "2017-11-28 14:00:00 -11.718750000000 0.000000004718 -0.000000722706   \n",
       "2017-11-28 16:00:00 -14.062500000000 0.000000004688 -0.000000778586   \n",
       "2017-11-28 18:00:00 -16.187500000000 0.000000004695 -0.000000737607   \n",
       "2017-11-28 20:00:00  -6.312500000000 0.000000004596 -0.000000370666   \n",
       "2017-11-28 22:00:00  -0.562500000000 0.000000004587 -0.000000091270   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-28 12:00:00 5,153.672513960000 288.250000000000  \n",
       "2017-11-28 14:00:00 5,153.671504970000 287.781250000000  \n",
       "2017-11-28 16:00:00 5,153.672332760000 285.187500000000  \n",
       "2017-11-28 18:00:00 5,153.673091890000 286.968750000000  \n",
       "2017-11-28 20:00:00 5,153.675785060000 287.531250000000  \n",
       "2017-11-28 22:00:00 5,153.674497600000 290.468750000000  "
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 11, 29)"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating index for output\n",
    "import datetime\n",
    "date = new_df.index.date[0]\n",
    "date + datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = new_df.index + datetime.timedelta(days =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-11-29 12:00:00', '2017-11-29 14:00:00',\n",
       "               '2017-11-29 16:00:00', '2017-11-29 18:00:00',\n",
       "               '2017-11-29 20:00:00', '2017-11-29 22:00:00'],\n",
       "              dtype='datetime64[ns]', name='Epoch_Time_of_Clock', freq='2H')"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.index= date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc'], dtype='object')"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Crs          Del_n             Cuc  \\\n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 12:00:00  -7.843750000000 0.000000004682 -0.000000456348   \n",
      "2017-11-29 14:00:00 -11.718750000000 0.000000004718 -0.000000722706   \n",
      "2017-11-29 16:00:00 -14.062500000000 0.000000004688 -0.000000778586   \n",
      "2017-11-29 18:00:00 -16.187500000000 0.000000004695 -0.000000737607   \n",
      "2017-11-29 20:00:00  -6.312500000000 0.000000004596 -0.000000370666   \n",
      "2017-11-29 22:00:00  -0.562500000000 0.000000004587 -0.000000091270   \n",
      "\n",
      "                                sqrt_A              Crc  \n",
      "Epoch_Time_of_Clock                                      \n",
      "2017-11-29 12:00:00 5,153.672513960000 288.250000000000  \n",
      "2017-11-29 14:00:00 5,153.671504970000 287.781250000000  \n",
      "2017-11-29 16:00:00 5,153.672332760000 285.187500000000  \n",
      "2017-11-29 18:00:00 5,153.673091890000 286.968750000000  \n",
      "2017-11-29 20:00:00 5,153.675785060000 287.531250000000  \n",
      "2017-11-29 22:00:00 5,153.674497600000 290.468750000000  \n",
      "Index(['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(new_df)\n",
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Crs          Del_n             Cuc  \\\n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 12:00:00 -0.017412305514 0.912690277182 -0.026884544478   \n",
      "2017-11-29 14:00:00 -0.097719108365 1.077670868243 -0.133261205663   \n",
      "2017-11-29 16:00:00 -0.146291771380 0.939920083469 -0.155577987730   \n",
      "2017-11-29 18:00:00 -0.190330985847 0.971955149724 -0.139212347547   \n",
      "2017-11-29 20:00:00  0.014321834323 0.529871235777  0.007334521358   \n",
      "\n",
      "                             sqrt_A            Crc  \n",
      "Epoch_Time_of_Clock                                 \n",
      "2017-11-29 12:00:00 -0.903708056080 1.224481166344  \n",
      "2017-11-29 14:00:00 -1.147318784535 1.214404974978  \n",
      "2017-11-29 16:00:00 -0.947457016901 1.158650049419  \n",
      "2017-11-29 18:00:00 -0.764172532240 1.196939576610  \n",
      "2017-11-29 20:00:00 -0.113933079899 1.209031006249  \n"
     ]
    }
   ],
   "source": [
    "freq = None\n",
    "idx_tuples = []\n",
    "drop_incomplete  = True\n",
    "new_df[['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc']] = X_scaler.transform(new_df)\n",
    "new_new_df = new_df.copy()\n",
    "tensor_structure={'X':(range(-T+1, 1), ['Crs', 'Del_n', 'Cuc', 'sqrt_A', 'Crc'])}\n",
    "for name, structure in tensor_structure.items():\n",
    "        rng = structure[0]\n",
    "        dataset_cols = structure[1]\n",
    "        for col in dataset_cols:\n",
    "        # do not shift non-sequential 'static' features\n",
    "            if rng is None:\n",
    "                new_df['context_'+col] = new_df[col]\n",
    "                idx_tuples.append((name, col, 'static'))\n",
    "            else:\n",
    "                for t in rng:\n",
    "                    sign = '+' if t > 0 else ''\n",
    "                    shift = str(t) if t != 0 else ''\n",
    "                    period = 't'+sign+shift\n",
    "                    shifted_col = name+'_'+col+'_'+ period\n",
    "                    new_new_df[shifted_col] = new_new_df[col].shift(t*-1, freq=freq)\n",
    "                    idx_tuples.append((name, col, period))\n",
    "        new_new_df = new_new_df.drop(new_df.columns, axis=1)\n",
    "        idx = pd.MultiIndex.from_tuples(idx_tuples, names=['tensor', 'feature', 'time step'])\n",
    "        print(new_df.head())\n",
    "        new_new_df.columns = idx\n",
    "        if drop_incomplete:\n",
    "            new_new_df = new_new_df.dropna(how='any')\n",
    "            \n",
    "inputs = {}           \n",
    "for name, structure in tensor_structure.items():\n",
    "    rng = structure[0]\n",
    "    cols = structure[1]\n",
    "    tensor = new_new_df[name][cols].as_matrix()\n",
    "    if rng is None:\n",
    "        tensor = tensor.reshape(tensor.shape[0], len(cols))\n",
    "    else:\n",
    "        tensor = tensor.reshape(tensor.shape[0], len(cols), len(rng))\n",
    "        tensor = np.transpose(tensor, axes=[0, 2, 1])\n",
    "    inputs[name] = tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor                            X                                  \\\n",
      "feature                         Crs                                   \n",
      "time step                       t-5             t-4             t-3   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -0.017412305514 -0.097719108365 -0.146291771380   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                       t-2            t-1              t   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 -0.190330985847 0.014321834323 0.133486767586   \n",
      "\n",
      "tensor                                                            \\\n",
      "feature                      Del_n                                 \n",
      "time step                      t-5            t-4            t-3   \n",
      "Epoch_Time_of_Clock                                                \n",
      "2017-11-29 22:00:00 0.912690277182 1.077670868243 0.939920083469   \n",
      "\n",
      "tensor                              ...                                  \\\n",
      "feature                             ...          sqrt_A                   \n",
      "time step                      t-2  ...             t-3             t-2   \n",
      "Epoch_Time_of_Clock                 ...                                   \n",
      "2017-11-29 22:00:00 0.971955149724  ... -0.947457016901 -0.764172532240   \n",
      "\n",
      "tensor                                                              \\\n",
      "feature                                                        Crc   \n",
      "time step                       t-1               t            t-5   \n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 22:00:00 -0.113933079899 -0.424777655362 1.224481166344   \n",
      "\n",
      "tensor                                                            \\\n",
      "feature                                                            \n",
      "time step                      t-4            t-3            t-2   \n",
      "Epoch_Time_of_Clock                                                \n",
      "2017-11-29 22:00:00 1.214404974978 1.158650049419 1.196939576610   \n",
      "\n",
      "tensor                                             \n",
      "feature                                            \n",
      "time step                      t-1              t  \n",
      "Epoch_Time_of_Clock                                \n",
      "2017-11-29 22:00:00 1.209031006249 1.272175138810  \n",
      "\n",
      "[1 rows x 30 columns]\n",
      "[[[-0.017412305514  0.912690277182 -0.026884544478 -0.90370805608\n",
      "    1.224481166344]\n",
      "  [-0.097719108365  1.077670868243 -0.133261205663 -1.147318784535\n",
      "    1.214404974978]\n",
      "  [-0.14629177138   0.939920083469 -0.15557798773  -0.947457016901\n",
      "    1.158650049419]\n",
      "  [-0.190330985847  0.971955149724 -0.139212347547 -0.76417253224\n",
      "    1.19693957661 ]\n",
      "  [ 0.014321834323  0.529871235777  0.007334521358 -0.113933079899\n",
      "    1.209031006249]\n",
      "  [ 0.133486767586  0.488225649677  0.118918431691 -0.424777655362\n",
      "    1.27217513881 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(new_new_df)\n",
    "print(inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1267238 , -1.2344683 , -1.2209716 , -0.99331826, -0.58704245,\n",
       "        -0.51023   ]], dtype=float32)"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictions[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1267238 , -1.2344683 , -1.2209716 , -0.99331826, -0.58704245,\n",
       "       -0.51023   ], dtype=float32)"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqrt_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.126723766327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.234468340874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.220971584320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.993318259716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.587042450905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.510230004787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sqrt_A\n",
       "0 -1.126723766327\n",
       "1 -1.234468340874\n",
       "2 -1.220971584320\n",
       "3 -0.993318259716\n",
       "4 -0.587042450905\n",
       "5 -0.510230004787"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results , columns = [var_name])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqrt_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>-1.126723766327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>-1.234468340874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>-1.220971584320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>-0.993318259716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>-0.587042450905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>-0.510230004787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sqrt_A\n",
       "Epoch_Time_of_Clock                \n",
       "2017-11-29 12:00:00 -1.126723766327\n",
       "2017-11-29 14:00:00 -1.234468340874\n",
       "2017-11-29 16:00:00 -1.220971584320\n",
       "2017-11-29 18:00:00 -0.993318259716\n",
       "2017-11-29 20:00:00 -0.587042450905\n",
       "2017-11-29 22:00:00 -0.510230004787"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.index = date\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqrt_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>-1.126723766327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>-1.234468340874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>-1.220971584320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>-0.993318259716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>-0.587042450905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>-0.510230004787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sqrt_A\n",
       "Epoch_Time_of_Clock                \n",
       "2017-11-29 12:00:00 -1.126723766327\n",
       "2017-11-29 14:00:00 -1.234468340874\n",
       "2017-11-29 16:00:00 -1.220971584320\n",
       "2017-11-29 18:00:00 -0.993318259716\n",
       "2017-11-29 20:00:00 -0.587042450905\n",
       "2017-11-29 22:00:00 -0.510230004787"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[[var_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[[var_name]] = y_scalar.inverse_transform(res_df[[var_name]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_df[[var_name]] = y_scalar.inverse_transform(res_df[[var_name]]) \n",
    "#pd.set_option(\"display.precision\", 8)\n",
    "#a = pd.Series( dtype = float)\n",
    "#list_b = []\n",
    "\n",
    "#for i in range(res_df.shape[0]):\n",
    "#    list_b.append( \"%.20f\"%res_df.iloc[i ,0])\n",
    "    \n",
    "\n",
    "#print(list_b)\n",
    "#for i in range(res_df.shape[0]):\n",
    "#    res_df.iloc[i , 1] = y_scalar.inverse_transform(np.array(res_df.iloc[i ,0]).reshape(1,-1))[0]\n",
    "#    c[0 , j] = y_scalar.inverse_transform(np.array(res_df.iloc[i ,0]).reshape(1,-1))[0]\n",
    "#    j +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print (y_scalar.inverse_transform(np.array(list_b).reshape(-1,1)))    \n",
    "\n",
    "\n",
    "#print (y_scalar.inverse_transform(list_b))    \n",
    "#a['prediction']\n",
    "#res_df['inverted'] = 0\n",
    "#c = np.array()\n",
    "#a\n",
    "#j=0\n",
    "\n",
    "#for i in range(res_df.shape[0]):\n",
    "    #res_df.iloc[i , 1] = y_scalar.inverse_transform(np.array(res_df.iloc[i ,0]).reshape(1,-1))[0]\n",
    "    #c[0 , j] = y_scalar.inverse_transform(np.array(res_df.iloc[i ,0]).reshape(1,-1))[0]\n",
    "    #j +=1\n",
    "\n",
    "#b = np.array(-1.08850443363189697266).reshape(1,-1)\n",
    "\n",
    "#y_scalar.inverse_transform(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final generated output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqrt_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>5,153.671386718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>5,153.671386718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>5,153.671386718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>5,153.672363281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>5,153.673828125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>5,153.674316406250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sqrt_A\n",
       "Epoch_Time_of_Clock                   \n",
       "2017-11-29 12:00:00 5,153.671386718750\n",
       "2017-11-29 14:00:00 5,153.671386718750\n",
       "2017-11-29 16:00:00 5,153.671386718750\n",
       "2017-11-29 18:00:00 5,153.672363281250\n",
       "2017-11-29 20:00:00 5,153.673828125000\n",
       "2017-11-29 22:00:00 5,153.674316406250"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final generated ouput\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('SA1SqrtA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crs</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cuc</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>19.437500000000</td>\n",
       "      <td>0.000000004697</td>\n",
       "      <td>0.000000964850</td>\n",
       "      <td>5,153.671113970000</td>\n",
       "      <td>275.218750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>16.781250000000</td>\n",
       "      <td>0.000000004731</td>\n",
       "      <td>0.000000741333</td>\n",
       "      <td>5,153.670415880000</td>\n",
       "      <td>275.343750000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>14.406250000000</td>\n",
       "      <td>0.000000004717</td>\n",
       "      <td>0.000000698492</td>\n",
       "      <td>5,153.670558930000</td>\n",
       "      <td>275.750000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>10.031250000000</td>\n",
       "      <td>0.000000004719</td>\n",
       "      <td>0.000000629574</td>\n",
       "      <td>5,153.671985630000</td>\n",
       "      <td>279.062500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>18.531250000000</td>\n",
       "      <td>0.000000004618</td>\n",
       "      <td>0.000000927597</td>\n",
       "      <td>5,153.674263000000</td>\n",
       "      <td>277.437500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>22.062500000000</td>\n",
       "      <td>0.000000004572</td>\n",
       "      <td>0.000001100823</td>\n",
       "      <td>5,153.674684520000</td>\n",
       "      <td>274.031250000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Crs          Del_n            Cuc  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-29 12:00:00 19.437500000000 0.000000004697 0.000000964850   \n",
       "2017-11-29 14:00:00 16.781250000000 0.000000004731 0.000000741333   \n",
       "2017-11-29 16:00:00 14.406250000000 0.000000004717 0.000000698492   \n",
       "2017-11-29 18:00:00 10.031250000000 0.000000004719 0.000000629574   \n",
       "2017-11-29 20:00:00 18.531250000000 0.000000004618 0.000000927597   \n",
       "2017-11-29 22:00:00 22.062500000000 0.000000004572 0.000001100823   \n",
       "\n",
       "                                sqrt_A              Crc  \n",
       "Epoch_Time_of_Clock                                      \n",
       "2017-11-29 12:00:00 5,153.671113970000 275.218750000000  \n",
       "2017-11-29 14:00:00 5,153.670415880000 275.343750000000  \n",
       "2017-11-29 16:00:00 5,153.670558930000 275.750000000000  \n",
       "2017-11-29 18:00:00 5,153.671985630000 279.062500000000  \n",
       "2017-11-29 20:00:00 5,153.674263000000 277.437500000000  \n",
       "2017-11-29 22:00:00 5,153.674684520000 274.031250000000  "
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
