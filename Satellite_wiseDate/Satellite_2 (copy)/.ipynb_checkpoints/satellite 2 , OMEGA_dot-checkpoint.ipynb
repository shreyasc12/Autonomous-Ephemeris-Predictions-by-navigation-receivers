{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi step model (simple encoder-decoder)\n",
    "\n",
    "In this notebook, we demonstrate how to:\n",
    "- prepare time series data for training a RNN forecasting model\n",
    "- get data in the required shape for the keras API\n",
    "- implement a RNN model in keras to predict the next 3 steps ahead (time *t+1* to *t+3*) in the time series. This model uses a simple encoder decoder approach in which the final hidden state of the encoder is replicated across each time step of the decoder. \n",
    "- enable early stopping to reduce the likelihood of model overfitting\n",
    "- evaluate the model on a test dataset\n",
    "\n",
    "The data in this example is taken from the GEFCom2014 forecasting competition<sup>1</sup>. It consists of 3 years of hourly electricity load and temperature values between 2012 and 2014. The task is to forecast future values of electricity load.\n",
    "\n",
    "<sup>1</sup>Tao Hong, Pierre Pinson, Shu Fan, Hamidreza Zareipour, Alberto Troccoli and Rob J. Hyndman, \"Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond\", International Journal of Forecasting, vol.32, no.3, pp 896-913, July-September, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from collections import UserDict\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "from common.utils import load_data, mape, TimeSeriesTensor, create_evaluation_df\n",
    "\n",
    "pd.options.display.float_format = '{:,.20f}'.format\n",
    "np.set_printoptions(precision=20)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paras = {\n",
    "    'M0':['M0', 'e','Del_n' , 'sqrt_A'],\n",
    "    'e':['OMEGA','i0','omega','I_dot','Cus','Crs','e' , 'M0'],\n",
    "    'sqrt_A':['Cuc','Crc','Del_n','Crs','sqrt_A','OMEGA_dot','Cus'],\n",
    "    'OMEGA':['OMEGA','e','i0','omega'],\n",
    "    'i0':['e','i0','omega','OMEGA' ,'I_dot'],\n",
    "    'omega':['omega','e','OMEGA','i0'],\n",
    "    'I_dot':['I_dot','e','Crs','Cuc'],\n",
    "    'Cic':['M0','Cic'],\n",
    "    'Cis':['Cis']\n",
    "    'OMEGA_dot':['OMEGA_dot'],\n",
    "    'Cuc':['Cuc','e','sqrt_A','I_dot','Crs'],\n",
    "    'Cus':['Cus','sqrt_A','OMEGA_dot','Crc','Del_n','Cus'],\n",
    "    'Crc':['Crc','sqrt_A','OMEGA_dot','Cus','Del_n'],\n",
    "    'Crs':['Crs','e','sqrt_A','I_dot','Cuc'],\n",
    "    'Del_n':['Crc','sqrt_A','OMEGA_dot','Cus','Del_n'],\n",
    "    'Codes' : ['Codes']    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'OMEGA_dot'\n",
    "sat_var = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>omega</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 00:00:00</th>\n",
       "      <td>-0.00000000977520683609</td>\n",
       "      <td>5,153.60276332000012189383</td>\n",
       "      <td>282.34585029499999109248</td>\n",
       "      <td>0.00000000581158188795</td>\n",
       "      <td>0.00000510800000000000</td>\n",
       "      <td>-1.94318871500000001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 01:00:00</th>\n",
       "      <td>-0.00000000957752760144</td>\n",
       "      <td>5,153.60349115999997593462</td>\n",
       "      <td>284.07928580200001533740</td>\n",
       "      <td>0.00000000570140051600</td>\n",
       "      <td>0.00000494188163079000</td>\n",
       "      <td>-1.94317699800000021071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 02:00:00</th>\n",
       "      <td>-0.00000000934083602756</td>\n",
       "      <td>5,153.60420780999993439764</td>\n",
       "      <td>286.24442521299999953044</td>\n",
       "      <td>0.00000000557356192470</td>\n",
       "      <td>0.00000473421044261000</td>\n",
       "      <td>-1.94316299289999983024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 03:00:00</th>\n",
       "      <td>-0.00000000906539628995</td>\n",
       "      <td>5,153.60488581000026897527</td>\n",
       "      <td>288.81768948799998497634</td>\n",
       "      <td>0.00000000542876376287</td>\n",
       "      <td>0.00000448533644926000</td>\n",
       "      <td>-1.94314589979999996494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 04:00:00</th>\n",
       "      <td>-0.00000000875378145918</td>\n",
       "      <td>5,153.60550435000004654285</td>\n",
       "      <td>291.75098147900001777089</td>\n",
       "      <td>0.00000000526888992774</td>\n",
       "      <td>0.00000419800000000000</td>\n",
       "      <td>-1.94312502000000009161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OMEGA_dot                     sqrt_A  \\\n",
       "Epoch_Time_of_Clock                                                      \n",
       "2017-11-02 00:00:00 -0.00000000977520683609 5,153.60276332000012189383   \n",
       "2017-11-02 01:00:00 -0.00000000957752760144 5,153.60349115999997593462   \n",
       "2017-11-02 02:00:00 -0.00000000934083602756 5,153.60420780999993439764   \n",
       "2017-11-02 03:00:00 -0.00000000906539628995 5,153.60488581000026897527   \n",
       "2017-11-02 04:00:00 -0.00000000875378145918 5,153.60550435000004654285   \n",
       "\n",
       "                                         Crc                  Del_n  \\\n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 00:00:00 282.34585029499999109248 0.00000000581158188795   \n",
       "2017-11-02 01:00:00 284.07928580200001533740 0.00000000570140051600   \n",
       "2017-11-02 02:00:00 286.24442521299999953044 0.00000000557356192470   \n",
       "2017-11-02 03:00:00 288.81768948799998497634 0.00000000542876376287   \n",
       "2017-11-02 04:00:00 291.75098147900001777089 0.00000000526888992774   \n",
       "\n",
       "                                       Cus                   omega  \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-02 00:00:00 0.00000510800000000000 -1.94318871500000001085  \n",
       "2017-11-02 01:00:00 0.00000494188163079000 -1.94317699800000021071  \n",
       "2017-11-02 02:00:00 0.00000473421044261000 -1.94316299289999983024  \n",
       "2017-11-02 03:00:00 0.00000448533644926000 -1.94314589979999996494  \n",
       "2017-11-02 04:00:00 0.00000419800000000000 -1.94312502000000009161  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"hourinterpol_21.csv\" , parse_dates = True)\n",
    "a = pd.to_datetime(df['Epoch_Time_of_Clock'])\n",
    "print(type(a[0]))\n",
    "#df = df.drop(['Unnamed: 0', 'Unnamed: 0.1' ,'sqrt_A'  ,'PRN','SV_Clock_Bias', 'SV_Clock_Drift', 'SV_Clock_Drift_Rate', 'IODE', 'Crs',\n",
    "#       'Del_n', 'Cuc','Cus','Toe', 'Cic', \n",
    "#       'Cis', 'Crc', 'M0', 'OMEGA_dot', 'I_dot', 'Codes', 'GPS_week',\n",
    "#       'L2_P_Data_flag', 'SV_accuracy', 'SV_health', 'Tgd', 'IODC', 'T_Tx',\n",
    "#       'Fit_Interval' ,'Epoch_Time_of_Clock' ],axis =1 )\n",
    "df = df.loc[:,Paras[var_name]]\n",
    "#df.head()\n",
    "#df = df.set_index(['Epoch_Time_of_Clock'])\n",
    "df = df.set_index(a)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter number of entries per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''entry = 6\n",
    "print(df.shape[0])\n",
    "no_of_entries = df.shape[0]//entry\n",
    "valid = (no_of_entries * 70)//100\n",
    "test = (no_of_entries * 85)//100\n",
    "indexes = df.index\n",
    "#print(valid , test , indexes)\n",
    "valid_start_dt = indexes[int(valid)*int(entry)] \n",
    "test_start_dt = indexes [int(test)*int(entry)] \n",
    "test_start_dt = str(test_start_dt)\n",
    "valid_start_dt = str(valid_start_dt)\n",
    "print(test_start_dt,valid_start_dt)\n",
    "print(type(test_start_dt))'''\n",
    "valid_start_dt = '2017-11-07 00:00:00'\n",
    "test_start_dt = '2017-11-10 00:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter lag and no. of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"total = len(df)\n",
    "t = total*70/100\n",
    "t = round(t)\n",
    "indexes = df.index\n",
    "valid_start_dt = str(indexes[t])\n",
    "t = total*85/100\n",
    "t = round(t)\n",
    "test_start_dt = str(indexes[t])\n",
    "print(valid_start_dt , test_start_dt)\n",
    "\"\"\"\n",
    "T = 24\n",
    "HORIZON = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set containing only the model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>omega</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 00:00:00</th>\n",
       "      <td>-0.00000000977520683609</td>\n",
       "      <td>5,153.60276332000012189383</td>\n",
       "      <td>282.34585029499999109248</td>\n",
       "      <td>0.00000000581158188795</td>\n",
       "      <td>0.00000510800000000000</td>\n",
       "      <td>-1.94318871500000001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 01:00:00</th>\n",
       "      <td>-0.00000000957752760144</td>\n",
       "      <td>5,153.60349115999997593462</td>\n",
       "      <td>284.07928580200001533740</td>\n",
       "      <td>0.00000000570140051600</td>\n",
       "      <td>0.00000494188163079000</td>\n",
       "      <td>-1.94317699800000021071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 02:00:00</th>\n",
       "      <td>-0.00000000934083602756</td>\n",
       "      <td>5,153.60420780999993439764</td>\n",
       "      <td>286.24442521299999953044</td>\n",
       "      <td>0.00000000557356192470</td>\n",
       "      <td>0.00000473421044261000</td>\n",
       "      <td>-1.94316299289999983024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 03:00:00</th>\n",
       "      <td>-0.00000000906539628995</td>\n",
       "      <td>5,153.60488581000026897527</td>\n",
       "      <td>288.81768948799998497634</td>\n",
       "      <td>0.00000000542876376287</td>\n",
       "      <td>0.00000448533644926000</td>\n",
       "      <td>-1.94314589979999996494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02 04:00:00</th>\n",
       "      <td>-0.00000000875378145918</td>\n",
       "      <td>5,153.60550435000004654285</td>\n",
       "      <td>291.75098147900001777089</td>\n",
       "      <td>0.00000000526888992774</td>\n",
       "      <td>0.00000419800000000000</td>\n",
       "      <td>-1.94312502000000009161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OMEGA_dot                     sqrt_A  \\\n",
       "Epoch_Time_of_Clock                                                      \n",
       "2017-11-02 00:00:00 -0.00000000977520683609 5,153.60276332000012189383   \n",
       "2017-11-02 01:00:00 -0.00000000957752760144 5,153.60349115999997593462   \n",
       "2017-11-02 02:00:00 -0.00000000934083602756 5,153.60420780999993439764   \n",
       "2017-11-02 03:00:00 -0.00000000906539628995 5,153.60488581000026897527   \n",
       "2017-11-02 04:00:00 -0.00000000875378145918 5,153.60550435000004654285   \n",
       "\n",
       "                                         Crc                  Del_n  \\\n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-02 00:00:00 282.34585029499999109248 0.00000000581158188795   \n",
       "2017-11-02 01:00:00 284.07928580200001533740 0.00000000570140051600   \n",
       "2017-11-02 02:00:00 286.24442521299999953044 0.00000000557356192470   \n",
       "2017-11-02 03:00:00 288.81768948799998497634 0.00000000542876376287   \n",
       "2017-11-02 04:00:00 291.75098147900001777089 0.00000000526888992774   \n",
       "\n",
       "                                       Cus                   omega  \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-02 00:00:00 0.00000510800000000000 -1.94318871500000001085  \n",
       "2017-11-02 01:00:00 0.00000494188163079000 -1.94317699800000021071  \n",
       "2017-11-02 02:00:00 0.00000473421044261000 -1.94316299289999983024  \n",
       "2017-11-02 03:00:00 0.00000448533644926000 -1.94314589979999996494  \n",
       "2017-11-02 04:00:00 0.00000419800000000000 -1.94312502000000009161  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.copy()[df.index < valid_start_dt][Paras[var_name]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-20 12:00:00</th>\n",
       "      <td>0.00000000421588989445</td>\n",
       "      <td>0.00001104921102520000</td>\n",
       "      <td>5,153.67980194000028859591</td>\n",
       "      <td>169.65625000000000000000</td>\n",
       "      <td>-0.00000000761960310134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 14:00:00</th>\n",
       "      <td>0.00000000416088760338</td>\n",
       "      <td>0.00001117587089540000</td>\n",
       "      <td>5,153.68068503999984386610</td>\n",
       "      <td>168.31250000000000000000</td>\n",
       "      <td>-0.00000000760888836931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 16:00:00</th>\n",
       "      <td>0.00000000420196074282</td>\n",
       "      <td>0.00001054815948010000</td>\n",
       "      <td>5,153.67795372000000497792</td>\n",
       "      <td>179.53125000000000000000</td>\n",
       "      <td>-0.00000000763460372618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 18:00:00</th>\n",
       "      <td>0.00000000418624580251</td>\n",
       "      <td>0.00001023523509500000</td>\n",
       "      <td>5,153.68110084999989339849</td>\n",
       "      <td>187.56250000000000000000</td>\n",
       "      <td>-0.00000000780496796539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 20:00:00</th>\n",
       "      <td>0.00000000416624496940</td>\n",
       "      <td>0.00001030042767520000</td>\n",
       "      <td>5,153.67985152999972342514</td>\n",
       "      <td>188.25000000000000000000</td>\n",
       "      <td>-0.00000000778639576321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20 22:00:00</th>\n",
       "      <td>0.00000000407731269358</td>\n",
       "      <td>0.00001066923141480000</td>\n",
       "      <td>5,153.68220519999977113912</td>\n",
       "      <td>178.34375000000000000000</td>\n",
       "      <td>-0.00000000775568019807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-20 12:00:00 0.00000000421588989445 0.00001104921102520000   \n",
       "2017-11-20 14:00:00 0.00000000416088760338 0.00001117587089540000   \n",
       "2017-11-20 16:00:00 0.00000000420196074282 0.00001054815948010000   \n",
       "2017-11-20 18:00:00 0.00000000418624580251 0.00001023523509500000   \n",
       "2017-11-20 20:00:00 0.00000000416624496940 0.00001030042767520000   \n",
       "2017-11-20 22:00:00 0.00000000407731269358 0.00001066923141480000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-20 12:00:00 5,153.67980194000028859591 169.65625000000000000000   \n",
       "2017-11-20 14:00:00 5,153.68068503999984386610 168.31250000000000000000   \n",
       "2017-11-20 16:00:00 5,153.67795372000000497792 179.53125000000000000000   \n",
       "2017-11-20 18:00:00 5,153.68110084999989339849 187.56250000000000000000   \n",
       "2017-11-20 20:00:00 5,153.67985152999972342514 188.25000000000000000000   \n",
       "2017-11-20 22:00:00 5,153.68220519999977113912 178.34375000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-20 12:00:00 -0.00000000761960310134  \n",
       "2017-11-20 14:00:00 -0.00000000760888836931  \n",
       "2017-11-20 16:00:00 -0.00000000763460372618  \n",
       "2017-11-20 18:00:00 -0.00000000780496796539  \n",
       "2017-11-20 20:00:00 -0.00000000778639576321  \n",
       "2017-11-20 22:00:00 -0.00000000775568019807  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data to be in range (0, 1). This transformation should be calibrated on the training set only. This is to prevent information from the validation or test sets leaking into the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter variable to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "y_scalar = StandardScaler()\n",
    "y_scalar.fit(train[[var_name]])\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "train[Paras[var_name]] = X_scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_x = open(var_name+'X_scaler2_5D_OME_dot','wb')\n",
    "pickle.dump(X_scaler, file_x)\n",
    "            \n",
    "file_y = open(var_name+'y_scalar2_5D_OME_dot','wb')\n",
    "pickle.dump(y_scalar, file_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the TimeSeriesTensor convenience class to:\n",
    "1. Shift the values of the time series to create a Pandas dataframe containing all the data for a single training example\n",
    "2. Discard any samples with missing values\n",
    "3. Transform this Pandas dataframe into a numpy array of shape (samples, time steps, features) for input into Keras\n",
    "\n",
    "The class takes the following parameters:\n",
    "\n",
    "- **dataset**: original time series\n",
    "- **H**: the forecast horizon\n",
    "- **tensor_structure**: a dictionary discribing the tensor structure in the form { 'tensor_name' : (range(max_backward_shift, max_forward_shift), [feature, feature, ...] ) }\n",
    "- **freq**: time series frequency\n",
    "- **drop_incomplete**: (Boolean) whether to drop incomplete samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_structure = {'X':(range(-T+1, 1), Paras[var_name])}\n",
    "train_inputs = TimeSeriesTensor(train, var_name, HORIZON, {'X':(range(-T+1, 1), Paras[var_name])} ,freq = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_inputs.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct validation set (keeping T hours from the training set in order to construct initial features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"10\" halign=\"left\">target</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">y</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">omega</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t+7</th>\n",
       "      <th>t+8</th>\n",
       "      <th>t+9</th>\n",
       "      <th>t+10</th>\n",
       "      <th>...</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-07 00:00:00</th>\n",
       "      <td>0.14071108129171694401</td>\n",
       "      <td>0.49293198617096850578</td>\n",
       "      <td>0.89979210028077249994</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.78114475329429322592</td>\n",
       "      <td>2.01247259003716960635</td>\n",
       "      <td>2.04384634676761844929</td>\n",
       "      <td>2.01598731575529210858</td>\n",
       "      <td>1.93154447146695740223</td>\n",
       "      <td>1.65501596662646299762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59156842348651528241</td>\n",
       "      <td>0.69238603837185141998</td>\n",
       "      <td>0.83180876725992380916</td>\n",
       "      <td>0.99822610480249540643</td>\n",
       "      <td>1.18002669771586132796</td>\n",
       "      <td>1.36560004064990203609</td>\n",
       "      <td>1.54333478032154003401</td>\n",
       "      <td>1.70162041138253861128</td>\n",
       "      <td>1.82884586319204744953</td>\n",
       "      <td>1.91340034775834721970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 01:00:00</th>\n",
       "      <td>0.49293198617096850578</td>\n",
       "      <td>0.89979210028077249994</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.78114475329429322592</td>\n",
       "      <td>2.01247259003716960635</td>\n",
       "      <td>2.04384634676761844929</td>\n",
       "      <td>2.01598731575529210858</td>\n",
       "      <td>1.93154447146695740223</td>\n",
       "      <td>1.65501596662646299762</td>\n",
       "      <td>1.19734709801070104973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69238603837185141998</td>\n",
       "      <td>0.83180876725992380916</td>\n",
       "      <td>0.99822610480249540643</td>\n",
       "      <td>1.18002669771586132796</td>\n",
       "      <td>1.36560004064990203609</td>\n",
       "      <td>1.54333478032154003401</td>\n",
       "      <td>1.70162041138253861128</td>\n",
       "      <td>1.82884586319204744953</td>\n",
       "      <td>1.91340034775834721970</td>\n",
       "      <td>1.94367251179585043275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 02:00:00</th>\n",
       "      <td>0.89979210028077249994</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.78114475329429322592</td>\n",
       "      <td>2.01247259003716960635</td>\n",
       "      <td>2.04384634676761844929</td>\n",
       "      <td>2.01598731575529210858</td>\n",
       "      <td>1.93154447146695740223</td>\n",
       "      <td>1.65501596662646299762</td>\n",
       "      <td>1.19734709801070104973</td>\n",
       "      <td>0.71865324034493660577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83180876725992380916</td>\n",
       "      <td>0.99822610480249540643</td>\n",
       "      <td>1.18002669771586132796</td>\n",
       "      <td>1.36560004064990203609</td>\n",
       "      <td>1.54333478032154003401</td>\n",
       "      <td>1.70162041138253861128</td>\n",
       "      <td>1.82884586319204744953</td>\n",
       "      <td>1.91340034775834721970</td>\n",
       "      <td>1.94367251179585043275</td>\n",
       "      <td>1.90805213260168526901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 03:00:00</th>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.78114475329429322592</td>\n",
       "      <td>2.01247259003716960635</td>\n",
       "      <td>2.04384634676761844929</td>\n",
       "      <td>2.01598731575529210858</td>\n",
       "      <td>1.93154447146695740223</td>\n",
       "      <td>1.65501596662646299762</td>\n",
       "      <td>1.19734709801070104973</td>\n",
       "      <td>0.71865324034493660577</td>\n",
       "      <td>0.30352642614630975793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99822610480249540643</td>\n",
       "      <td>1.18002669771586132796</td>\n",
       "      <td>1.36560004064990203609</td>\n",
       "      <td>1.54333478032154003401</td>\n",
       "      <td>1.70162041138253861128</td>\n",
       "      <td>1.82884586319204744953</td>\n",
       "      <td>1.91340034775834721970</td>\n",
       "      <td>1.94367251179585043275</td>\n",
       "      <td>1.90805213260168526901</td>\n",
       "      <td>1.79492785689151923556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07 04:00:00</th>\n",
       "      <td>1.78114475329429322592</td>\n",
       "      <td>2.01247259003716960635</td>\n",
       "      <td>2.04384634676761844929</td>\n",
       "      <td>2.01598731575529210858</td>\n",
       "      <td>1.93154447146695740223</td>\n",
       "      <td>1.65501596662646299762</td>\n",
       "      <td>1.19734709801070104973</td>\n",
       "      <td>0.71865324034493660577</td>\n",
       "      <td>0.30352642614630975793</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18002669771586132796</td>\n",
       "      <td>1.36560004064990203609</td>\n",
       "      <td>1.54333478032154003401</td>\n",
       "      <td>1.70162041138253861128</td>\n",
       "      <td>1.82884586319204744953</td>\n",
       "      <td>1.91340034775834721970</td>\n",
       "      <td>1.94367251179585043275</td>\n",
       "      <td>1.90805213260168526901</td>\n",
       "      <td>1.79492785689151923556</td>\n",
       "      <td>1.59586865676594791275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                              target                         \\\n",
       "feature                                  y                          \n",
       "time step                              t+1                    t+2   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 0.14071108129171694401 0.49293198617096850578   \n",
       "2017-11-07 01:00:00 0.49293198617096850578 0.89979210028077249994   \n",
       "2017-11-07 02:00:00 0.89979210028077249994 1.40530733235496274602   \n",
       "2017-11-07 03:00:00 1.40530733235496274602 1.78114475329429322592   \n",
       "2017-11-07 04:00:00 1.78114475329429322592 2.01247259003716960635   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+3                    t+4   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 0.89979210028077249994 1.40530733235496274602   \n",
       "2017-11-07 01:00:00 1.40530733235496274602 1.78114475329429322592   \n",
       "2017-11-07 02:00:00 1.78114475329429322592 2.01247259003716960635   \n",
       "2017-11-07 03:00:00 2.01247259003716960635 2.04384634676761844929   \n",
       "2017-11-07 04:00:00 2.04384634676761844929 2.01598731575529210858   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+5                    t+6   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 1.78114475329429322592 2.01247259003716960635   \n",
       "2017-11-07 01:00:00 2.01247259003716960635 2.04384634676761844929   \n",
       "2017-11-07 02:00:00 2.04384634676761844929 2.01598731575529210858   \n",
       "2017-11-07 03:00:00 2.01598731575529210858 1.93154447146695740223   \n",
       "2017-11-07 04:00:00 1.93154447146695740223 1.65501596662646299762   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+7                    t+8   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 2.04384634676761844929 2.01598731575529210858   \n",
       "2017-11-07 01:00:00 2.01598731575529210858 1.93154447146695740223   \n",
       "2017-11-07 02:00:00 1.93154447146695740223 1.65501596662646299762   \n",
       "2017-11-07 03:00:00 1.65501596662646299762 1.19734709801070104973   \n",
       "2017-11-07 04:00:00 1.19734709801070104973 0.71865324034493660577   \n",
       "\n",
       "tensor                                                              \\\n",
       "feature                                                              \n",
       "time step                              t+9                    t+10   \n",
       "Epoch_Time_of_Clock                                                  \n",
       "2017-11-07 00:00:00 1.93154447146695740223  1.65501596662646299762   \n",
       "2017-11-07 01:00:00 1.65501596662646299762  1.19734709801070104973   \n",
       "2017-11-07 02:00:00 1.19734709801070104973  0.71865324034493660577   \n",
       "2017-11-07 03:00:00 0.71865324034493660577  0.30352642614630975793   \n",
       "2017-11-07 04:00:00 0.30352642614630975793 -0.04749514996851413040   \n",
       "\n",
       "tensor                       ...                                X  \\\n",
       "feature                      ...                            omega   \n",
       "time step                    ...                              t-9   \n",
       "Epoch_Time_of_Clock          ...                                    \n",
       "2017-11-07 00:00:00          ...           0.59156842348651528241   \n",
       "2017-11-07 01:00:00          ...           0.69238603837185141998   \n",
       "2017-11-07 02:00:00          ...           0.83180876725992380916   \n",
       "2017-11-07 03:00:00          ...           0.99822610480249540643   \n",
       "2017-11-07 04:00:00          ...           1.18002669771586132796   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-8                    t-7   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 0.69238603837185141998 0.83180876725992380916   \n",
       "2017-11-07 01:00:00 0.83180876725992380916 0.99822610480249540643   \n",
       "2017-11-07 02:00:00 0.99822610480249540643 1.18002669771586132796   \n",
       "2017-11-07 03:00:00 1.18002669771586132796 1.36560004064990203609   \n",
       "2017-11-07 04:00:00 1.36560004064990203609 1.54333478032154003401   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-6                    t-5   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 0.99822610480249540643 1.18002669771586132796   \n",
       "2017-11-07 01:00:00 1.18002669771586132796 1.36560004064990203609   \n",
       "2017-11-07 02:00:00 1.36560004064990203609 1.54333478032154003401   \n",
       "2017-11-07 03:00:00 1.54333478032154003401 1.70162041138253861128   \n",
       "2017-11-07 04:00:00 1.70162041138253861128 1.82884586319204744953   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-4                    t-3   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 1.36560004064990203609 1.54333478032154003401   \n",
       "2017-11-07 01:00:00 1.54333478032154003401 1.70162041138253861128   \n",
       "2017-11-07 02:00:00 1.70162041138253861128 1.82884586319204744953   \n",
       "2017-11-07 03:00:00 1.82884586319204744953 1.91340034775834721970   \n",
       "2017-11-07 04:00:00 1.91340034775834721970 1.94367251179585043275   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-2                    t-1   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-07 00:00:00 1.70162041138253861128 1.82884586319204744953   \n",
       "2017-11-07 01:00:00 1.82884586319204744953 1.91340034775834721970   \n",
       "2017-11-07 02:00:00 1.91340034775834721970 1.94367251179585043275   \n",
       "2017-11-07 03:00:00 1.94367251179585043275 1.90805213260168526901   \n",
       "2017-11-07 04:00:00 1.90805213260168526901 1.79492785689151923556   \n",
       "\n",
       "tensor                                      \n",
       "feature                                     \n",
       "time step                                t  \n",
       "Epoch_Time_of_Clock                         \n",
       "2017-11-07 00:00:00 1.91340034775834721970  \n",
       "2017-11-07 01:00:00 1.94367251179585043275  \n",
       "2017-11-07 02:00:00 1.90805213260168526901  \n",
       "2017-11-07 03:00:00 1.79492785689151923556  \n",
       "2017-11-07 04:00:00 1.59586865676594791275  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back_dt = dt.datetime.strptime(valid_start_dt, '%Y-%m-%d %H:%M:%S') - dt.timedelta(hours=T-1)\n",
    "valid = df.copy()[(df.index >=look_back_dt) & (df.index < test_start_dt)][Paras[var_name]]\n",
    "valid[Paras[var_name]] = X_scaler.transform(valid)\n",
    "valid_inputs = TimeSeriesTensor(valid, var_name, HORIZON, tensor_structure,freq = None)\n",
    "valid_inputs.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a RNN forecasting model with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('./images/simple_encoder_decoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Flatten\n",
    "from keras.callbacks import EarlyStopping ,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(LATENT_DIM, input_shape=(T,6) ,return_sequences=True))\n",
    "model.add(LSTM(LATENT_DIM))\n",
    "model.add(RepeatVector(HORIZON))\n",
    "model.add(LSTM(LATENT_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 24, 64)            18176     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 24, 64)            33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 24, 1)             65        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 84,289\n",
      "Trainable params: 84,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = ModelCheckpoint(str(sat_var) +'_' +  var_name + '_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73 samples, validate on 48 samples\n",
      "Epoch 1/1000\n",
      "73/73 [==============================] - 2s 27ms/step - loss: 0.9853 - val_loss: 2.0715\n",
      "Epoch 2/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0614 - val_loss: 1.2801\n",
      "Epoch 3/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9255 - val_loss: 1.1665\n",
      "Epoch 4/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.8930 - val_loss: 1.0511\n",
      "Epoch 5/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8502 - val_loss: 1.0855\n",
      "Epoch 6/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.7748 - val_loss: 1.1049\n",
      "Epoch 7/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6824 - val_loss: 2.3963\n",
      "Epoch 8/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 3.5938\n",
      "Epoch 9/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.8924\n",
      "Epoch 10/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5378 - val_loss: 1.3559\n",
      "Epoch 11/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3872 - val_loss: 0.9248\n",
      "Epoch 12/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 1.8211\n",
      "Epoch 13/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 1.2026\n",
      "Epoch 14/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 1.2384\n",
      "Epoch 15/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2857 - val_loss: 0.7997\n",
      "Epoch 16/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2605 - val_loss: 1.0212\n",
      "Epoch 17/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2727 - val_loss: 0.7095\n",
      "Epoch 18/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2851 - val_loss: 0.9494\n",
      "Epoch 19/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2157 - val_loss: 0.5386\n",
      "Epoch 20/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1842 - val_loss: 0.6498\n",
      "Epoch 21/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2037 - val_loss: 0.6535\n",
      "Epoch 22/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1844 - val_loss: 0.8411\n",
      "Epoch 23/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.5031\n",
      "Epoch 24/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 0.7233\n",
      "Epoch 25/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1444 - val_loss: 0.6487\n",
      "Epoch 26/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2109 - val_loss: 0.3854\n",
      "Epoch 27/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.3464\n",
      "Epoch 28/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.3707\n",
      "Epoch 29/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.3760\n",
      "Epoch 30/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0898 - val_loss: 0.4982\n",
      "Epoch 31/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1431 - val_loss: 0.4766\n",
      "Epoch 32/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2062 - val_loss: 0.5391\n",
      "Epoch 33/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.2548\n",
      "Epoch 34/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.2801\n",
      "Epoch 35/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0488 - val_loss: 0.4035\n",
      "Epoch 36/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.5046\n",
      "Epoch 37/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1261 - val_loss: 0.6631\n",
      "Epoch 38/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0991 - val_loss: 0.4520\n",
      "Epoch 39/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.4198\n",
      "Epoch 40/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1609 - val_loss: 0.3610\n",
      "Epoch 41/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.2719\n",
      "Epoch 42/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.3137\n",
      "Epoch 43/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.4292\n",
      "Epoch 44/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.3949\n",
      "Epoch 45/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 0.5518\n",
      "Epoch 46/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.4324\n",
      "Epoch 47/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.3016\n",
      "Epoch 48/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1309 - val_loss: 0.3048\n",
      "Epoch 49/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.2802\n",
      "Epoch 50/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.2754\n",
      "Epoch 51/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.4850\n",
      "Epoch 52/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.3793\n",
      "Epoch 53/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0979 - val_loss: 0.3897\n",
      "Epoch 54/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1124 - val_loss: 0.4040\n",
      "Epoch 55/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.2810\n",
      "Epoch 56/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.2620\n",
      "Epoch 57/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.2729\n",
      "Epoch 58/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.2743\n",
      "Epoch 59/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.5141\n",
      "Epoch 60/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.3653\n",
      "Epoch 61/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0974 - val_loss: 0.2982\n",
      "Epoch 62/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.3823\n",
      "Epoch 63/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.2857\n",
      "Epoch 64/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.2380\n",
      "Epoch 65/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.2650\n",
      "Epoch 66/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0293 - val_loss: 0.2750\n",
      "Epoch 67/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.4889\n",
      "Epoch 68/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.3604\n",
      "Epoch 69/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.3019\n",
      "Epoch 70/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.3722\n",
      "Epoch 71/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.2701\n",
      "Epoch 72/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.2413\n",
      "Epoch 73/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.2666\n",
      "Epoch 74/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.2687\n",
      "Epoch 75/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.4369\n",
      "Epoch 76/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.3367\n",
      "Epoch 77/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.3111\n",
      "Epoch 78/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.3638\n",
      "Epoch 79/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.2511\n",
      "Epoch 80/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.2512\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.2743\n",
      "Epoch 82/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0327 - val_loss: 0.2587\n",
      "Epoch 83/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.4379\n",
      "Epoch 84/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.3196\n",
      "Epoch 85/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.2661\n",
      "Epoch 86/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0949 - val_loss: 0.3711\n",
      "Epoch 87/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.2588\n",
      "Epoch 88/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.2409\n",
      "Epoch 89/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.2750\n",
      "Epoch 90/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.2626\n",
      "Epoch 91/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.4297\n",
      "Epoch 92/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.3138\n",
      "Epoch 93/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.2707\n",
      "Epoch 94/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.3649\n",
      "Epoch 95/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.2484\n",
      "Epoch 96/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.2468\n",
      "Epoch 97/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.2778\n",
      "Epoch 98/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.2573\n",
      "Epoch 99/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.4179\n",
      "Epoch 100/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.2995\n",
      "Epoch 101/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.2610\n",
      "Epoch 102/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0878 - val_loss: 0.3630\n",
      "Epoch 103/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0654 - val_loss: 0.2461\n",
      "Epoch 104/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.2483\n",
      "Epoch 105/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.2801\n",
      "Epoch 106/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.2565\n",
      "Epoch 107/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0462 - val_loss: 0.4153\n",
      "Epoch 108/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0492 - val_loss: 0.2888\n",
      "Epoch 109/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.2461\n",
      "Epoch 110/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.3618\n",
      "Epoch 111/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.2463\n",
      "Epoch 112/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.2458\n",
      "Epoch 113/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.2814\n",
      "Epoch 114/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.2561\n",
      "Epoch 115/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.4084\n",
      "Epoch 116/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.2815\n",
      "Epoch 117/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0691 - val_loss: 0.2490\n",
      "Epoch 118/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.3544\n",
      "Epoch 119/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0637 - val_loss: 0.2409\n",
      "Epoch 120/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.2516\n",
      "Epoch 121/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.2796\n",
      "Epoch 122/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.2534\n",
      "Epoch 123/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.3919\n",
      "Epoch 124/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.2706\n",
      "Epoch 125/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.2428\n",
      "Epoch 126/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.3437\n",
      "Epoch 127/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0629 - val_loss: 0.2399\n",
      "Epoch 128/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.2546\n",
      "Epoch 129/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.2802\n",
      "Epoch 130/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.2510\n",
      "Epoch 131/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.3839\n",
      "Epoch 132/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.2634\n",
      "Epoch 133/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.2328\n",
      "Epoch 134/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.3353\n",
      "Epoch 135/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.2401\n",
      "Epoch 136/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.2525\n",
      "Epoch 137/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.2802\n",
      "Epoch 138/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.2492\n",
      "Epoch 139/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.3732\n",
      "Epoch 140/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.2576\n",
      "Epoch 141/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.2323\n",
      "Epoch 142/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0785 - val_loss: 0.3237\n",
      "Epoch 143/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0615 - val_loss: 0.2379\n",
      "Epoch 144/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.2570\n",
      "Epoch 145/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.2763\n",
      "Epoch 146/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.2452\n",
      "Epoch 147/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0378 - val_loss: 0.3564\n",
      "Epoch 148/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.2524\n",
      "Epoch 149/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.2305\n",
      "Epoch 150/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.3100\n",
      "Epoch 151/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0611 - val_loss: 0.2374\n",
      "Epoch 152/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.2619\n",
      "Epoch 153/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.2723\n",
      "Epoch 154/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.2410\n",
      "Epoch 155/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.3455\n",
      "Epoch 156/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0323 - val_loss: 0.2500\n",
      "Epoch 157/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0567 - val_loss: 0.2247\n",
      "Epoch 158/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.2994\n",
      "Epoch 159/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.2376\n",
      "Epoch 160/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.2618\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.2705\n",
      "Epoch 162/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.2372\n",
      "Epoch 163/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.3386\n",
      "Epoch 164/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.2472\n",
      "Epoch 165/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.2195\n",
      "Epoch 166/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.2920\n",
      "Epoch 167/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.2363\n",
      "Epoch 168/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.2625\n",
      "Epoch 169/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.2668\n",
      "Epoch 170/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.2324\n",
      "Epoch 171/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.3307\n",
      "Epoch 172/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.2441\n",
      "Epoch 173/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.2166\n",
      "Epoch 174/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.2836\n",
      "Epoch 175/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.2342\n",
      "Epoch 176/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.2645\n",
      "Epoch 177/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.2622\n",
      "Epoch 178/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.2270\n",
      "Epoch 179/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.3224\n",
      "Epoch 180/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0300 - val_loss: 0.2408\n",
      "Epoch 181/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.2109\n",
      "Epoch 182/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.2771\n",
      "Epoch 183/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.2327\n",
      "Epoch 184/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.2628\n",
      "Epoch 185/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.2590\n",
      "Epoch 186/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0235 - val_loss: 0.2229\n",
      "Epoch 187/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.3172\n",
      "Epoch 188/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.2368\n",
      "Epoch 189/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.2057\n",
      "Epoch 190/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.2716\n",
      "Epoch 191/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.2313\n",
      "Epoch 192/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.2629\n",
      "Epoch 193/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.2558\n",
      "Epoch 194/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.2183\n",
      "Epoch 195/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0321 - val_loss: 0.3105\n",
      "Epoch 196/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.2328\n",
      "Epoch 197/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.2009\n",
      "Epoch 198/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.2661\n",
      "Epoch 199/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.2295\n",
      "Epoch 200/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.2620\n",
      "Epoch 201/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.2521\n",
      "Epoch 202/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.2142\n",
      "Epoch 203/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.3032\n",
      "Epoch 204/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.2288\n",
      "Epoch 205/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.1974\n",
      "Epoch 206/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.2585\n",
      "Epoch 207/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.2271\n",
      "Epoch 208/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.2633\n",
      "Epoch 209/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.2473\n",
      "Epoch 210/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.2090\n",
      "Epoch 211/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.2955\n",
      "Epoch 212/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.2257\n",
      "Epoch 213/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.1929\n",
      "Epoch 214/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.2544\n",
      "Epoch 215/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.2259\n",
      "Epoch 216/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.2599\n",
      "Epoch 217/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.2439\n",
      "Epoch 218/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.2055\n",
      "Epoch 219/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.2896\n",
      "Epoch 220/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.2218\n",
      "Epoch 221/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.1883\n",
      "Epoch 222/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.2488\n",
      "Epoch 223/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.2229\n",
      "Epoch 224/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0475 - val_loss: 0.2572\n",
      "Epoch 225/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2398\n",
      "Epoch 226/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.2016\n",
      "Epoch 227/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.2819\n",
      "Epoch 228/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.2191\n",
      "Epoch 229/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.1849\n",
      "Epoch 230/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.2432\n",
      "Epoch 231/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.2209\n",
      "Epoch 232/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.2571\n",
      "Epoch 233/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.2353\n",
      "Epoch 234/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.1967\n",
      "Epoch 235/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.2751\n",
      "Epoch 236/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.2163\n",
      "Epoch 237/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.1799\n",
      "Epoch 238/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.2362\n",
      "Epoch 239/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.2179\n",
      "Epoch 240/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.2548\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.2304\n",
      "Epoch 242/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.1923\n",
      "Epoch 243/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0276 - val_loss: 0.2693\n",
      "Epoch 244/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.2131\n",
      "Epoch 245/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.1755\n",
      "Epoch 246/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.2333\n",
      "Epoch 247/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.2164\n",
      "Epoch 248/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.2508\n",
      "Epoch 249/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2268\n",
      "Epoch 250/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.1890\n",
      "Epoch 251/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.2634\n",
      "Epoch 252/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.2094\n",
      "Epoch 253/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.1708\n",
      "Epoch 254/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.2275\n",
      "Epoch 255/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.2139\n",
      "Epoch 256/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.2485\n",
      "Epoch 257/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2226\n",
      "Epoch 258/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.1852\n",
      "Epoch 259/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.2573\n",
      "Epoch 260/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.2066\n",
      "Epoch 261/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0463 - val_loss: 0.1659\n",
      "Epoch 262/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.2240\n",
      "Epoch 263/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.2141\n",
      "Epoch 264/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.2459\n",
      "Epoch 265/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.2200\n",
      "Epoch 266/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.1825\n",
      "Epoch 267/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.2507\n",
      "Epoch 268/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.2042\n",
      "Epoch 269/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.1605\n",
      "Epoch 270/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.2217\n",
      "Epoch 271/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.2140\n",
      "Epoch 272/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.2405\n",
      "Epoch 273/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.2164\n",
      "Epoch 274/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.1807\n",
      "Epoch 275/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.2456\n",
      "Epoch 276/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.2012\n",
      "Epoch 277/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.1552\n",
      "Epoch 278/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.2183\n",
      "Epoch 279/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.2133\n",
      "Epoch 280/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.2375\n",
      "Epoch 281/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2135\n",
      "Epoch 282/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.1786\n",
      "Epoch 283/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.2395\n",
      "Epoch 284/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.1989\n",
      "Epoch 285/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.1505\n",
      "Epoch 286/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.2143\n",
      "Epoch 287/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.2125\n",
      "Epoch 288/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.2337\n",
      "Epoch 289/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.2097\n",
      "Epoch 290/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.1756\n",
      "Epoch 291/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.2344\n",
      "Epoch 292/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.1969\n",
      "Epoch 293/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.1456\n",
      "Epoch 294/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.2094\n",
      "Epoch 295/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.2106\n",
      "Epoch 296/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.2303\n",
      "Epoch 297/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.2067\n",
      "Epoch 298/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.1737\n",
      "Epoch 299/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.2292\n",
      "Epoch 300/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.1947\n",
      "Epoch 301/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.1429\n",
      "Epoch 302/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.2072\n",
      "Epoch 303/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.2092\n",
      "Epoch 304/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.2250\n",
      "Epoch 305/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.2027\n",
      "Epoch 306/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.1712\n",
      "Epoch 307/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.2251\n",
      "Epoch 308/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.1936\n",
      "Epoch 309/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.1395\n",
      "Epoch 310/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.2031\n",
      "Epoch 311/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.2072\n",
      "Epoch 312/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.2214\n",
      "Epoch 313/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1994\n",
      "Epoch 314/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.1693\n",
      "Epoch 315/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.2204\n",
      "Epoch 316/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.1918\n",
      "Epoch 317/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.1359\n",
      "Epoch 318/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.1986\n",
      "Epoch 319/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.2063\n",
      "Epoch 320/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.2195\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1960\n",
      "Epoch 322/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.1650\n",
      "Epoch 323/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2186\n",
      "Epoch 324/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.1903\n",
      "Epoch 325/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.1295\n",
      "Epoch 326/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.2001\n",
      "Epoch 327/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.2044\n",
      "Epoch 328/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.2130\n",
      "Epoch 329/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1953\n",
      "Epoch 330/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.1689\n",
      "Epoch 331/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.2129\n",
      "Epoch 332/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.1853\n",
      "Epoch 333/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.1317\n",
      "Epoch 334/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.1951\n",
      "Epoch 335/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.2076\n",
      "Epoch 336/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0285 - val_loss: 0.2098\n",
      "Epoch 337/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1881\n",
      "Epoch 338/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.1537\n",
      "Epoch 339/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2148\n",
      "Epoch 340/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.1866\n",
      "Epoch 341/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.1164\n",
      "Epoch 342/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.2074\n",
      "Epoch 343/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.1975\n",
      "Epoch 344/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.2016\n",
      "Epoch 345/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1954\n",
      "Epoch 346/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.1777\n",
      "Epoch 347/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.2049\n",
      "Epoch 348/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.1607\n",
      "Epoch 349/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.1360\n",
      "Epoch 350/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.1975\n",
      "Epoch 351/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.1974\n",
      "Epoch 352/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.2090\n",
      "Epoch 353/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1813\n",
      "Epoch 354/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.1438\n",
      "Epoch 355/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.1970\n",
      "Epoch 356/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.2004\n",
      "Epoch 357/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.1229\n",
      "Epoch 358/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.1882\n",
      "Epoch 359/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.1983\n",
      "Epoch 360/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.2061\n",
      "Epoch 361/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1854\n",
      "Epoch 362/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.1617\n",
      "Epoch 363/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.2064\n",
      "Epoch 364/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.1696\n",
      "Epoch 365/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.1116\n",
      "Epoch 366/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.2081\n",
      "Epoch 367/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.2003\n",
      "Epoch 368/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.1750\n",
      "Epoch 369/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1829\n",
      "Epoch 370/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1591\n",
      "Epoch 371/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.1913\n",
      "Epoch 372/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.1772\n",
      "Epoch 373/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.1189\n",
      "Epoch 374/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.2059\n",
      "Epoch 375/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.1929\n",
      "Epoch 376/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.1702\n",
      "Epoch 377/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1832\n",
      "Epoch 378/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1520\n",
      "Epoch 379/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.1584\n",
      "Epoch 380/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.1762\n",
      "Epoch 381/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.1355\n",
      "Epoch 382/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.2112\n",
      "Epoch 383/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.1875\n",
      "Epoch 384/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.1481\n",
      "Epoch 385/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1917\n",
      "Epoch 386/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1437\n",
      "Epoch 387/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.1229\n",
      "Epoch 388/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.1935\n",
      "Epoch 389/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.1758\n",
      "Epoch 390/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.2244\n",
      "Epoch 391/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1722\n",
      "Epoch 392/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.1522\n",
      "Epoch 393/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.1912\n",
      "Epoch 394/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.1435\n",
      "Epoch 395/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.1114\n",
      "Epoch 396/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.1949\n",
      "Epoch 397/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.1804\n",
      "Epoch 398/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.1838\n",
      "Epoch 399/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1657\n",
      "Epoch 400/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1424\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.1829\n",
      "Epoch 402/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.1697\n",
      "Epoch 403/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.1041\n",
      "Epoch 404/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.1881\n",
      "Epoch 405/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0278 - val_loss: 0.1860\n",
      "Epoch 406/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.1686\n",
      "Epoch 407/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1613\n",
      "Epoch 408/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1403\n",
      "Epoch 409/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.1716\n",
      "Epoch 410/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.1707\n",
      "Epoch 411/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.1000\n",
      "Epoch 412/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.1991\n",
      "Epoch 413/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.1840\n",
      "Epoch 414/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.1497\n",
      "Epoch 415/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1595\n",
      "Epoch 416/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1499\n",
      "Epoch 417/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.1522\n",
      "Epoch 418/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.1535\n",
      "Epoch 419/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.1337\n",
      "Epoch 420/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.2113\n",
      "Epoch 421/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.1539\n",
      "Epoch 422/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.1387\n",
      "Epoch 423/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1733\n",
      "Epoch 424/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1318\n",
      "Epoch 425/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.1178\n",
      "Epoch 426/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.1898\n",
      "Epoch 427/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.1665\n",
      "Epoch 428/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.1867\n",
      "Epoch 429/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1613\n",
      "Epoch 430/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.1458\n",
      "Epoch 431/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.1753\n",
      "Epoch 432/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.1390\n",
      "Epoch 433/1000\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0260 - val_loss: 0.0868\n",
      "Epoch 434/1000\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.2021\n",
      "Epoch 435/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.1796\n",
      "Epoch 436/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.1473\n",
      "Epoch 437/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1565\n",
      "Epoch 438/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1407\n",
      "Epoch 439/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.1621\n",
      "Epoch 440/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.1438\n",
      "Epoch 441/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.1065\n",
      "Epoch 442/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.2172\n",
      "Epoch 443/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.1427\n",
      "Epoch 444/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.1428\n",
      "Epoch 445/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1704\n",
      "Epoch 446/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1355\n",
      "Epoch 447/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.1307\n",
      "Epoch 448/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.1517\n",
      "Epoch 449/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.1401\n",
      "Epoch 450/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.1959\n",
      "Epoch 451/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.1365\n",
      "Epoch 452/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1367\n",
      "Epoch 453/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1716\n",
      "Epoch 454/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1194\n",
      "Epoch 455/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.1011\n",
      "Epoch 456/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.2014\n",
      "Epoch 457/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.1499\n",
      "Epoch 458/1000\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.0220 - val_loss: 0.1512\n",
      "Epoch 459/1000\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0104 - val_loss: 0.1534\n",
      "Epoch 460/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1490\n",
      "Epoch 461/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.1515\n",
      "Epoch 462/1000\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.0179 - val_loss: 0.1374\n",
      "Epoch 463/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0919\n",
      "Epoch 464/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.1980\n",
      "Epoch 465/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.1736\n",
      "Epoch 466/1000\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.0193 - val_loss: 0.1339\n",
      "Epoch 467/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1443\n",
      "Epoch 468/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1204\n",
      "Epoch 469/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.1281\n",
      "Epoch 470/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.1520\n",
      "Epoch 471/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.1243\n",
      "Epoch 472/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.2631\n",
      "Epoch 473/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.1400\n",
      "Epoch 474/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.1246\n",
      "Epoch 475/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.1655\n",
      "Epoch 476/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1192\n",
      "Epoch 477/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.1056\n",
      "Epoch 478/1000\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.0268 - val_loss: 0.1737\n",
      "Epoch 479/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.1306\n",
      "Epoch 480/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.1832\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1429\n",
      "Epoch 482/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1406\n",
      "Epoch 483/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.1681\n",
      "Epoch 484/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.1256\n",
      "Epoch 485/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0940\n",
      "Epoch 486/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.1808\n",
      "Epoch 487/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.1450\n",
      "Epoch 488/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.1598\n",
      "Epoch 489/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1397\n",
      "Epoch 490/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1252\n",
      "Epoch 491/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.1368\n",
      "Epoch 492/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.1547\n",
      "Epoch 493/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0910\n",
      "Epoch 494/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.1824\n",
      "Epoch 495/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.1695\n",
      "Epoch 496/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.1372\n",
      "Epoch 497/1000\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.0115 - val_loss: 0.1332\n",
      "Epoch 498/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1132\n",
      "Epoch 499/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1113\n",
      "Epoch 500/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.1730\n",
      "Epoch 501/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.1185\n",
      "Epoch 502/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.2060\n",
      "Epoch 503/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1524\n",
      "Epoch 504/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.1205\n",
      "Epoch 505/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.1418\n",
      "Epoch 506/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1320\n",
      "Epoch 507/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0962\n",
      "Epoch 508/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.1629\n",
      "Epoch 509/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.1472\n",
      "Epoch 510/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.1804\n",
      "Epoch 511/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1316\n",
      "Epoch 512/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1114\n",
      "Epoch 513/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.1484\n",
      "Epoch 514/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1415\n",
      "Epoch 515/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.0778\n",
      "Epoch 516/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.1993\n",
      "Epoch 517/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.1464\n",
      "Epoch 518/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.1347\n",
      "Epoch 519/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1336\n",
      "Epoch 520/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1276\n",
      "Epoch 521/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.1295\n",
      "Epoch 522/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.1305\n",
      "Epoch 523/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.1010\n",
      "Epoch 524/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.2032\n",
      "Epoch 525/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.1356\n",
      "Epoch 526/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.1290\n",
      "Epoch 527/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1429\n",
      "Epoch 528/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1183\n",
      "Epoch 529/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0887\n",
      "Epoch 530/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.1705\n",
      "Epoch 531/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.1398\n",
      "Epoch 532/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.1534\n",
      "Epoch 533/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1311\n",
      "Epoch 534/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1113\n",
      "Epoch 535/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.1516\n",
      "Epoch 536/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.1060\n",
      "Epoch 537/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0828\n",
      "Epoch 538/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.2432\n",
      "Epoch 539/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.1240\n",
      "Epoch 540/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.1528\n",
      "Epoch 541/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.1397\n",
      "Epoch 542/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1201\n",
      "Epoch 543/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.1210\n",
      "Epoch 544/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.1228\n",
      "Epoch 545/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0985\n",
      "Epoch 546/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.1748\n",
      "Epoch 547/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.1217\n",
      "Epoch 548/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.1691\n",
      "Epoch 549/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.1374\n",
      "Epoch 550/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.1132\n",
      "Epoch 551/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.1107\n",
      "Epoch 552/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.1326\n",
      "Epoch 553/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0940\n",
      "Epoch 554/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0331 - val_loss: 0.1861\n",
      "Epoch 555/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.1351\n",
      "Epoch 556/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.1262\n",
      "Epoch 557/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1318\n",
      "Epoch 558/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1122\n",
      "Epoch 559/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0774\n",
      "Epoch 560/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.1780\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.1315\n",
      "Epoch 562/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.1508\n",
      "Epoch 563/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1236\n",
      "Epoch 564/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1186\n",
      "Epoch 565/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1173\n",
      "Epoch 566/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1301\n",
      "Epoch 567/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0765\n",
      "Epoch 568/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.1855\n",
      "Epoch 569/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.1530\n",
      "Epoch 570/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.1225\n",
      "Epoch 571/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1171\n",
      "Epoch 572/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0988\n",
      "Epoch 573/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1027\n",
      "Epoch 574/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.1524\n",
      "Epoch 575/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.1032\n",
      "Epoch 576/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.2238\n",
      "Epoch 577/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1218\n",
      "Epoch 578/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.1099\n",
      "Epoch 579/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.1332\n",
      "Epoch 580/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1101\n",
      "Epoch 581/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0808\n",
      "Epoch 582/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.1586\n",
      "Epoch 583/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.1166\n",
      "Epoch 584/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.1768\n",
      "Epoch 585/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1172\n",
      "Epoch 586/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1202\n",
      "Epoch 587/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.1372\n",
      "Epoch 588/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.1075\n",
      "Epoch 589/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0718\n",
      "Epoch 590/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.1814\n",
      "Epoch 591/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.1238\n",
      "Epoch 592/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.1440\n",
      "Epoch 593/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1173\n",
      "Epoch 594/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1197\n",
      "Epoch 595/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1070\n",
      "Epoch 596/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.1284\n",
      "Epoch 597/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0897\n",
      "Epoch 598/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.1749\n",
      "Epoch 599/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.1349\n",
      "Epoch 600/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1279\n",
      "Epoch 601/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.1251\n",
      "Epoch 602/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0843\n",
      "Epoch 603/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0813\n",
      "Epoch 604/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.1880\n",
      "Epoch 605/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.1051\n",
      "Epoch 606/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.1841\n",
      "Epoch 607/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1213\n",
      "Epoch 608/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.1150\n",
      "Epoch 609/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.1270\n",
      "Epoch 610/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1133\n",
      "Epoch 611/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0909\n",
      "Epoch 612/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.1325\n",
      "Epoch 613/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.1138\n",
      "Epoch 614/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.2202\n",
      "Epoch 615/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1137\n",
      "Epoch 616/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.1135\n",
      "Epoch 617/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.1293\n",
      "Epoch 618/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0999\n",
      "Epoch 619/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0728\n",
      "Epoch 620/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.1777\n",
      "Epoch 621/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.1103\n",
      "Epoch 622/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.1491\n",
      "Epoch 623/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1144\n",
      "Epoch 624/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1263\n",
      "Epoch 625/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1126\n",
      "Epoch 626/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1174\n",
      "Epoch 627/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0857\n",
      "Epoch 628/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.1605\n",
      "Epoch 629/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.1219\n",
      "Epoch 630/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.1450\n",
      "Epoch 631/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1147\n",
      "Epoch 632/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0872\n",
      "Epoch 633/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0901\n",
      "Epoch 634/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.1732\n",
      "Epoch 635/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0932\n",
      "Epoch 636/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.1909\n",
      "Epoch 637/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.1193\n",
      "Epoch 638/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.1080\n",
      "Epoch 639/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1140\n",
      "Epoch 640/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1133\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0847\n",
      "Epoch 642/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.1456\n",
      "Epoch 643/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.1121\n",
      "Epoch 644/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.1982\n",
      "Epoch 645/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1092\n",
      "Epoch 646/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1143\n",
      "Epoch 647/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.1274\n",
      "Epoch 648/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0980\n",
      "Epoch 649/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0693\n",
      "Epoch 650/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.1844\n",
      "Epoch 651/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.1119\n",
      "Epoch 652/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.1490\n",
      "Epoch 653/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1128\n",
      "Epoch 654/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1211\n",
      "Epoch 655/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1059\n",
      "Epoch 656/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1182\n",
      "Epoch 657/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0833\n",
      "Epoch 658/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.1710\n",
      "Epoch 659/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.1203\n",
      "Epoch 660/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1370\n",
      "Epoch 661/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1151\n",
      "Epoch 662/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0914\n",
      "Epoch 663/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0745\n",
      "Epoch 664/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.1872\n",
      "Epoch 665/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.1027\n",
      "Epoch 666/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.1643\n",
      "Epoch 667/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1196\n",
      "Epoch 668/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1114\n",
      "Epoch 669/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1000\n",
      "Epoch 670/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1172\n",
      "Epoch 671/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0881\n",
      "Epoch 672/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.1535\n",
      "Epoch 673/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.1184\n",
      "Epoch 674/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1682\n",
      "Epoch 675/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1094\n",
      "Epoch 676/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0994\n",
      "Epoch 677/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0961\n",
      "Epoch 678/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1447\n",
      "Epoch 679/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0836\n",
      "Epoch 680/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.1881\n",
      "Epoch 681/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1231\n",
      "Epoch 682/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1109\n",
      "Epoch 683/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1080\n",
      "Epoch 684/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1064\n",
      "Epoch 685/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0777\n",
      "Epoch 686/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.1594\n",
      "Epoch 687/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.1139\n",
      "Epoch 688/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.1720\n",
      "Epoch 689/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1050\n",
      "Epoch 690/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1076\n",
      "Epoch 691/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1065\n",
      "Epoch 692/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1217\n",
      "Epoch 693/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0755\n",
      "Epoch 694/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.1663\n",
      "Epoch 695/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.1198\n",
      "Epoch 696/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1302\n",
      "Epoch 697/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1053\n",
      "Epoch 698/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0924\n",
      "Epoch 699/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0895\n",
      "Epoch 700/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.1583\n",
      "Epoch 701/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0940\n",
      "Epoch 702/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.1949\n",
      "Epoch 703/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1089\n",
      "Epoch 704/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.1064\n",
      "Epoch 705/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1054\n",
      "Epoch 706/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1119\n",
      "Epoch 707/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0765\n",
      "Epoch 708/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.1530\n",
      "Epoch 709/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.1096\n",
      "Epoch 710/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.1672\n",
      "Epoch 711/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1012\n",
      "Epoch 712/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1107\n",
      "Epoch 713/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1096\n",
      "Epoch 714/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1107\n",
      "Epoch 715/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0715\n",
      "Epoch 716/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.1824\n",
      "Epoch 717/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1152\n",
      "Epoch 718/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1264\n",
      "Epoch 719/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1039\n",
      "Epoch 720/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1044\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0816\n",
      "Epoch 722/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.1447\n",
      "Epoch 723/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0979\n",
      "Epoch 724/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.1804\n",
      "Epoch 725/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1073\n",
      "Epoch 726/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1131\n",
      "Epoch 727/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1076\n",
      "Epoch 728/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1096\n",
      "Epoch 729/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0691\n",
      "Epoch 730/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.1640\n",
      "Epoch 731/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.1125\n",
      "Epoch 732/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1379\n",
      "Epoch 733/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1003\n",
      "Epoch 734/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0941\n",
      "Epoch 735/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0936\n",
      "Epoch 736/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1428\n",
      "Epoch 737/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0850\n",
      "Epoch 738/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.1987\n",
      "Epoch 739/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1076\n",
      "Epoch 740/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1111\n",
      "Epoch 741/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1021\n",
      "Epoch 742/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1023\n",
      "Epoch 743/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0736\n",
      "Epoch 744/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.1522\n",
      "Epoch 745/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.1018\n",
      "Epoch 746/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.1674\n",
      "Epoch 747/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0982\n",
      "Epoch 748/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1110\n",
      "Epoch 749/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1031\n",
      "Epoch 750/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1096\n",
      "Epoch 751/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0702\n",
      "Epoch 752/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.1721\n",
      "Epoch 753/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1108\n",
      "Epoch 754/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.1273\n",
      "Epoch 755/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0989\n",
      "Epoch 756/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0945\n",
      "Epoch 757/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0808\n",
      "Epoch 758/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.1596\n",
      "Epoch 759/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0917\n",
      "Epoch 760/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.1742\n",
      "Epoch 761/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1023\n",
      "Epoch 762/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1050\n",
      "Epoch 763/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0901\n",
      "Epoch 764/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1200\n",
      "Epoch 765/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0773\n",
      "Epoch 766/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.1540\n",
      "Epoch 767/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1075\n",
      "Epoch 768/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1441\n",
      "Epoch 769/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0985\n",
      "Epoch 770/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0975\n",
      "Epoch 771/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0766\n",
      "Epoch 772/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.1539\n",
      "Epoch 773/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0899\n",
      "Epoch 774/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.1645\n",
      "Epoch 775/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1054\n",
      "Epoch 776/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0964\n",
      "Epoch 777/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0869\n",
      "Epoch 778/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.1214\n",
      "Epoch 779/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0739\n",
      "Epoch 780/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.1733\n",
      "Epoch 781/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.1128\n",
      "Epoch 782/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1249\n",
      "Epoch 783/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0967\n",
      "Epoch 784/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0969\n",
      "Epoch 785/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0643\n",
      "Epoch 786/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1510\n",
      "Epoch 787/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0979\n",
      "Epoch 788/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.1531\n",
      "Epoch 789/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.1047\n",
      "Epoch 790/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0877\n",
      "Epoch 791/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0947\n",
      "Epoch 792/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1144\n",
      "Epoch 793/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0775\n",
      "Epoch 794/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2054\n",
      "Epoch 795/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0992\n",
      "Epoch 796/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.1199\n",
      "Epoch 797/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0984\n",
      "Epoch 798/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0933\n",
      "Epoch 799/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0717\n",
      "Epoch 800/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1342\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0878\n",
      "Epoch 802/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.1812\n",
      "Epoch 803/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0917\n",
      "Epoch 804/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1141\n",
      "Epoch 805/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.1039\n",
      "Epoch 806/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0909\n",
      "Epoch 807/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0632\n",
      "Epoch 808/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.1613\n",
      "Epoch 809/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0963\n",
      "Epoch 810/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.1513\n",
      "Epoch 811/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0908\n",
      "Epoch 812/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1063\n",
      "Epoch 813/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0857\n",
      "Epoch 814/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1207\n",
      "Epoch 815/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0725\n",
      "Epoch 816/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.1698\n",
      "Epoch 817/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1081\n",
      "Epoch 818/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1130\n",
      "Epoch 819/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0962\n",
      "Epoch 820/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0826\n",
      "Epoch 821/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0786\n",
      "Epoch 822/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.1737\n",
      "Epoch 823/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0948\n",
      "Epoch 824/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.1790\n",
      "Epoch 825/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0916\n",
      "Epoch 826/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0973\n",
      "Epoch 827/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0866\n",
      "Epoch 828/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1153\n",
      "Epoch 829/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0711\n",
      "Epoch 830/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.1503\n",
      "Epoch 831/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0963\n",
      "Epoch 832/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1483\n",
      "Epoch 833/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0867\n",
      "Epoch 834/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1053\n",
      "Epoch 835/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0824\n",
      "Epoch 836/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1191\n",
      "Epoch 837/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0787\n",
      "Epoch 838/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.1875\n",
      "Epoch 839/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0994\n",
      "Epoch 840/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1027\n",
      "Epoch 841/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0932\n",
      "Epoch 842/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0918\n",
      "Epoch 843/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0700\n",
      "Epoch 844/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.1765\n",
      "Epoch 845/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0957\n",
      "Epoch 846/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.1616\n",
      "Epoch 847/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0876\n",
      "Epoch 848/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0995\n",
      "Epoch 849/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0822\n",
      "Epoch 850/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.1127\n",
      "Epoch 851/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0720\n",
      "Epoch 852/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.1677\n",
      "Epoch 853/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0976\n",
      "Epoch 854/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1271\n",
      "Epoch 855/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0877\n",
      "Epoch 856/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0947\n",
      "Epoch 857/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0655\n",
      "Epoch 858/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.1731\n",
      "Epoch 859/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0903\n",
      "Epoch 860/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1395\n",
      "Epoch 861/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0949\n",
      "Epoch 862/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0906\n",
      "Epoch 863/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0694\n",
      "Epoch 864/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1505\n",
      "Epoch 865/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0851\n",
      "Epoch 866/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.1555\n",
      "Epoch 867/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0929\n",
      "Epoch 868/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1108\n",
      "Epoch 869/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0701\n",
      "Epoch 870/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1363\n",
      "Epoch 871/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0736\n",
      "Epoch 872/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.1523\n",
      "Epoch 873/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1029\n",
      "Epoch 874/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1060\n",
      "Epoch 875/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0960\n",
      "Epoch 876/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0878\n",
      "Epoch 877/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0828\n",
      "Epoch 878/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.1940\n",
      "Epoch 879/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1011\n",
      "Epoch 880/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1525\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0936\n",
      "Epoch 882/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0903\n",
      "Epoch 883/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0699\n",
      "Epoch 884/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1216\n",
      "Epoch 885/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0747\n",
      "Epoch 886/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.1650\n",
      "Epoch 887/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0914\n",
      "Epoch 888/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1296\n",
      "Epoch 889/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0865\n",
      "Epoch 890/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1015\n",
      "Epoch 891/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0602\n",
      "Epoch 892/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.1489\n",
      "Epoch 893/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0930\n",
      "Epoch 894/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1387\n",
      "Epoch 895/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0871\n",
      "Epoch 896/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0879\n",
      "Epoch 897/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0777\n",
      "Epoch 898/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1529\n",
      "Epoch 899/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0826\n",
      "Epoch 900/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.1815\n",
      "Epoch 901/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0851\n",
      "Epoch 902/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0997\n",
      "Epoch 903/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0795\n",
      "Epoch 904/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.1103\n",
      "Epoch 905/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0674\n",
      "Epoch 906/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.1586\n",
      "Epoch 907/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0908\n",
      "Epoch 908/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1378\n",
      "Epoch 909/1000\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0823\n",
      "Epoch 910/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0979\n",
      "Epoch 911/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0639\n",
      "Epoch 912/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1513\n",
      "Epoch 913/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0832\n",
      "Epoch 914/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1433\n",
      "Epoch 915/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0891\n",
      "Epoch 916/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0860\n",
      "Epoch 917/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0768\n",
      "Epoch 918/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1431\n",
      "Epoch 919/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0808\n",
      "Epoch 920/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1807\n",
      "Epoch 921/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0817\n",
      "Epoch 922/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.1074\n",
      "Epoch 923/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0790\n",
      "Epoch 924/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.1091\n",
      "Epoch 925/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0668\n",
      "Epoch 926/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.1539\n",
      "Epoch 927/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0886\n",
      "Epoch 928/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.1404\n",
      "Epoch 929/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0812\n",
      "Epoch 930/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0970\n",
      "Epoch 931/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0632\n",
      "Epoch 932/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1550\n",
      "Epoch 933/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0823\n",
      "Epoch 934/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1397\n",
      "Epoch 935/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0876\n",
      "Epoch 936/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0857\n",
      "Epoch 937/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0741\n",
      "Epoch 938/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1455\n",
      "Epoch 939/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0810\n",
      "Epoch 940/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1726\n",
      "Epoch 941/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0801\n",
      "Epoch 942/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1087\n",
      "Epoch 943/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0752\n",
      "Epoch 944/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.1142\n",
      "Epoch 945/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0683\n",
      "Epoch 946/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1530\n",
      "Epoch 947/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0869\n",
      "Epoch 948/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1305\n",
      "Epoch 949/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0819\n",
      "Epoch 950/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0943\n",
      "Epoch 951/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0673\n",
      "Epoch 952/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.1823\n",
      "Epoch 953/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0854\n",
      "Epoch 954/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1368\n",
      "Epoch 955/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0838\n",
      "Epoch 956/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0883\n",
      "Epoch 957/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0654\n",
      "Epoch 958/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.1340\n",
      "Epoch 959/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0761\n",
      "Epoch 960/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.1610\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0903\n",
      "Epoch 962/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1009\n",
      "Epoch 963/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0829\n",
      "Epoch 964/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0893\n",
      "Epoch 965/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0763\n",
      "Epoch 966/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1940\n",
      "Epoch 967/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0951\n",
      "Epoch 968/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1509\n",
      "Epoch 969/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0828\n",
      "Epoch 970/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0838\n",
      "Epoch 971/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0665\n",
      "Epoch 972/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.1197\n",
      "Epoch 973/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0710\n",
      "Epoch 974/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.1716\n",
      "Epoch 975/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0865\n",
      "Epoch 976/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1177\n",
      "Epoch 977/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0789\n",
      "Epoch 978/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0918\n",
      "Epoch 979/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0628\n",
      "Epoch 980/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1752\n",
      "Epoch 981/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0883\n",
      "Epoch 982/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.1359\n",
      "Epoch 983/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0846\n",
      "Epoch 984/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0859\n",
      "Epoch 985/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0665\n",
      "Epoch 986/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.1400\n",
      "Epoch 987/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0793\n",
      "Epoch 988/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.1607\n",
      "Epoch 989/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0803\n",
      "Epoch 990/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.1096\n",
      "Epoch 991/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0666\n",
      "Epoch 992/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.1209\n",
      "Epoch 993/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0667\n",
      "Epoch 994/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1577\n",
      "Epoch 995/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0925\n",
      "Epoch 996/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1079\n",
      "Epoch 997/1000\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0860\n",
      "Epoch 998/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0855\n",
      "Epoch 999/1000\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0741\n",
      "Epoch 1000/1000\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1710\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_inputs['X'],\n",
    "          train_inputs['target'],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(valid_inputs['X'], valid_inputs['target']),\n",
    "          callbacks=[earlystop ,best_val],\n",
    "          verbose=1 , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model.load_weights(str(sat_var) +'_' +  var_name + '_{:02d}.h5'.format(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0788\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0080\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0253\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0232\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0251\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0237\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0074\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0272\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0091\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0453\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0305\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0107\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0486\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0104\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0280\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0089\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0081\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0123\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0278\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0090\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0093\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0225\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1349684b70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(valid_inputs['X'],\n",
    "          valid_inputs['target'],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=100,\n",
    "          callbacks=[earlystop ,best_val],\n",
    "          verbose=1 , shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"10\" halign=\"left\">target</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">y</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">omega</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t+7</th>\n",
       "      <th>t+8</th>\n",
       "      <th>t+9</th>\n",
       "      <th>t+10</th>\n",
       "      <th>...</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-10 23:00:00</th>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.19404413624700211916</td>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>...</td>\n",
       "      <td>6.52263332280473218105</td>\n",
       "      <td>6.57617398195691471585</td>\n",
       "      <td>6.62038395308589144861</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 00:00:00</th>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.19404413624700211916</td>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>...</td>\n",
       "      <td>6.57617398195691471585</td>\n",
       "      <td>6.62038395308589144861</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 01:00:00</th>\n",
       "      <td>0.19404413624700211916</td>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>...</td>\n",
       "      <td>6.62038395308589144861</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 02:00:00</th>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 03:00:00</th>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>...</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                               target                          \\\n",
       "feature                                   y                           \n",
       "time step                               t+1                     t+2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-10 23:00:00 -0.04749514996851413040 -0.04749514996851413040   \n",
       "2017-11-11 00:00:00 -0.04749514996851413040  0.19404413624700211916   \n",
       "2017-11-11 01:00:00  0.19404413624700211916  0.46194475503740306532   \n",
       "2017-11-11 02:00:00  0.46194475503740306532  0.82264315942287291605   \n",
       "2017-11-11 03:00:00  0.82264315942287291605  1.18369645268441892050   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+3                    t+4   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 0.19404413624700211916 0.46194475503740306532   \n",
       "2017-11-11 00:00:00 0.46194475503740306532 0.82264315942287291605   \n",
       "2017-11-11 01:00:00 0.82264315942287291605 1.18369645268441892050   \n",
       "2017-11-11 02:00:00 1.18369645268441892050 1.40530733235496274602   \n",
       "2017-11-11 03:00:00 1.40530733235496274602 1.40530733235496274602   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+5                    t+6   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 0.82264315942287291605 1.18369645268441892050   \n",
       "2017-11-11 00:00:00 1.18369645268441892050 1.40530733235496274602   \n",
       "2017-11-11 01:00:00 1.40530733235496274602 1.40530733235496274602   \n",
       "2017-11-11 02:00:00 1.40530733235496274602 1.31928791011067270134   \n",
       "2017-11-11 03:00:00 1.31928791011067270134 1.26069452437746742923   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t+7                    t+8   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 1.40530733235496274602 1.40530733235496274602   \n",
       "2017-11-11 00:00:00 1.40530733235496274602 1.31928791011067270134   \n",
       "2017-11-11 01:00:00 1.31928791011067270134 1.26069452437746742923   \n",
       "2017-11-11 02:00:00 1.26069452437746742923 1.00934490392437581363   \n",
       "2017-11-11 03:00:00 1.00934490392437581363 0.56495539050500220846   \n",
       "\n",
       "tensor                                                              \\\n",
       "feature                                                              \n",
       "time step                              t+9                    t+10   \n",
       "Epoch_Time_of_Clock                                                  \n",
       "2017-11-10 23:00:00 1.31928791011067270134  1.26069452437746742923   \n",
       "2017-11-11 00:00:00 1.26069452437746742923  1.00934490392437581363   \n",
       "2017-11-11 01:00:00 1.00934490392437581363  0.56495539050500220846   \n",
       "2017-11-11 02:00:00 0.56495539050500220846  0.09846296321911932048   \n",
       "2017-11-11 03:00:00 0.09846296321911932048 -0.30012666061452453192   \n",
       "\n",
       "tensor                       ...                                X  \\\n",
       "feature                      ...                            omega   \n",
       "time step                    ...                              t-9   \n",
       "Epoch_Time_of_Clock          ...                                    \n",
       "2017-11-10 23:00:00          ...           6.52263332280473218105   \n",
       "2017-11-11 00:00:00          ...           6.57617398195691471585   \n",
       "2017-11-11 01:00:00          ...           6.62038395308589144861   \n",
       "2017-11-11 02:00:00          ...           6.65640088369470817042   \n",
       "2017-11-11 03:00:00          ...           6.68536270392863940515   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-8                    t-7   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.57617398195691471585 6.62038395308589144861   \n",
       "2017-11-11 00:00:00 6.62038395308589144861 6.65640088369470817042   \n",
       "2017-11-11 01:00:00 6.65640088369470817042 6.68536270392863940515   \n",
       "2017-11-11 02:00:00 6.68536270392863940515 6.70840762657706779493   \n",
       "2017-11-11 03:00:00 6.70840762657706779493 6.72667329914241207689   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-6                    t-5   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.65640088369470817042 6.68536270392863940515   \n",
       "2017-11-11 00:00:00 6.68536270392863940515 6.70840762657706779493   \n",
       "2017-11-11 01:00:00 6.70840762657706779493 6.72667329914241207689   \n",
       "2017-11-11 02:00:00 6.72667329914241207689 6.74129765176994677489   \n",
       "2017-11-11 03:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-4                    t-3   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.70840762657706779493 6.72667329914241207689   \n",
       "2017-11-11 00:00:00 6.72667329914241207689 6.74129765176994677489   \n",
       "2017-11-11 01:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "2017-11-11 02:00:00 6.75341861460557169039 6.76417411779518840120   \n",
       "2017-11-11 03:00:00 6.76417411779518840120 6.77470180883933270621   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-2                    t-1   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "2017-11-11 00:00:00 6.75341861460557169039 6.76417411779518840120   \n",
       "2017-11-11 01:00:00 6.76417411779518840120 6.77470180883933270621   \n",
       "2017-11-11 02:00:00 6.77470180883933270621 6.78613961788390618324   \n",
       "2017-11-11 03:00:00 6.78613961788390618324 6.79962575772017441267   \n",
       "\n",
       "tensor                                      \n",
       "feature                                     \n",
       "time step                                t  \n",
       "Epoch_Time_of_Clock                         \n",
       "2017-11-10 23:00:00 6.76417411779518840120  \n",
       "2017-11-11 00:00:00 6.77470180883933270621  \n",
       "2017-11-11 01:00:00 6.78613961788390618324  \n",
       "2017-11-11 02:00:00 6.79962575772017441267  \n",
       "2017-11-11 03:00:00 6.81629787584867319339  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back_dt = dt.datetime.strptime(test_start_dt, '%Y-%m-%d %H:%M:%S') - dt.timedelta(hours=T-1)\n",
    "test = df.copy()[test_start_dt:][Paras[var_name]]\n",
    "test[Paras[var_name]] = X_scaler.transform(test)\n",
    "test_inputs = TimeSeriesTensor(test, var_name, HORIZON, tensor_structure,freq =None)\n",
    "test_inputs.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tensor</th>\n",
       "      <th colspan=\"10\" halign=\"left\">target</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">y</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">omega</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time step</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t+7</th>\n",
       "      <th>t+8</th>\n",
       "      <th>t+9</th>\n",
       "      <th>t+10</th>\n",
       "      <th>...</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-10 23:00:00</th>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.19404413624700211916</td>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>...</td>\n",
       "      <td>6.52263332280473218105</td>\n",
       "      <td>6.57617398195691471585</td>\n",
       "      <td>6.62038395308589144861</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 00:00:00</th>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.19404413624700211916</td>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>...</td>\n",
       "      <td>6.57617398195691471585</td>\n",
       "      <td>6.62038395308589144861</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 01:00:00</th>\n",
       "      <td>0.19404413624700211916</td>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>...</td>\n",
       "      <td>6.62038395308589144861</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 02:00:00</th>\n",
       "      <td>0.46194475503740306532</td>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65640088369470817042</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 03:00:00</th>\n",
       "      <td>0.82264315942287291605</td>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>...</td>\n",
       "      <td>6.68536270392863940515</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 04:00:00</th>\n",
       "      <td>1.18369645268441892050</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>...</td>\n",
       "      <td>6.70840762657706779493</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 05:00:00</th>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>...</td>\n",
       "      <td>6.72667329914241207689</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 06:00:00</th>\n",
       "      <td>1.40530733235496274602</td>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>...</td>\n",
       "      <td>6.74129765176994677489</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 07:00:00</th>\n",
       "      <td>1.31928791011067270134</td>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>...</td>\n",
       "      <td>6.75341861460557169039</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 08:00:00</th>\n",
       "      <td>1.26069452437746742923</td>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>...</td>\n",
       "      <td>6.76417411779518840120</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 09:00:00</th>\n",
       "      <td>1.00934490392437581363</td>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>...</td>\n",
       "      <td>6.77470180883933270621</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 10:00:00</th>\n",
       "      <td>0.56495539050500220846</td>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>...</td>\n",
       "      <td>6.78613961788390618324</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 11:00:00</th>\n",
       "      <td>0.09846296321911932048</td>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>...</td>\n",
       "      <td>6.79962575772017441267</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 12:00:00</th>\n",
       "      <td>-0.30012666061452453192</td>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>...</td>\n",
       "      <td>6.81629787584867319339</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 13:00:00</th>\n",
       "      <td>-0.62935077917560144911</td>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>...</td>\n",
       "      <td>6.83634308348606101191</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 14:00:00</th>\n",
       "      <td>-0.89159638695275433840</td>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>...</td>\n",
       "      <td>6.83808078704657429370</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 15:00:00</th>\n",
       "      <td>-1.08925047846367162308</td>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>...</td>\n",
       "      <td>6.78279988052559268397</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 16:00:00</th>\n",
       "      <td>-1.22470004818246480660</td>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>...</td>\n",
       "      <td>6.74210290834869585552</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 17:00:00</th>\n",
       "      <td>-1.30033209062682719726</td>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>...</td>\n",
       "      <td>6.88880714653155656890</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 18:00:00</th>\n",
       "      <td>-1.31853360027087274098</td>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>...</td>\n",
       "      <td>7.16945051132596766763</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 19:00:00</th>\n",
       "      <td>-1.28169157164681646321</td>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>...</td>\n",
       "      <td>7.30906515640065013173</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 20:00:00</th>\n",
       "      <td>-1.19219299921424792821</td>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>...</td>\n",
       "      <td>7.24373790385281335347</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 21:00:00</th>\n",
       "      <td>-1.05242487749085378290</td>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>...</td>\n",
       "      <td>7.12712324081789549979</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 22:00:00</th>\n",
       "      <td>-0.86477420097980273184</td>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>...</td>\n",
       "      <td>7.04115581218801001029</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 23:00:00</th>\n",
       "      <td>-0.63162796416973310265</td>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>...</td>\n",
       "      <td>6.98643736989720842701</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 00:00:00</th>\n",
       "      <td>-0.35537316156381160148</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>...</td>\n",
       "      <td>6.96003377265225697812</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 01:00:00</th>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>...</td>\n",
       "      <td>6.95901087916055338667</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 02:00:00</th>\n",
       "      <td>0.31691416308103514954</td>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>...</td>\n",
       "      <td>6.98043426548349810190</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 03:00:00</th>\n",
       "      <td>0.70511375824904432008</td>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>...</td>\n",
       "      <td>7.02136979032974206660</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 04:00:00</th>\n",
       "      <td>1.05040049484698294613</td>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>...</td>\n",
       "      <td>7.07888302975943251028</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 05:00:00</th>\n",
       "      <td>1.21305198471984576614</td>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>...</td>\n",
       "      <td>7.15004012512595910067</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 06:00:00</th>\n",
       "      <td>1.19828466932275601309</td>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>...</td>\n",
       "      <td>7.23190636984723944636</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 07:00:00</th>\n",
       "      <td>1.15272323911899876592</td>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>...</td>\n",
       "      <td>7.32154790527415322288</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 08:00:00</th>\n",
       "      <td>1.07786814357278437626</td>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>...</td>\n",
       "      <td>7.41603002482399276118</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 09:00:00</th>\n",
       "      <td>0.83031232596214643582</td>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>...</td>\n",
       "      <td>7.51241915249488290129</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 10:00:00</th>\n",
       "      <td>0.41304187706132033941</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>...</td>\n",
       "      <td>7.60778029905686814516</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 11:00:00</th>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>...</td>\n",
       "      <td>7.69917960586459226846</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 12:00:00</th>\n",
       "      <td>-0.39271368224057368046</td>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>...</td>\n",
       "      <td>7.78368293162356827963</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 13:00:00</th>\n",
       "      <td>-0.69945481921963137406</td>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>...</td>\n",
       "      <td>7.85759270997397063496</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 14:00:00</th>\n",
       "      <td>-0.94362447808817129236</td>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>...</td>\n",
       "      <td>7.89965909883198769137</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 15:00:00</th>\n",
       "      <td>-1.12721975325551548863</td>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>...</td>\n",
       "      <td>7.87488636520894225157</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 16:00:00</th>\n",
       "      <td>-1.25223773908739888228</td>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.83505739687620739176</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 17:00:00</th>\n",
       "      <td>-1.32067552997860504505</td>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>...</td>\n",
       "      <td>7.91281426097266749053</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 18:00:00</th>\n",
       "      <td>-1.33453022032392465412</td>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>...</td>\n",
       "      <td>8.09089693706054724487</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 19:00:00</th>\n",
       "      <td>-1.29579890450362422705</td>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>1.00685604963283181768</td>\n",
       "      <td>...</td>\n",
       "      <td>8.20378492126491387637</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "      <td>8.12943902115187810864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 20:00:00</th>\n",
       "      <td>-1.20647867691248444899</td>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>1.00685604963283181768</td>\n",
       "      <td>1.16735408214440905539</td>\n",
       "      <td>...</td>\n",
       "      <td>8.20456558769877908333</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "      <td>8.12943902115187810864</td>\n",
       "      <td>8.15184827442745962855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 21:00:00</th>\n",
       "      <td>-1.06856663193077228158</td>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>1.00685604963283181768</td>\n",
       "      <td>1.16735408214440905539</td>\n",
       "      <td>1.14545450666833925624</td>\n",
       "      <td>...</td>\n",
       "      <td>8.16986861083594995137</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "      <td>8.12943902115187810864</td>\n",
       "      <td>8.15184827442745962855</td>\n",
       "      <td>8.18068177367628734942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 22:00:00</th>\n",
       "      <td>-0.88405986396779967507</td>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>1.00685604963283181768</td>\n",
       "      <td>1.16735408214440905539</td>\n",
       "      <td>1.14545450666833925624</td>\n",
       "      <td>1.07747725818829209743</td>\n",
       "      <td>...</td>\n",
       "      <td>8.14150345491949600785</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "      <td>8.12943902115187810864</td>\n",
       "      <td>8.15184827442745962855</td>\n",
       "      <td>8.18068177367628734942</td>\n",
       "      <td>8.21573262250614533286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 23:00:00</th>\n",
       "      <td>-0.65495546737477794430</td>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>1.00685604963283181768</td>\n",
       "      <td>1.16735408214440905539</td>\n",
       "      <td>1.14545450666833925624</td>\n",
       "      <td>1.07747725818829209743</td>\n",
       "      <td>0.97484411328082565262</td>\n",
       "      <td>...</td>\n",
       "      <td>8.12101336351441105421</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "      <td>8.12943902115187810864</td>\n",
       "      <td>8.15184827442745962855</td>\n",
       "      <td>8.18068177367628734942</td>\n",
       "      <td>8.21573262250614533286</td>\n",
       "      <td>8.25679307659311056966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13 00:00:00</th>\n",
       "      <td>-0.38325053657554575270</td>\n",
       "      <td>-0.04749514996851413040</td>\n",
       "      <td>0.27997255014954863794</td>\n",
       "      <td>0.66443071761719918467</td>\n",
       "      <td>1.00685604963283181768</td>\n",
       "      <td>1.16735408214440905539</td>\n",
       "      <td>1.14545450666833925624</td>\n",
       "      <td>1.07747725818829209743</td>\n",
       "      <td>0.97484411328082565262</td>\n",
       "      <td>0.72340416195684853484</td>\n",
       "      <td>...</td>\n",
       "      <td>8.10819172287697931267</td>\n",
       "      <td>8.10283050603414878310</td>\n",
       "      <td>8.10472281659746762728</td>\n",
       "      <td>8.11366147553060912401</td>\n",
       "      <td>8.12943902115187810864</td>\n",
       "      <td>8.15184827442745962855</td>\n",
       "      <td>8.18068177367628734942</td>\n",
       "      <td>8.21573262250614533286</td>\n",
       "      <td>8.25679307659311056966</td>\n",
       "      <td>8.30365595690022928466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tensor                               target                          \\\n",
       "feature                                   y                           \n",
       "time step                               t+1                     t+2   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-10 23:00:00 -0.04749514996851413040 -0.04749514996851413040   \n",
       "2017-11-11 00:00:00 -0.04749514996851413040  0.19404413624700211916   \n",
       "2017-11-11 01:00:00  0.19404413624700211916  0.46194475503740306532   \n",
       "2017-11-11 02:00:00  0.46194475503740306532  0.82264315942287291605   \n",
       "2017-11-11 03:00:00  0.82264315942287291605  1.18369645268441892050   \n",
       "2017-11-11 04:00:00  1.18369645268441892050  1.40530733235496274602   \n",
       "2017-11-11 05:00:00  1.40530733235496274602  1.40530733235496274602   \n",
       "2017-11-11 06:00:00  1.40530733235496274602  1.31928791011067270134   \n",
       "2017-11-11 07:00:00  1.31928791011067270134  1.26069452437746742923   \n",
       "2017-11-11 08:00:00  1.26069452437746742923  1.00934490392437581363   \n",
       "2017-11-11 09:00:00  1.00934490392437581363  0.56495539050500220846   \n",
       "2017-11-11 10:00:00  0.56495539050500220846  0.09846296321911932048   \n",
       "2017-11-11 11:00:00  0.09846296321911932048 -0.30012666061452453192   \n",
       "2017-11-11 12:00:00 -0.30012666061452453192 -0.62935077917560144911   \n",
       "2017-11-11 13:00:00 -0.62935077917560144911 -0.89159638695275433840   \n",
       "2017-11-11 14:00:00 -0.89159638695275433840 -1.08925047846367162308   \n",
       "2017-11-11 15:00:00 -1.08925047846367162308 -1.22470004818246480660   \n",
       "2017-11-11 16:00:00 -1.22470004818246480660 -1.30033209062682719726   \n",
       "2017-11-11 17:00:00 -1.30033209062682719726 -1.31853360027087274098   \n",
       "2017-11-11 18:00:00 -1.31853360027087274098 -1.28169157164681646321   \n",
       "2017-11-11 19:00:00 -1.28169157164681646321 -1.19219299921424792821   \n",
       "2017-11-11 20:00:00 -1.19219299921424792821 -1.05242487749085378290   \n",
       "2017-11-11 21:00:00 -1.05242487749085378290 -0.86477420097980273184   \n",
       "2017-11-11 22:00:00 -0.86477420097980273184 -0.63162796416973310265   \n",
       "2017-11-11 23:00:00 -0.63162796416973310265 -0.35537316156381160148   \n",
       "2017-11-12 00:00:00 -0.35537316156381160148 -0.04749514996851413040   \n",
       "2017-11-12 01:00:00 -0.04749514996851413040  0.31691416308103514954   \n",
       "2017-11-12 02:00:00  0.31691416308103514954  0.70511375824904432008   \n",
       "2017-11-12 03:00:00  0.70511375824904432008  1.05040049484698294613   \n",
       "2017-11-12 04:00:00  1.05040049484698294613  1.21305198471984576614   \n",
       "2017-11-12 05:00:00  1.21305198471984576614  1.19828466932275601309   \n",
       "2017-11-12 06:00:00  1.19828466932275601309  1.15272323911899876592   \n",
       "2017-11-12 07:00:00  1.15272323911899876592  1.07786814357278437626   \n",
       "2017-11-12 08:00:00  1.07786814357278437626  0.83031232596214643582   \n",
       "2017-11-12 09:00:00  0.83031232596214643582  0.41304187706132033941   \n",
       "2017-11-12 10:00:00  0.41304187706132033941 -0.04749514996851413040   \n",
       "2017-11-12 11:00:00 -0.04749514996851413040 -0.39271368224057368046   \n",
       "2017-11-12 12:00:00 -0.39271368224057368046 -0.69945481921963137406   \n",
       "2017-11-12 13:00:00 -0.69945481921963137406 -0.94362447808817129236   \n",
       "2017-11-12 14:00:00 -0.94362447808817129236 -1.12721975325551548863   \n",
       "2017-11-12 15:00:00 -1.12721975325551548863 -1.25223773908739888228   \n",
       "2017-11-12 16:00:00 -1.25223773908739888228 -1.32067552997860504505   \n",
       "2017-11-12 17:00:00 -1.32067552997860504505 -1.33453022032392465412   \n",
       "2017-11-12 18:00:00 -1.33453022032392465412 -1.29579890450362422705   \n",
       "2017-11-12 19:00:00 -1.29579890450362422705 -1.20647867691248444899   \n",
       "2017-11-12 20:00:00 -1.20647867691248444899 -1.06856663193077228158   \n",
       "2017-11-12 21:00:00 -1.06856663193077228158 -0.88405986396779967507   \n",
       "2017-11-12 22:00:00 -0.88405986396779967507 -0.65495546737477794430   \n",
       "2017-11-12 23:00:00 -0.65495546737477794430 -0.38325053657554575270   \n",
       "2017-11-13 00:00:00 -0.38325053657554575270 -0.04749514996851413040   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+3                     t+4   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-10 23:00:00  0.19404413624700211916  0.46194475503740306532   \n",
       "2017-11-11 00:00:00  0.46194475503740306532  0.82264315942287291605   \n",
       "2017-11-11 01:00:00  0.82264315942287291605  1.18369645268441892050   \n",
       "2017-11-11 02:00:00  1.18369645268441892050  1.40530733235496274602   \n",
       "2017-11-11 03:00:00  1.40530733235496274602  1.40530733235496274602   \n",
       "2017-11-11 04:00:00  1.40530733235496274602  1.31928791011067270134   \n",
       "2017-11-11 05:00:00  1.31928791011067270134  1.26069452437746742923   \n",
       "2017-11-11 06:00:00  1.26069452437746742923  1.00934490392437581363   \n",
       "2017-11-11 07:00:00  1.00934490392437581363  0.56495539050500220846   \n",
       "2017-11-11 08:00:00  0.56495539050500220846  0.09846296321911932048   \n",
       "2017-11-11 09:00:00  0.09846296321911932048 -0.30012666061452453192   \n",
       "2017-11-11 10:00:00 -0.30012666061452453192 -0.62935077917560144911   \n",
       "2017-11-11 11:00:00 -0.62935077917560144911 -0.89159638695275433840   \n",
       "2017-11-11 12:00:00 -0.89159638695275433840 -1.08925047846367162308   \n",
       "2017-11-11 13:00:00 -1.08925047846367162308 -1.22470004818246480660   \n",
       "2017-11-11 14:00:00 -1.22470004818246480660 -1.30033209062682719726   \n",
       "2017-11-11 15:00:00 -1.30033209062682719726 -1.31853360027087274098   \n",
       "2017-11-11 16:00:00 -1.31853360027087274098 -1.28169157164681646321   \n",
       "2017-11-11 17:00:00 -1.28169157164681646321 -1.19219299921424792821   \n",
       "2017-11-11 18:00:00 -1.19219299921424792821 -1.05242487749085378290   \n",
       "2017-11-11 19:00:00 -1.05242487749085378290 -0.86477420097980273184   \n",
       "2017-11-11 20:00:00 -0.86477420097980273184 -0.63162796416973310265   \n",
       "2017-11-11 21:00:00 -0.63162796416973310265 -0.35537316156381160148   \n",
       "2017-11-11 22:00:00 -0.35537316156381160148 -0.04749514996851413040   \n",
       "2017-11-11 23:00:00 -0.04749514996851413040  0.31691416308103514954   \n",
       "2017-11-12 00:00:00  0.31691416308103514954  0.70511375824904432008   \n",
       "2017-11-12 01:00:00  0.70511375824904432008  1.05040049484698294613   \n",
       "2017-11-12 02:00:00  1.05040049484698294613  1.21305198471984576614   \n",
       "2017-11-12 03:00:00  1.21305198471984576614  1.19828466932275601309   \n",
       "2017-11-12 04:00:00  1.19828466932275601309  1.15272323911899876592   \n",
       "2017-11-12 05:00:00  1.15272323911899876592  1.07786814357278437626   \n",
       "2017-11-12 06:00:00  1.07786814357278437626  0.83031232596214643582   \n",
       "2017-11-12 07:00:00  0.83031232596214643582  0.41304187706132033941   \n",
       "2017-11-12 08:00:00  0.41304187706132033941 -0.04749514996851413040   \n",
       "2017-11-12 09:00:00 -0.04749514996851413040 -0.39271368224057368046   \n",
       "2017-11-12 10:00:00 -0.39271368224057368046 -0.69945481921963137406   \n",
       "2017-11-12 11:00:00 -0.69945481921963137406 -0.94362447808817129236   \n",
       "2017-11-12 12:00:00 -0.94362447808817129236 -1.12721975325551548863   \n",
       "2017-11-12 13:00:00 -1.12721975325551548863 -1.25223773908739888228   \n",
       "2017-11-12 14:00:00 -1.25223773908739888228 -1.32067552997860504505   \n",
       "2017-11-12 15:00:00 -1.32067552997860504505 -1.33453022032392465412   \n",
       "2017-11-12 16:00:00 -1.33453022032392465412 -1.29579890450362422705   \n",
       "2017-11-12 17:00:00 -1.29579890450362422705 -1.20647867691248444899   \n",
       "2017-11-12 18:00:00 -1.20647867691248444899 -1.06856663193077228158   \n",
       "2017-11-12 19:00:00 -1.06856663193077228158 -0.88405986396779967507   \n",
       "2017-11-12 20:00:00 -0.88405986396779967507 -0.65495546737477794430   \n",
       "2017-11-12 21:00:00 -0.65495546737477794430 -0.38325053657554575270   \n",
       "2017-11-12 22:00:00 -0.38325053657554575270 -0.04749514996851413040   \n",
       "2017-11-12 23:00:00 -0.04749514996851413040  0.27997255014954863794   \n",
       "2017-11-13 00:00:00  0.27997255014954863794  0.66443071761719918467   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+5                     t+6   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-10 23:00:00  0.82264315942287291605  1.18369645268441892050   \n",
       "2017-11-11 00:00:00  1.18369645268441892050  1.40530733235496274602   \n",
       "2017-11-11 01:00:00  1.40530733235496274602  1.40530733235496274602   \n",
       "2017-11-11 02:00:00  1.40530733235496274602  1.31928791011067270134   \n",
       "2017-11-11 03:00:00  1.31928791011067270134  1.26069452437746742923   \n",
       "2017-11-11 04:00:00  1.26069452437746742923  1.00934490392437581363   \n",
       "2017-11-11 05:00:00  1.00934490392437581363  0.56495539050500220846   \n",
       "2017-11-11 06:00:00  0.56495539050500220846  0.09846296321911932048   \n",
       "2017-11-11 07:00:00  0.09846296321911932048 -0.30012666061452453192   \n",
       "2017-11-11 08:00:00 -0.30012666061452453192 -0.62935077917560144911   \n",
       "2017-11-11 09:00:00 -0.62935077917560144911 -0.89159638695275433840   \n",
       "2017-11-11 10:00:00 -0.89159638695275433840 -1.08925047846367162308   \n",
       "2017-11-11 11:00:00 -1.08925047846367162308 -1.22470004818246480660   \n",
       "2017-11-11 12:00:00 -1.22470004818246480660 -1.30033209062682719726   \n",
       "2017-11-11 13:00:00 -1.30033209062682719726 -1.31853360027087274098   \n",
       "2017-11-11 14:00:00 -1.31853360027087274098 -1.28169157164681646321   \n",
       "2017-11-11 15:00:00 -1.28169157164681646321 -1.19219299921424792821   \n",
       "2017-11-11 16:00:00 -1.19219299921424792821 -1.05242487749085378290   \n",
       "2017-11-11 17:00:00 -1.05242487749085378290 -0.86477420097980273184   \n",
       "2017-11-11 18:00:00 -0.86477420097980273184 -0.63162796416973310265   \n",
       "2017-11-11 19:00:00 -0.63162796416973310265 -0.35537316156381160148   \n",
       "2017-11-11 20:00:00 -0.35537316156381160148 -0.04749514996851413040   \n",
       "2017-11-11 21:00:00 -0.04749514996851413040  0.31691416308103514954   \n",
       "2017-11-11 22:00:00  0.31691416308103514954  0.70511375824904432008   \n",
       "2017-11-11 23:00:00  0.70511375824904432008  1.05040049484698294613   \n",
       "2017-11-12 00:00:00  1.05040049484698294613  1.21305198471984576614   \n",
       "2017-11-12 01:00:00  1.21305198471984576614  1.19828466932275601309   \n",
       "2017-11-12 02:00:00  1.19828466932275601309  1.15272323911899876592   \n",
       "2017-11-12 03:00:00  1.15272323911899876592  1.07786814357278437626   \n",
       "2017-11-12 04:00:00  1.07786814357278437626  0.83031232596214643582   \n",
       "2017-11-12 05:00:00  0.83031232596214643582  0.41304187706132033941   \n",
       "2017-11-12 06:00:00  0.41304187706132033941 -0.04749514996851413040   \n",
       "2017-11-12 07:00:00 -0.04749514996851413040 -0.39271368224057368046   \n",
       "2017-11-12 08:00:00 -0.39271368224057368046 -0.69945481921963137406   \n",
       "2017-11-12 09:00:00 -0.69945481921963137406 -0.94362447808817129236   \n",
       "2017-11-12 10:00:00 -0.94362447808817129236 -1.12721975325551548863   \n",
       "2017-11-12 11:00:00 -1.12721975325551548863 -1.25223773908739888228   \n",
       "2017-11-12 12:00:00 -1.25223773908739888228 -1.32067552997860504505   \n",
       "2017-11-12 13:00:00 -1.32067552997860504505 -1.33453022032392465412   \n",
       "2017-11-12 14:00:00 -1.33453022032392465412 -1.29579890450362422705   \n",
       "2017-11-12 15:00:00 -1.29579890450362422705 -1.20647867691248444899   \n",
       "2017-11-12 16:00:00 -1.20647867691248444899 -1.06856663193077228158   \n",
       "2017-11-12 17:00:00 -1.06856663193077228158 -0.88405986396779967507   \n",
       "2017-11-12 18:00:00 -0.88405986396779967507 -0.65495546737477794430   \n",
       "2017-11-12 19:00:00 -0.65495546737477794430 -0.38325053657554575270   \n",
       "2017-11-12 20:00:00 -0.38325053657554575270 -0.04749514996851413040   \n",
       "2017-11-12 21:00:00 -0.04749514996851413040  0.27997255014954863794   \n",
       "2017-11-12 22:00:00  0.27997255014954863794  0.66443071761719918467   \n",
       "2017-11-12 23:00:00  0.66443071761719918467  1.00685604963283181768   \n",
       "2017-11-13 00:00:00  1.00685604963283181768  1.16735408214440905539   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+7                     t+8   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-10 23:00:00  1.40530733235496274602  1.40530733235496274602   \n",
       "2017-11-11 00:00:00  1.40530733235496274602  1.31928791011067270134   \n",
       "2017-11-11 01:00:00  1.31928791011067270134  1.26069452437746742923   \n",
       "2017-11-11 02:00:00  1.26069452437746742923  1.00934490392437581363   \n",
       "2017-11-11 03:00:00  1.00934490392437581363  0.56495539050500220846   \n",
       "2017-11-11 04:00:00  0.56495539050500220846  0.09846296321911932048   \n",
       "2017-11-11 05:00:00  0.09846296321911932048 -0.30012666061452453192   \n",
       "2017-11-11 06:00:00 -0.30012666061452453192 -0.62935077917560144911   \n",
       "2017-11-11 07:00:00 -0.62935077917560144911 -0.89159638695275433840   \n",
       "2017-11-11 08:00:00 -0.89159638695275433840 -1.08925047846367162308   \n",
       "2017-11-11 09:00:00 -1.08925047846367162308 -1.22470004818246480660   \n",
       "2017-11-11 10:00:00 -1.22470004818246480660 -1.30033209062682719726   \n",
       "2017-11-11 11:00:00 -1.30033209062682719726 -1.31853360027087274098   \n",
       "2017-11-11 12:00:00 -1.31853360027087274098 -1.28169157164681646321   \n",
       "2017-11-11 13:00:00 -1.28169157164681646321 -1.19219299921424792821   \n",
       "2017-11-11 14:00:00 -1.19219299921424792821 -1.05242487749085378290   \n",
       "2017-11-11 15:00:00 -1.05242487749085378290 -0.86477420097980273184   \n",
       "2017-11-11 16:00:00 -0.86477420097980273184 -0.63162796416973310265   \n",
       "2017-11-11 17:00:00 -0.63162796416973310265 -0.35537316156381160148   \n",
       "2017-11-11 18:00:00 -0.35537316156381160148 -0.04749514996851413040   \n",
       "2017-11-11 19:00:00 -0.04749514996851413040  0.31691416308103514954   \n",
       "2017-11-11 20:00:00  0.31691416308103514954  0.70511375824904432008   \n",
       "2017-11-11 21:00:00  0.70511375824904432008  1.05040049484698294613   \n",
       "2017-11-11 22:00:00  1.05040049484698294613  1.21305198471984576614   \n",
       "2017-11-11 23:00:00  1.21305198471984576614  1.19828466932275601309   \n",
       "2017-11-12 00:00:00  1.19828466932275601309  1.15272323911899876592   \n",
       "2017-11-12 01:00:00  1.15272323911899876592  1.07786814357278437626   \n",
       "2017-11-12 02:00:00  1.07786814357278437626  0.83031232596214643582   \n",
       "2017-11-12 03:00:00  0.83031232596214643582  0.41304187706132033941   \n",
       "2017-11-12 04:00:00  0.41304187706132033941 -0.04749514996851413040   \n",
       "2017-11-12 05:00:00 -0.04749514996851413040 -0.39271368224057368046   \n",
       "2017-11-12 06:00:00 -0.39271368224057368046 -0.69945481921963137406   \n",
       "2017-11-12 07:00:00 -0.69945481921963137406 -0.94362447808817129236   \n",
       "2017-11-12 08:00:00 -0.94362447808817129236 -1.12721975325551548863   \n",
       "2017-11-12 09:00:00 -1.12721975325551548863 -1.25223773908739888228   \n",
       "2017-11-12 10:00:00 -1.25223773908739888228 -1.32067552997860504505   \n",
       "2017-11-12 11:00:00 -1.32067552997860504505 -1.33453022032392465412   \n",
       "2017-11-12 12:00:00 -1.33453022032392465412 -1.29579890450362422705   \n",
       "2017-11-12 13:00:00 -1.29579890450362422705 -1.20647867691248444899   \n",
       "2017-11-12 14:00:00 -1.20647867691248444899 -1.06856663193077228158   \n",
       "2017-11-12 15:00:00 -1.06856663193077228158 -0.88405986396779967507   \n",
       "2017-11-12 16:00:00 -0.88405986396779967507 -0.65495546737477794430   \n",
       "2017-11-12 17:00:00 -0.65495546737477794430 -0.38325053657554575270   \n",
       "2017-11-12 18:00:00 -0.38325053657554575270 -0.04749514996851413040   \n",
       "2017-11-12 19:00:00 -0.04749514996851413040  0.27997255014954863794   \n",
       "2017-11-12 20:00:00  0.27997255014954863794  0.66443071761719918467   \n",
       "2017-11-12 21:00:00  0.66443071761719918467  1.00685604963283181768   \n",
       "2017-11-12 22:00:00  1.00685604963283181768  1.16735408214440905539   \n",
       "2017-11-12 23:00:00  1.16735408214440905539  1.14545450666833925624   \n",
       "2017-11-13 00:00:00  1.14545450666833925624  1.07747725818829209743   \n",
       "\n",
       "tensor                                                               \\\n",
       "feature                                                               \n",
       "time step                               t+9                    t+10   \n",
       "Epoch_Time_of_Clock                                                   \n",
       "2017-11-10 23:00:00  1.31928791011067270134  1.26069452437746742923   \n",
       "2017-11-11 00:00:00  1.26069452437746742923  1.00934490392437581363   \n",
       "2017-11-11 01:00:00  1.00934490392437581363  0.56495539050500220846   \n",
       "2017-11-11 02:00:00  0.56495539050500220846  0.09846296321911932048   \n",
       "2017-11-11 03:00:00  0.09846296321911932048 -0.30012666061452453192   \n",
       "2017-11-11 04:00:00 -0.30012666061452453192 -0.62935077917560144911   \n",
       "2017-11-11 05:00:00 -0.62935077917560144911 -0.89159638695275433840   \n",
       "2017-11-11 06:00:00 -0.89159638695275433840 -1.08925047846367162308   \n",
       "2017-11-11 07:00:00 -1.08925047846367162308 -1.22470004818246480660   \n",
       "2017-11-11 08:00:00 -1.22470004818246480660 -1.30033209062682719726   \n",
       "2017-11-11 09:00:00 -1.30033209062682719726 -1.31853360027087274098   \n",
       "2017-11-11 10:00:00 -1.31853360027087274098 -1.28169157164681646321   \n",
       "2017-11-11 11:00:00 -1.28169157164681646321 -1.19219299921424792821   \n",
       "2017-11-11 12:00:00 -1.19219299921424792821 -1.05242487749085378290   \n",
       "2017-11-11 13:00:00 -1.05242487749085378290 -0.86477420097980273184   \n",
       "2017-11-11 14:00:00 -0.86477420097980273184 -0.63162796416973310265   \n",
       "2017-11-11 15:00:00 -0.63162796416973310265 -0.35537316156381160148   \n",
       "2017-11-11 16:00:00 -0.35537316156381160148 -0.04749514996851413040   \n",
       "2017-11-11 17:00:00 -0.04749514996851413040  0.31691416308103514954   \n",
       "2017-11-11 18:00:00  0.31691416308103514954  0.70511375824904432008   \n",
       "2017-11-11 19:00:00  0.70511375824904432008  1.05040049484698294613   \n",
       "2017-11-11 20:00:00  1.05040049484698294613  1.21305198471984576614   \n",
       "2017-11-11 21:00:00  1.21305198471984576614  1.19828466932275601309   \n",
       "2017-11-11 22:00:00  1.19828466932275601309  1.15272323911899876592   \n",
       "2017-11-11 23:00:00  1.15272323911899876592  1.07786814357278437626   \n",
       "2017-11-12 00:00:00  1.07786814357278437626  0.83031232596214643582   \n",
       "2017-11-12 01:00:00  0.83031232596214643582  0.41304187706132033941   \n",
       "2017-11-12 02:00:00  0.41304187706132033941 -0.04749514996851413040   \n",
       "2017-11-12 03:00:00 -0.04749514996851413040 -0.39271368224057368046   \n",
       "2017-11-12 04:00:00 -0.39271368224057368046 -0.69945481921963137406   \n",
       "2017-11-12 05:00:00 -0.69945481921963137406 -0.94362447808817129236   \n",
       "2017-11-12 06:00:00 -0.94362447808817129236 -1.12721975325551548863   \n",
       "2017-11-12 07:00:00 -1.12721975325551548863 -1.25223773908739888228   \n",
       "2017-11-12 08:00:00 -1.25223773908739888228 -1.32067552997860504505   \n",
       "2017-11-12 09:00:00 -1.32067552997860504505 -1.33453022032392465412   \n",
       "2017-11-12 10:00:00 -1.33453022032392465412 -1.29579890450362422705   \n",
       "2017-11-12 11:00:00 -1.29579890450362422705 -1.20647867691248444899   \n",
       "2017-11-12 12:00:00 -1.20647867691248444899 -1.06856663193077228158   \n",
       "2017-11-12 13:00:00 -1.06856663193077228158 -0.88405986396779967507   \n",
       "2017-11-12 14:00:00 -0.88405986396779967507 -0.65495546737477794430   \n",
       "2017-11-12 15:00:00 -0.65495546737477794430 -0.38325053657554575270   \n",
       "2017-11-12 16:00:00 -0.38325053657554575270 -0.04749514996851413040   \n",
       "2017-11-12 17:00:00 -0.04749514996851413040  0.27997255014954863794   \n",
       "2017-11-12 18:00:00  0.27997255014954863794  0.66443071761719918467   \n",
       "2017-11-12 19:00:00  0.66443071761719918467  1.00685604963283181768   \n",
       "2017-11-12 20:00:00  1.00685604963283181768  1.16735408214440905539   \n",
       "2017-11-12 21:00:00  1.16735408214440905539  1.14545450666833925624   \n",
       "2017-11-12 22:00:00  1.14545450666833925624  1.07747725818829209743   \n",
       "2017-11-12 23:00:00  1.07747725818829209743  0.97484411328082565262   \n",
       "2017-11-13 00:00:00  0.97484411328082565262  0.72340416195684853484   \n",
       "\n",
       "tensor                       ...                                X  \\\n",
       "feature                      ...                            omega   \n",
       "time step                    ...                              t-9   \n",
       "Epoch_Time_of_Clock          ...                                    \n",
       "2017-11-10 23:00:00          ...           6.52263332280473218105   \n",
       "2017-11-11 00:00:00          ...           6.57617398195691471585   \n",
       "2017-11-11 01:00:00          ...           6.62038395308589144861   \n",
       "2017-11-11 02:00:00          ...           6.65640088369470817042   \n",
       "2017-11-11 03:00:00          ...           6.68536270392863940515   \n",
       "2017-11-11 04:00:00          ...           6.70840762657706779493   \n",
       "2017-11-11 05:00:00          ...           6.72667329914241207689   \n",
       "2017-11-11 06:00:00          ...           6.74129765176994677489   \n",
       "2017-11-11 07:00:00          ...           6.75341861460557169039   \n",
       "2017-11-11 08:00:00          ...           6.76417411779518840120   \n",
       "2017-11-11 09:00:00          ...           6.77470180883933270621   \n",
       "2017-11-11 10:00:00          ...           6.78613961788390618324   \n",
       "2017-11-11 11:00:00          ...           6.79962575772017441267   \n",
       "2017-11-11 12:00:00          ...           6.81629787584867319339   \n",
       "2017-11-11 13:00:00          ...           6.83634308348606101191   \n",
       "2017-11-11 14:00:00          ...           6.83808078704657429370   \n",
       "2017-11-11 15:00:00          ...           6.78279988052559268397   \n",
       "2017-11-11 16:00:00          ...           6.74210290834869585552   \n",
       "2017-11-11 17:00:00          ...           6.88880714653155656890   \n",
       "2017-11-11 18:00:00          ...           7.16945051132596766763   \n",
       "2017-11-11 19:00:00          ...           7.30906515640065013173   \n",
       "2017-11-11 20:00:00          ...           7.24373790385281335347   \n",
       "2017-11-11 21:00:00          ...           7.12712324081789549979   \n",
       "2017-11-11 22:00:00          ...           7.04115581218801001029   \n",
       "2017-11-11 23:00:00          ...           6.98643736989720842701   \n",
       "2017-11-12 00:00:00          ...           6.96003377265225697812   \n",
       "2017-11-12 01:00:00          ...           6.95901087916055338667   \n",
       "2017-11-12 02:00:00          ...           6.98043426548349810190   \n",
       "2017-11-12 03:00:00          ...           7.02136979032974206660   \n",
       "2017-11-12 04:00:00          ...           7.07888302975943251028   \n",
       "2017-11-12 05:00:00          ...           7.15004012512595910067   \n",
       "2017-11-12 06:00:00          ...           7.23190636984723944636   \n",
       "2017-11-12 07:00:00          ...           7.32154790527415322288   \n",
       "2017-11-12 08:00:00          ...           7.41603002482399276118   \n",
       "2017-11-12 09:00:00          ...           7.51241915249488290129   \n",
       "2017-11-12 10:00:00          ...           7.60778029905686814516   \n",
       "2017-11-12 11:00:00          ...           7.69917960586459226846   \n",
       "2017-11-12 12:00:00          ...           7.78368293162356827963   \n",
       "2017-11-12 13:00:00          ...           7.85759270997397063496   \n",
       "2017-11-12 14:00:00          ...           7.89965909883198769137   \n",
       "2017-11-12 15:00:00          ...           7.87488636520894225157   \n",
       "2017-11-12 16:00:00          ...           7.83505739687620739176   \n",
       "2017-11-12 17:00:00          ...           7.91281426097266749053   \n",
       "2017-11-12 18:00:00          ...           8.09089693706054724487   \n",
       "2017-11-12 19:00:00          ...           8.20378492126491387637   \n",
       "2017-11-12 20:00:00          ...           8.20456558769877908333   \n",
       "2017-11-12 21:00:00          ...           8.16986861083594995137   \n",
       "2017-11-12 22:00:00          ...           8.14150345491949600785   \n",
       "2017-11-12 23:00:00          ...           8.12101336351441105421   \n",
       "2017-11-13 00:00:00          ...           8.10819172287697931267   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-8                    t-7   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.57617398195691471585 6.62038395308589144861   \n",
       "2017-11-11 00:00:00 6.62038395308589144861 6.65640088369470817042   \n",
       "2017-11-11 01:00:00 6.65640088369470817042 6.68536270392863940515   \n",
       "2017-11-11 02:00:00 6.68536270392863940515 6.70840762657706779493   \n",
       "2017-11-11 03:00:00 6.70840762657706779493 6.72667329914241207689   \n",
       "2017-11-11 04:00:00 6.72667329914241207689 6.74129765176994677489   \n",
       "2017-11-11 05:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "2017-11-11 06:00:00 6.75341861460557169039 6.76417411779518840120   \n",
       "2017-11-11 07:00:00 6.76417411779518840120 6.77470180883933270621   \n",
       "2017-11-11 08:00:00 6.77470180883933270621 6.78613961788390618324   \n",
       "2017-11-11 09:00:00 6.78613961788390618324 6.79962575772017441267   \n",
       "2017-11-11 10:00:00 6.79962575772017441267 6.81629787584867319339   \n",
       "2017-11-11 11:00:00 6.81629787584867319339 6.83634308348606101191   \n",
       "2017-11-11 12:00:00 6.83634308348606101191 6.83808078704657429370   \n",
       "2017-11-11 13:00:00 6.83808078704657429370 6.78279988052559268397   \n",
       "2017-11-11 14:00:00 6.78279988052559268397 6.74210290834869585552   \n",
       "2017-11-11 15:00:00 6.74210290834869585552 6.88880714653155656890   \n",
       "2017-11-11 16:00:00 6.88880714653155656890 7.16945051132596766763   \n",
       "2017-11-11 17:00:00 7.16945051132596766763 7.30906515640065013173   \n",
       "2017-11-11 18:00:00 7.30906515640065013173 7.24373790385281335347   \n",
       "2017-11-11 19:00:00 7.24373790385281335347 7.12712324081789549979   \n",
       "2017-11-11 20:00:00 7.12712324081789549979 7.04115581218801001029   \n",
       "2017-11-11 21:00:00 7.04115581218801001029 6.98643736989720842701   \n",
       "2017-11-11 22:00:00 6.98643736989720842701 6.96003377265225697812   \n",
       "2017-11-11 23:00:00 6.96003377265225697812 6.95901087916055338667   \n",
       "2017-11-12 00:00:00 6.95901087916055338667 6.98043426548349810190   \n",
       "2017-11-12 01:00:00 6.98043426548349810190 7.02136979032974206660   \n",
       "2017-11-12 02:00:00 7.02136979032974206660 7.07888302975943251028   \n",
       "2017-11-12 03:00:00 7.07888302975943251028 7.15004012512595910067   \n",
       "2017-11-12 04:00:00 7.15004012512595910067 7.23190636984723944636   \n",
       "2017-11-12 05:00:00 7.23190636984723944636 7.32154790527415322288   \n",
       "2017-11-12 06:00:00 7.32154790527415322288 7.41603002482399276118   \n",
       "2017-11-12 07:00:00 7.41603002482399276118 7.51241915249488290129   \n",
       "2017-11-12 08:00:00 7.51241915249488290129 7.60778029905686814516   \n",
       "2017-11-12 09:00:00 7.60778029905686814516 7.69917960586459226846   \n",
       "2017-11-12 10:00:00 7.69917960586459226846 7.78368293162356827963   \n",
       "2017-11-12 11:00:00 7.78368293162356827963 7.85759270997397063496   \n",
       "2017-11-12 12:00:00 7.85759270997397063496 7.89965909883198769137   \n",
       "2017-11-12 13:00:00 7.89965909883198769137 7.87488636520894225157   \n",
       "2017-11-12 14:00:00 7.87488636520894225157 7.83505739687620739176   \n",
       "2017-11-12 15:00:00 7.83505739687620739176 7.91281426097266749053   \n",
       "2017-11-12 16:00:00 7.91281426097266749053 8.09089693706054724487   \n",
       "2017-11-12 17:00:00 8.09089693706054724487 8.20378492126491387637   \n",
       "2017-11-12 18:00:00 8.20378492126491387637 8.20456558769877908333   \n",
       "2017-11-12 19:00:00 8.20456558769877908333 8.16986861083594995137   \n",
       "2017-11-12 20:00:00 8.16986861083594995137 8.14150345491949600785   \n",
       "2017-11-12 21:00:00 8.14150345491949600785 8.12101336351441105421   \n",
       "2017-11-12 22:00:00 8.12101336351441105421 8.10819172287697931267   \n",
       "2017-11-12 23:00:00 8.10819172287697931267 8.10283050603414878310   \n",
       "2017-11-13 00:00:00 8.10283050603414878310 8.10472281659746762728   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-6                    t-5   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.65640088369470817042 6.68536270392863940515   \n",
       "2017-11-11 00:00:00 6.68536270392863940515 6.70840762657706779493   \n",
       "2017-11-11 01:00:00 6.70840762657706779493 6.72667329914241207689   \n",
       "2017-11-11 02:00:00 6.72667329914241207689 6.74129765176994677489   \n",
       "2017-11-11 03:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "2017-11-11 04:00:00 6.75341861460557169039 6.76417411779518840120   \n",
       "2017-11-11 05:00:00 6.76417411779518840120 6.77470180883933270621   \n",
       "2017-11-11 06:00:00 6.77470180883933270621 6.78613961788390618324   \n",
       "2017-11-11 07:00:00 6.78613961788390618324 6.79962575772017441267   \n",
       "2017-11-11 08:00:00 6.79962575772017441267 6.81629787584867319339   \n",
       "2017-11-11 09:00:00 6.81629787584867319339 6.83634308348606101191   \n",
       "2017-11-11 10:00:00 6.83634308348606101191 6.83808078704657429370   \n",
       "2017-11-11 11:00:00 6.83808078704657429370 6.78279988052559268397   \n",
       "2017-11-11 12:00:00 6.78279988052559268397 6.74210290834869585552   \n",
       "2017-11-11 13:00:00 6.74210290834869585552 6.88880714653155656890   \n",
       "2017-11-11 14:00:00 6.88880714653155656890 7.16945051132596766763   \n",
       "2017-11-11 15:00:00 7.16945051132596766763 7.30906515640065013173   \n",
       "2017-11-11 16:00:00 7.30906515640065013173 7.24373790385281335347   \n",
       "2017-11-11 17:00:00 7.24373790385281335347 7.12712324081789549979   \n",
       "2017-11-11 18:00:00 7.12712324081789549979 7.04115581218801001029   \n",
       "2017-11-11 19:00:00 7.04115581218801001029 6.98643736989720842701   \n",
       "2017-11-11 20:00:00 6.98643736989720842701 6.96003377265225697812   \n",
       "2017-11-11 21:00:00 6.96003377265225697812 6.95901087916055338667   \n",
       "2017-11-11 22:00:00 6.95901087916055338667 6.98043426548349810190   \n",
       "2017-11-11 23:00:00 6.98043426548349810190 7.02136979032974206660   \n",
       "2017-11-12 00:00:00 7.02136979032974206660 7.07888302975943251028   \n",
       "2017-11-12 01:00:00 7.07888302975943251028 7.15004012512595910067   \n",
       "2017-11-12 02:00:00 7.15004012512595910067 7.23190636984723944636   \n",
       "2017-11-12 03:00:00 7.23190636984723944636 7.32154790527415322288   \n",
       "2017-11-12 04:00:00 7.32154790527415322288 7.41603002482399276118   \n",
       "2017-11-12 05:00:00 7.41603002482399276118 7.51241915249488290129   \n",
       "2017-11-12 06:00:00 7.51241915249488290129 7.60778029905686814516   \n",
       "2017-11-12 07:00:00 7.60778029905686814516 7.69917960586459226846   \n",
       "2017-11-12 08:00:00 7.69917960586459226846 7.78368293162356827963   \n",
       "2017-11-12 09:00:00 7.78368293162356827963 7.85759270997397063496   \n",
       "2017-11-12 10:00:00 7.85759270997397063496 7.89965909883198769137   \n",
       "2017-11-12 11:00:00 7.89965909883198769137 7.87488636520894225157   \n",
       "2017-11-12 12:00:00 7.87488636520894225157 7.83505739687620739176   \n",
       "2017-11-12 13:00:00 7.83505739687620739176 7.91281426097266749053   \n",
       "2017-11-12 14:00:00 7.91281426097266749053 8.09089693706054724487   \n",
       "2017-11-12 15:00:00 8.09089693706054724487 8.20378492126491387637   \n",
       "2017-11-12 16:00:00 8.20378492126491387637 8.20456558769877908333   \n",
       "2017-11-12 17:00:00 8.20456558769877908333 8.16986861083594995137   \n",
       "2017-11-12 18:00:00 8.16986861083594995137 8.14150345491949600785   \n",
       "2017-11-12 19:00:00 8.14150345491949600785 8.12101336351441105421   \n",
       "2017-11-12 20:00:00 8.12101336351441105421 8.10819172287697931267   \n",
       "2017-11-12 21:00:00 8.10819172287697931267 8.10283050603414878310   \n",
       "2017-11-12 22:00:00 8.10283050603414878310 8.10472281659746762728   \n",
       "2017-11-12 23:00:00 8.10472281659746762728 8.11366147553060912401   \n",
       "2017-11-13 00:00:00 8.11366147553060912401 8.12943902115187810864   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-4                    t-3   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.70840762657706779493 6.72667329914241207689   \n",
       "2017-11-11 00:00:00 6.72667329914241207689 6.74129765176994677489   \n",
       "2017-11-11 01:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "2017-11-11 02:00:00 6.75341861460557169039 6.76417411779518840120   \n",
       "2017-11-11 03:00:00 6.76417411779518840120 6.77470180883933270621   \n",
       "2017-11-11 04:00:00 6.77470180883933270621 6.78613961788390618324   \n",
       "2017-11-11 05:00:00 6.78613961788390618324 6.79962575772017441267   \n",
       "2017-11-11 06:00:00 6.79962575772017441267 6.81629787584867319339   \n",
       "2017-11-11 07:00:00 6.81629787584867319339 6.83634308348606101191   \n",
       "2017-11-11 08:00:00 6.83634308348606101191 6.83808078704657429370   \n",
       "2017-11-11 09:00:00 6.83808078704657429370 6.78279988052559268397   \n",
       "2017-11-11 10:00:00 6.78279988052559268397 6.74210290834869585552   \n",
       "2017-11-11 11:00:00 6.74210290834869585552 6.88880714653155656890   \n",
       "2017-11-11 12:00:00 6.88880714653155656890 7.16945051132596766763   \n",
       "2017-11-11 13:00:00 7.16945051132596766763 7.30906515640065013173   \n",
       "2017-11-11 14:00:00 7.30906515640065013173 7.24373790385281335347   \n",
       "2017-11-11 15:00:00 7.24373790385281335347 7.12712324081789549979   \n",
       "2017-11-11 16:00:00 7.12712324081789549979 7.04115581218801001029   \n",
       "2017-11-11 17:00:00 7.04115581218801001029 6.98643736989720842701   \n",
       "2017-11-11 18:00:00 6.98643736989720842701 6.96003377265225697812   \n",
       "2017-11-11 19:00:00 6.96003377265225697812 6.95901087916055338667   \n",
       "2017-11-11 20:00:00 6.95901087916055338667 6.98043426548349810190   \n",
       "2017-11-11 21:00:00 6.98043426548349810190 7.02136979032974206660   \n",
       "2017-11-11 22:00:00 7.02136979032974206660 7.07888302975943251028   \n",
       "2017-11-11 23:00:00 7.07888302975943251028 7.15004012512595910067   \n",
       "2017-11-12 00:00:00 7.15004012512595910067 7.23190636984723944636   \n",
       "2017-11-12 01:00:00 7.23190636984723944636 7.32154790527415322288   \n",
       "2017-11-12 02:00:00 7.32154790527415322288 7.41603002482399276118   \n",
       "2017-11-12 03:00:00 7.41603002482399276118 7.51241915249488290129   \n",
       "2017-11-12 04:00:00 7.51241915249488290129 7.60778029905686814516   \n",
       "2017-11-12 05:00:00 7.60778029905686814516 7.69917960586459226846   \n",
       "2017-11-12 06:00:00 7.69917960586459226846 7.78368293162356827963   \n",
       "2017-11-12 07:00:00 7.78368293162356827963 7.85759270997397063496   \n",
       "2017-11-12 08:00:00 7.85759270997397063496 7.89965909883198769137   \n",
       "2017-11-12 09:00:00 7.89965909883198769137 7.87488636520894225157   \n",
       "2017-11-12 10:00:00 7.87488636520894225157 7.83505739687620739176   \n",
       "2017-11-12 11:00:00 7.83505739687620739176 7.91281426097266749053   \n",
       "2017-11-12 12:00:00 7.91281426097266749053 8.09089693706054724487   \n",
       "2017-11-12 13:00:00 8.09089693706054724487 8.20378492126491387637   \n",
       "2017-11-12 14:00:00 8.20378492126491387637 8.20456558769877908333   \n",
       "2017-11-12 15:00:00 8.20456558769877908333 8.16986861083594995137   \n",
       "2017-11-12 16:00:00 8.16986861083594995137 8.14150345491949600785   \n",
       "2017-11-12 17:00:00 8.14150345491949600785 8.12101336351441105421   \n",
       "2017-11-12 18:00:00 8.12101336351441105421 8.10819172287697931267   \n",
       "2017-11-12 19:00:00 8.10819172287697931267 8.10283050603414878310   \n",
       "2017-11-12 20:00:00 8.10283050603414878310 8.10472281659746762728   \n",
       "2017-11-12 21:00:00 8.10472281659746762728 8.11366147553060912401   \n",
       "2017-11-12 22:00:00 8.11366147553060912401 8.12943902115187810864   \n",
       "2017-11-12 23:00:00 8.12943902115187810864 8.15184827442745962855   \n",
       "2017-11-13 00:00:00 8.15184827442745962855 8.18068177367628734942   \n",
       "\n",
       "tensor                                                             \\\n",
       "feature                                                             \n",
       "time step                              t-2                    t-1   \n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-10 23:00:00 6.74129765176994677489 6.75341861460557169039   \n",
       "2017-11-11 00:00:00 6.75341861460557169039 6.76417411779518840120   \n",
       "2017-11-11 01:00:00 6.76417411779518840120 6.77470180883933270621   \n",
       "2017-11-11 02:00:00 6.77470180883933270621 6.78613961788390618324   \n",
       "2017-11-11 03:00:00 6.78613961788390618324 6.79962575772017441267   \n",
       "2017-11-11 04:00:00 6.79962575772017441267 6.81629787584867319339   \n",
       "2017-11-11 05:00:00 6.81629787584867319339 6.83634308348606101191   \n",
       "2017-11-11 06:00:00 6.83634308348606101191 6.83808078704657429370   \n",
       "2017-11-11 07:00:00 6.83808078704657429370 6.78279988052559268397   \n",
       "2017-11-11 08:00:00 6.78279988052559268397 6.74210290834869585552   \n",
       "2017-11-11 09:00:00 6.74210290834869585552 6.88880714653155656890   \n",
       "2017-11-11 10:00:00 6.88880714653155656890 7.16945051132596766763   \n",
       "2017-11-11 11:00:00 7.16945051132596766763 7.30906515640065013173   \n",
       "2017-11-11 12:00:00 7.30906515640065013173 7.24373790385281335347   \n",
       "2017-11-11 13:00:00 7.24373790385281335347 7.12712324081789549979   \n",
       "2017-11-11 14:00:00 7.12712324081789549979 7.04115581218801001029   \n",
       "2017-11-11 15:00:00 7.04115581218801001029 6.98643736989720842701   \n",
       "2017-11-11 16:00:00 6.98643736989720842701 6.96003377265225697812   \n",
       "2017-11-11 17:00:00 6.96003377265225697812 6.95901087916055338667   \n",
       "2017-11-11 18:00:00 6.95901087916055338667 6.98043426548349810190   \n",
       "2017-11-11 19:00:00 6.98043426548349810190 7.02136979032974206660   \n",
       "2017-11-11 20:00:00 7.02136979032974206660 7.07888302975943251028   \n",
       "2017-11-11 21:00:00 7.07888302975943251028 7.15004012512595910067   \n",
       "2017-11-11 22:00:00 7.15004012512595910067 7.23190636984723944636   \n",
       "2017-11-11 23:00:00 7.23190636984723944636 7.32154790527415322288   \n",
       "2017-11-12 00:00:00 7.32154790527415322288 7.41603002482399276118   \n",
       "2017-11-12 01:00:00 7.41603002482399276118 7.51241915249488290129   \n",
       "2017-11-12 02:00:00 7.51241915249488290129 7.60778029905686814516   \n",
       "2017-11-12 03:00:00 7.60778029905686814516 7.69917960586459226846   \n",
       "2017-11-12 04:00:00 7.69917960586459226846 7.78368293162356827963   \n",
       "2017-11-12 05:00:00 7.78368293162356827963 7.85759270997397063496   \n",
       "2017-11-12 06:00:00 7.85759270997397063496 7.89965909883198769137   \n",
       "2017-11-12 07:00:00 7.89965909883198769137 7.87488636520894225157   \n",
       "2017-11-12 08:00:00 7.87488636520894225157 7.83505739687620739176   \n",
       "2017-11-12 09:00:00 7.83505739687620739176 7.91281426097266749053   \n",
       "2017-11-12 10:00:00 7.91281426097266749053 8.09089693706054724487   \n",
       "2017-11-12 11:00:00 8.09089693706054724487 8.20378492126491387637   \n",
       "2017-11-12 12:00:00 8.20378492126491387637 8.20456558769877908333   \n",
       "2017-11-12 13:00:00 8.20456558769877908333 8.16986861083594995137   \n",
       "2017-11-12 14:00:00 8.16986861083594995137 8.14150345491949600785   \n",
       "2017-11-12 15:00:00 8.14150345491949600785 8.12101336351441105421   \n",
       "2017-11-12 16:00:00 8.12101336351441105421 8.10819172287697931267   \n",
       "2017-11-12 17:00:00 8.10819172287697931267 8.10283050603414878310   \n",
       "2017-11-12 18:00:00 8.10283050603414878310 8.10472281659746762728   \n",
       "2017-11-12 19:00:00 8.10472281659746762728 8.11366147553060912401   \n",
       "2017-11-12 20:00:00 8.11366147553060912401 8.12943902115187810864   \n",
       "2017-11-12 21:00:00 8.12943902115187810864 8.15184827442745962855   \n",
       "2017-11-12 22:00:00 8.15184827442745962855 8.18068177367628734942   \n",
       "2017-11-12 23:00:00 8.18068177367628734942 8.21573262250614533286   \n",
       "2017-11-13 00:00:00 8.21573262250614533286 8.25679307659311056966   \n",
       "\n",
       "tensor                                      \n",
       "feature                                     \n",
       "time step                                t  \n",
       "Epoch_Time_of_Clock                         \n",
       "2017-11-10 23:00:00 6.76417411779518840120  \n",
       "2017-11-11 00:00:00 6.77470180883933270621  \n",
       "2017-11-11 01:00:00 6.78613961788390618324  \n",
       "2017-11-11 02:00:00 6.79962575772017441267  \n",
       "2017-11-11 03:00:00 6.81629787584867319339  \n",
       "2017-11-11 04:00:00 6.83634308348606101191  \n",
       "2017-11-11 05:00:00 6.83808078704657429370  \n",
       "2017-11-11 06:00:00 6.78279988052559268397  \n",
       "2017-11-11 07:00:00 6.74210290834869585552  \n",
       "2017-11-11 08:00:00 6.88880714653155656890  \n",
       "2017-11-11 09:00:00 7.16945051132596766763  \n",
       "2017-11-11 10:00:00 7.30906515640065013173  \n",
       "2017-11-11 11:00:00 7.24373790385281335347  \n",
       "2017-11-11 12:00:00 7.12712324081789549979  \n",
       "2017-11-11 13:00:00 7.04115581218801001029  \n",
       "2017-11-11 14:00:00 6.98643736989720842701  \n",
       "2017-11-11 15:00:00 6.96003377265225697812  \n",
       "2017-11-11 16:00:00 6.95901087916055338667  \n",
       "2017-11-11 17:00:00 6.98043426548349810190  \n",
       "2017-11-11 18:00:00 7.02136979032974206660  \n",
       "2017-11-11 19:00:00 7.07888302975943251028  \n",
       "2017-11-11 20:00:00 7.15004012512595910067  \n",
       "2017-11-11 21:00:00 7.23190636984723944636  \n",
       "2017-11-11 22:00:00 7.32154790527415322288  \n",
       "2017-11-11 23:00:00 7.41603002482399276118  \n",
       "2017-11-12 00:00:00 7.51241915249488290129  \n",
       "2017-11-12 01:00:00 7.60778029905686814516  \n",
       "2017-11-12 02:00:00 7.69917960586459226846  \n",
       "2017-11-12 03:00:00 7.78368293162356827963  \n",
       "2017-11-12 04:00:00 7.85759270997397063496  \n",
       "2017-11-12 05:00:00 7.89965909883198769137  \n",
       "2017-11-12 06:00:00 7.87488636520894225157  \n",
       "2017-11-12 07:00:00 7.83505739687620739176  \n",
       "2017-11-12 08:00:00 7.91281426097266749053  \n",
       "2017-11-12 09:00:00 8.09089693706054724487  \n",
       "2017-11-12 10:00:00 8.20378492126491387637  \n",
       "2017-11-12 11:00:00 8.20456558769877908333  \n",
       "2017-11-12 12:00:00 8.16986861083594995137  \n",
       "2017-11-12 13:00:00 8.14150345491949600785  \n",
       "2017-11-12 14:00:00 8.12101336351441105421  \n",
       "2017-11-12 15:00:00 8.10819172287697931267  \n",
       "2017-11-12 16:00:00 8.10283050603414878310  \n",
       "2017-11-12 17:00:00 8.10472281659746762728  \n",
       "2017-11-12 18:00:00 8.11366147553060912401  \n",
       "2017-11-12 19:00:00 8.12943902115187810864  \n",
       "2017-11-12 20:00:00 8.15184827442745962855  \n",
       "2017-11-12 21:00:00 8.18068177367628734942  \n",
       "2017-11-12 22:00:00 8.21573262250614533286  \n",
       "2017-11-12 23:00:00 8.25679307659311056966  \n",
       "2017-11-13 00:00:00 8.30365595690022928466  \n",
       "\n",
       "[50 rows x 168 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.dataframe.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437, 168)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7701668 , -0.8893684 , -0.89038575, ..., -0.5147062 ,\n",
       "        -0.77636683, -0.98749435],\n",
       "       [-0.72159946, -0.8158428 , -0.79867464, ..., -0.64098907,\n",
       "        -0.8876246 , -1.0777663 ],\n",
       "       [-0.6679045 , -0.73911834, -0.707759  , ..., -0.76979935,\n",
       "        -0.99293756, -1.1592311 ],\n",
       "       ...,\n",
       "       [-0.39693636, -0.40659946, -0.3384969 , ..., -1.1249083 ,\n",
       "        -0.9849645 , -0.7574408 ],\n",
       "       [-0.39581403, -0.40684158, -0.34117845, ..., -1.1160161 ,\n",
       "        -0.97533375, -0.7473269 ],\n",
       "       [-0.39603582, -0.40919262, -0.34680364, ..., -1.1086224 ,\n",
       "        -0.9696984 , -0.7439916 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp    h              prediction                  actual\n",
      "0 2017-11-10 23:00:00  t+1 -0.00000000949743283974 -0.00000000900000000000\n",
      "1 2017-11-11 00:00:00  t+1 -0.00000000946400272431 -0.00000000900000000000\n",
      "2 2017-11-11 01:00:00  t+1 -0.00000000942704314852 -0.00000000883374251548\n",
      "3 2017-11-11 02:00:00  t+1 -0.00000000938314305695 -0.00000000864933987159\n",
      "4 2017-11-11 03:00:00  t+1 -0.00000000932756941073 -0.00000000840106220909\n",
      "                timestamp     h              prediction  \\\n",
      "10483 2017-11-28 23:00:00  t+24 -0.00000000951869268231   \n",
      "10484 2017-11-29 00:00:00  t+24 -0.00000000950164959037   \n",
      "10485 2017-11-29 01:00:00  t+24 -0.00000000948867321202   \n",
      "10486 2017-11-29 02:00:00  t+24 -0.00000000948171156716   \n",
      "10487 2017-11-29 03:00:00  t+24 -0.00000000947941579939   \n",
      "\n",
      "                       actual  \n",
      "10483 -0.00000000640544942104  \n",
      "10484 -0.00000000652218498120  \n",
      "10485 -0.00000000678410990516  \n",
      "10486 -0.00000000721176326813  \n",
      "10487 -0.00000000782568414532  \n",
      "(10488, 4)\n"
     ]
    }
   ],
   "source": [
    "eval_df = create_evaluation_df(predictions, test_inputs, HORIZON, y_scalar)\n",
    "print(eval_df.head())\n",
    "print(eval_df.tail())\n",
    "print(eval_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h\n",
       "t+1    -0.07724178423743587041\n",
       "t+10   -0.04279287214695590841\n",
       "t+11   -0.03635866525948710376\n",
       "t+12   -0.03239630514088921720\n",
       "t+13   -0.03051199301725383492\n",
       "t+14   -0.03157803214954682525\n",
       "t+15   -0.03404558119010442363\n",
       "t+16   -0.03756993932855166862\n",
       "t+17   -0.04361065745029887170\n",
       "t+18   -0.05288264630645108516\n",
       "t+19   -0.06506145058498735700\n",
       "t+2    -0.07902206420556748268\n",
       "t+20   -0.07757988015434082174\n",
       "t+21   -0.08911102876482543400\n",
       "t+22   -0.09882818176695529200\n",
       "t+23   -0.10572746836457580510\n",
       "t+24   -0.10936590195948509008\n",
       "t+3    -0.07780848477775537120\n",
       "t+4    -0.07538977209156920434\n",
       "t+5    -0.07219464346528241261\n",
       "t+6    -0.06823753152588529769\n",
       "t+7    -0.06322232422356871551\n",
       "t+8    -0.05709515621116044437\n",
       "t+9    -0.05004589541436634675\n",
       "Name: APE, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']\n",
    "eval_df.groupby('h')['APE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.249364718389024e-10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(eval_df['prediction'], eval_df['actual'])\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "a = mean_absolute_error(eval_df['prediction'], eval_df['actual'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot actuals vs predictions at each horizon for first week of the test period. As is to be expected, predictions for one step ahead (*t+1*) are more accurate than those for 2 or 3 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13496b2e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]\n",
    "for t in range(1, HORIZON+1):\n",
    "    plot_df['t+'+str(t)] = eval_df[ (eval_df.h=='t+'+str(t))]['prediction'].values\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+1'], color='blue', linewidth=4.0, alpha=0.75)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+2'], color='blue', linewidth=3.0, alpha=0.5)\n",
    "ax.plot(plot_df['timestamp'], plot_df['t+3'], color='blue', linewidth=2.0, alpha=0.25)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>0.00000000468162357984</td>\n",
       "      <td>0.00000496394932270000</td>\n",
       "      <td>5,153.67251396000028762501</td>\n",
       "      <td>288.25000000000000000000</td>\n",
       "      <td>-0.00000000813141013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>0.00000000471841082646</td>\n",
       "      <td>0.00000500492751598000</td>\n",
       "      <td>5,153.67150496999965980649</td>\n",
       "      <td>287.78125000000000000000</td>\n",
       "      <td>-0.00000000819855578847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>0.00000000468769526132</td>\n",
       "      <td>0.00000502541661263000</td>\n",
       "      <td>5,153.67233276000024488894</td>\n",
       "      <td>285.18750000000000000000</td>\n",
       "      <td>-0.00000000822212819893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>0.00000000469483841601</td>\n",
       "      <td>0.00000506825745106000</td>\n",
       "      <td>5,153.67309189000025071437</td>\n",
       "      <td>286.96875000000000000000</td>\n",
       "      <td>-0.00000000834534761723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>0.00000000459626288137</td>\n",
       "      <td>0.00000505149364471000</td>\n",
       "      <td>5,153.67578505999972549034</td>\n",
       "      <td>287.53125000000000000000</td>\n",
       "      <td>-0.00000000830641742420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>0.00000000458697678028</td>\n",
       "      <td>0.00000484287738800000</td>\n",
       "      <td>5,153.67449759999999514548</td>\n",
       "      <td>290.46875000000000000000</td>\n",
       "      <td>-0.00000000827534470132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-28 12:00:00 0.00000000468162357984 0.00000496394932270000   \n",
       "2017-11-28 14:00:00 0.00000000471841082646 0.00000500492751598000   \n",
       "2017-11-28 16:00:00 0.00000000468769526132 0.00000502541661263000   \n",
       "2017-11-28 18:00:00 0.00000000469483841601 0.00000506825745106000   \n",
       "2017-11-28 20:00:00 0.00000000459626288137 0.00000505149364471000   \n",
       "2017-11-28 22:00:00 0.00000000458697678028 0.00000484287738800000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-28 12:00:00 5,153.67251396000028762501 288.25000000000000000000   \n",
       "2017-11-28 14:00:00 5,153.67150496999965980649 287.78125000000000000000   \n",
       "2017-11-28 16:00:00 5,153.67233276000024488894 285.18750000000000000000   \n",
       "2017-11-28 18:00:00 5,153.67309189000025071437 286.96875000000000000000   \n",
       "2017-11-28 20:00:00 5,153.67578505999972549034 287.53125000000000000000   \n",
       "2017-11-28 22:00:00 5,153.67449759999999514548 290.46875000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-28 12:00:00 -0.00000000813141013444  \n",
       "2017-11-28 14:00:00 -0.00000000819855578847  \n",
       "2017-11-28 16:00:00 -0.00000000822212819893  \n",
       "2017-11-28 18:00:00 -0.00000000834534761723  \n",
       "2017-11-28 20:00:00 -0.00000000830641742420  \n",
       "2017-11-28 22:00:00 -0.00000000827534470132  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.iloc[156:162  , :]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key , value in enumerate(columns):\n",
    "    new_df[value] = a[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna( how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Del_n</th>\n",
       "      <th>Cus</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>Crc</th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-28 12:00:00</th>\n",
       "      <td>0.00000000468162357984</td>\n",
       "      <td>0.00000496394932270000</td>\n",
       "      <td>5,153.67251396000028762501</td>\n",
       "      <td>288.25000000000000000000</td>\n",
       "      <td>-0.00000000813141013444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 14:00:00</th>\n",
       "      <td>0.00000000471841082646</td>\n",
       "      <td>0.00000500492751598000</td>\n",
       "      <td>5,153.67150496999965980649</td>\n",
       "      <td>287.78125000000000000000</td>\n",
       "      <td>-0.00000000819855578847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 16:00:00</th>\n",
       "      <td>0.00000000468769526132</td>\n",
       "      <td>0.00000502541661263000</td>\n",
       "      <td>5,153.67233276000024488894</td>\n",
       "      <td>285.18750000000000000000</td>\n",
       "      <td>-0.00000000822212819893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 18:00:00</th>\n",
       "      <td>0.00000000469483841601</td>\n",
       "      <td>0.00000506825745106000</td>\n",
       "      <td>5,153.67309189000025071437</td>\n",
       "      <td>286.96875000000000000000</td>\n",
       "      <td>-0.00000000834534761723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 20:00:00</th>\n",
       "      <td>0.00000000459626288137</td>\n",
       "      <td>0.00000505149364471000</td>\n",
       "      <td>5,153.67578505999972549034</td>\n",
       "      <td>287.53125000000000000000</td>\n",
       "      <td>-0.00000000830641742420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28 22:00:00</th>\n",
       "      <td>0.00000000458697678028</td>\n",
       "      <td>0.00000484287738800000</td>\n",
       "      <td>5,153.67449759999999514548</td>\n",
       "      <td>290.46875000000000000000</td>\n",
       "      <td>-0.00000000827534470132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Del_n                    Cus  \\\n",
       "Epoch_Time_of_Clock                                                 \n",
       "2017-11-28 12:00:00 0.00000000468162357984 0.00000496394932270000   \n",
       "2017-11-28 14:00:00 0.00000000471841082646 0.00000500492751598000   \n",
       "2017-11-28 16:00:00 0.00000000468769526132 0.00000502541661263000   \n",
       "2017-11-28 18:00:00 0.00000000469483841601 0.00000506825745106000   \n",
       "2017-11-28 20:00:00 0.00000000459626288137 0.00000505149364471000   \n",
       "2017-11-28 22:00:00 0.00000000458697678028 0.00000484287738800000   \n",
       "\n",
       "                                        sqrt_A                      Crc  \\\n",
       "Epoch_Time_of_Clock                                                       \n",
       "2017-11-28 12:00:00 5,153.67251396000028762501 288.25000000000000000000   \n",
       "2017-11-28 14:00:00 5,153.67150496999965980649 287.78125000000000000000   \n",
       "2017-11-28 16:00:00 5,153.67233276000024488894 285.18750000000000000000   \n",
       "2017-11-28 18:00:00 5,153.67309189000025071437 286.96875000000000000000   \n",
       "2017-11-28 20:00:00 5,153.67578505999972549034 287.53125000000000000000   \n",
       "2017-11-28 22:00:00 5,153.67449759999999514548 290.46875000000000000000   \n",
       "\n",
       "                                  OMEGA_dot  \n",
       "Epoch_Time_of_Clock                          \n",
       "2017-11-28 12:00:00 -0.00000000813141013444  \n",
       "2017-11-28 14:00:00 -0.00000000819855578847  \n",
       "2017-11-28 16:00:00 -0.00000000822212819893  \n",
       "2017-11-28 18:00:00 -0.00000000834534761723  \n",
       "2017-11-28 20:00:00 -0.00000000830641742420  \n",
       "2017-11-28 22:00:00 -0.00000000827534470132  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 11, 29)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating index for output\n",
    "import datetime\n",
    "date = new_df.index.date[0]\n",
    "date + datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = new_df.index + datetime.timedelta(days =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-11-29 12:00:00', '2017-11-29 14:00:00',\n",
       "               '2017-11-29 16:00:00', '2017-11-29 18:00:00',\n",
       "               '2017-11-29 20:00:00', '2017-11-29 22:00:00'],\n",
       "              dtype='datetime64[ns]', name='Epoch_Time_of_Clock', freq='2H')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.index= date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'], dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Del_n                    Cus  \\\n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 12:00:00 0.00000000468162357984 0.00000496394932270000   \n",
      "2017-11-29 14:00:00 0.00000000471841082646 0.00000500492751598000   \n",
      "2017-11-29 16:00:00 0.00000000468769526132 0.00000502541661263000   \n",
      "2017-11-29 18:00:00 0.00000000469483841601 0.00000506825745106000   \n",
      "2017-11-29 20:00:00 0.00000000459626288137 0.00000505149364471000   \n",
      "2017-11-29 22:00:00 0.00000000458697678028 0.00000484287738800000   \n",
      "\n",
      "                                        sqrt_A                      Crc  \\\n",
      "Epoch_Time_of_Clock                                                       \n",
      "2017-11-29 12:00:00 5,153.67251396000028762501 288.25000000000000000000   \n",
      "2017-11-29 14:00:00 5,153.67150496999965980649 287.78125000000000000000   \n",
      "2017-11-29 16:00:00 5,153.67233276000024488894 285.18750000000000000000   \n",
      "2017-11-29 18:00:00 5,153.67309189000025071437 286.96875000000000000000   \n",
      "2017-11-29 20:00:00 5,153.67578505999972549034 287.53125000000000000000   \n",
      "2017-11-29 22:00:00 5,153.67449759999999514548 290.46875000000000000000   \n",
      "\n",
      "                                  OMEGA_dot  \n",
      "Epoch_Time_of_Clock                          \n",
      "2017-11-29 12:00:00 -0.00000000813141013444  \n",
      "2017-11-29 14:00:00 -0.00000000819855578847  \n",
      "2017-11-29 16:00:00 -0.00000000822212819893  \n",
      "2017-11-29 18:00:00 -0.00000000834534761723  \n",
      "2017-11-29 20:00:00 -0.00000000830641742420  \n",
      "2017-11-29 22:00:00 -0.00000000827534470132  \n",
      "Index(['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(new_df)\n",
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Del_n                     Cus  \\\n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 12:00:00 0.91269027718195072651 -1.22312509319444773226   \n",
      "2017-11-29 14:00:00 1.07767086824331581596 -1.20617816297157554040   \n",
      "2017-11-29 16:00:00 0.93992008346927835571 -1.19770469785600397472   \n",
      "2017-11-29 18:00:00 0.97195514972395735676 -1.17998745262262549893   \n",
      "2017-11-29 20:00:00 0.52987123577711836564 -1.18692028771718405267   \n",
      "\n",
      "                                     sqrt_A                    Crc  \\\n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 12:00:00 -0.90370805607990212227 1.22448116634390147262   \n",
      "2017-11-29 14:00:00 -1.14731878453497881942 1.21440497497780919289   \n",
      "2017-11-29 16:00:00 -0.94745701690112382742 1.15865004941876525990   \n",
      "2017-11-29 18:00:00 -0.76417253223977721355 1.19693957660991601166   \n",
      "2017-11-29 20:00:00 -0.11393307989914304434 1.20903100624922665851   \n",
      "\n",
      "                                  OMEGA_dot  \n",
      "Epoch_Time_of_Clock                          \n",
      "2017-11-29 12:00:00 -0.53700835000242375106  \n",
      "2017-11-29 14:00:00 -0.83859534643038335933  \n",
      "2017-11-29 16:00:00 -0.94447163242235010472  \n",
      "2017-11-29 18:00:00 -1.49791585459187781559  \n",
      "2017-11-29 20:00:00 -1.32305956410087155461  \n"
     ]
    }
   ],
   "source": [
    "freq = None\n",
    "idx_tuples = []\n",
    "drop_incomplete  = True\n",
    "new_df[['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot']] = X_scaler.transform(new_df)\n",
    "new_new_df = new_df.copy()\n",
    "tensor_structure={'X':(range(-T+1, 1), ['Del_n', 'Cus', 'sqrt_A', 'Crc', 'OMEGA_dot'])}\n",
    "for name, structure in tensor_structure.items():\n",
    "        rng = structure[0]\n",
    "        dataset_cols = structure[1]\n",
    "        for col in dataset_cols:\n",
    "        # do not shift non-sequential 'static' features\n",
    "            if rng is None:\n",
    "                new_df['context_'+col] = new_df[col]\n",
    "                idx_tuples.append((name, col, 'static'))\n",
    "            else:\n",
    "                for t in rng:\n",
    "                    sign = '+' if t > 0 else ''\n",
    "                    shift = str(t) if t != 0 else ''\n",
    "                    period = 't'+sign+shift\n",
    "                    shifted_col = name+'_'+col+'_'+ period\n",
    "                    new_new_df[shifted_col] = new_new_df[col].shift(t*-1, freq=freq)\n",
    "                    idx_tuples.append((name, col, period))\n",
    "        new_new_df = new_new_df.drop(new_df.columns, axis=1)\n",
    "        idx = pd.MultiIndex.from_tuples(idx_tuples, names=['tensor', 'feature', 'time step'])\n",
    "        print(new_df.head())\n",
    "        new_new_df.columns = idx\n",
    "        if drop_incomplete:\n",
    "            new_new_df = new_new_df.dropna(how='any')\n",
    "            \n",
    "inputs = {}           \n",
    "for name, structure in tensor_structure.items():\n",
    "    rng = structure[0]\n",
    "    cols = structure[1]\n",
    "    tensor = new_new_df[name][cols].as_matrix()\n",
    "    if rng is None:\n",
    "        tensor = tensor.reshape(tensor.shape[0], len(cols))\n",
    "    else:\n",
    "        tensor = tensor.reshape(tensor.shape[0], len(cols), len(rng))\n",
    "        tensor = np.transpose(tensor, axes=[0, 2, 1])\n",
    "    inputs[name] = tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor                                   X                         \\\n",
      "feature                              Del_n                          \n",
      "time step                              t-5                    t-4   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 0.91269027718195072651 1.07767086824331581596   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                              t-3                    t-2   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 0.93992008346927835571 0.97195514972395735676   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                              t-1                      t   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 0.52987123577711836564 0.48822564967742920761   \n",
      "\n",
      "tensor                                                               \\\n",
      "feature                                 Cus                           \n",
      "time step                               t-5                     t-4   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -1.22312509319444773226 -1.20617816297157554040   \n",
      "\n",
      "tensor                                                               ...  \\\n",
      "feature                                                              ...   \n",
      "time step                               t-3                     t-2  ...   \n",
      "Epoch_Time_of_Clock                                                  ...   \n",
      "2017-11-29 22:00:00 -1.19770469785600397472 -1.17998745262262549893  ...   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                Crc                          \n",
      "time step                              t-3                    t-2   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 1.15865004941876525990 1.19693957660991601166   \n",
      "\n",
      "tensor                                                             \\\n",
      "feature                                                             \n",
      "time step                              t-1                      t   \n",
      "Epoch_Time_of_Clock                                                 \n",
      "2017-11-29 22:00:00 1.20903100624922665851 1.27217513881007149301   \n",
      "\n",
      "tensor                                                               \\\n",
      "feature                           OMEGA_dot                           \n",
      "time step                               t-5                     t-4   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -0.53700835000242375106 -0.83859534643038335933   \n",
      "\n",
      "tensor                                                               \\\n",
      "feature                                                               \n",
      "time step                               t-3                     t-2   \n",
      "Epoch_Time_of_Clock                                                   \n",
      "2017-11-29 22:00:00 -0.94447163242235010472 -1.49791585459187781559   \n",
      "\n",
      "tensor                                                               \n",
      "feature                                                              \n",
      "time step                               t-1                       t  \n",
      "Epoch_Time_of_Clock                                                  \n",
      "2017-11-29 22:00:00 -1.32305956410087155461 -1.18349536892555073919  \n",
      "\n",
      "[1 rows x 30 columns]\n",
      "[[[ 0.9126902771819507  -1.2231250931944477  -0.9037080560799021\n",
      "    1.2244811663439015  -0.5370083500024238 ]\n",
      "  [ 1.0776708682433158  -1.2061781629715755  -1.1473187845349788\n",
      "    1.2144049749778092  -0.8385953464303834 ]\n",
      "  [ 0.9399200834692784  -1.197704697856004   -0.9474570169011238\n",
      "    1.1586500494187653  -0.9444716324223501 ]\n",
      "  [ 0.9719551497239574  -1.1799874526226255  -0.7641725322397772\n",
      "    1.196939576609916   -1.4979158545918778 ]\n",
      "  [ 0.5298712357771184  -1.186920287717184   -0.11393307989914304\n",
      "    1.2090310062492267  -1.3230595641008716 ]\n",
      "  [ 0.4882256496774292  -1.273195568856693   -0.42477765536166323\n",
      "    1.2721751388100715  -1.1834953689255507 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(new_new_df)\n",
    "print(inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(inputs['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3903802 , -0.60097617, -0.9670547 , -1.2216293 , -0.9747424 ,\n",
       "        -0.5217734 ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictions[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3903802 , -0.60097617, -0.9670547 , -1.2216293 , -0.9747424 ,\n",
       "       -0.5217734 ], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.39038020372390747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.60097616910934448242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.96705472469329833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.22162926197052001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.97474241256713867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.52177339792251586914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                OMEGA_dot\n",
       "0 -0.39038020372390747070\n",
       "1 -0.60097616910934448242\n",
       "2 -0.96705472469329833984\n",
       "3 -1.22162926197052001953\n",
       "4 -0.97474241256713867188\n",
       "5 -0.52177339792251586914"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results , columns = [var_name])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>-0.39038020372390747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>-0.60097616910934448242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>-0.96705472469329833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>-1.22162926197052001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>-0.97474241256713867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>-0.52177339792251586914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OMEGA_dot\n",
       "Epoch_Time_of_Clock                        \n",
       "2017-11-29 12:00:00 -0.39038020372390747070\n",
       "2017-11-29 14:00:00 -0.60097616910934448242\n",
       "2017-11-29 16:00:00 -0.96705472469329833984\n",
       "2017-11-29 18:00:00 -1.22162926197052001953\n",
       "2017-11-29 20:00:00 -0.97474241256713867188\n",
       "2017-11-29 22:00:00 -0.52177339792251586914"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.index = date\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[var_name] = y_scalar.inverse_transform(res_df[[var_name]])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final generated output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OMEGA_dot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch_Time_of_Clock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:00:00</th>\n",
       "      <td>-0.00000000809876432584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 14:00:00</th>\n",
       "      <td>-0.00000000814565215279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 16:00:00</th>\n",
       "      <td>-0.00000000822715584547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 18:00:00</th>\n",
       "      <td>-0.00000000828383495133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>-0.00000000822886736529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>-0.00000000812801825845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OMEGA_dot\n",
       "Epoch_Time_of_Clock                        \n",
       "2017-11-29 12:00:00 -0.00000000809876432584\n",
       "2017-11-29 14:00:00 -0.00000000814565215279\n",
       "2017-11-29 16:00:00 -0.00000000822715584547\n",
       "2017-11-29 18:00:00 -0.00000000828383495133\n",
       "2017-11-29 20:00:00 -0.00000000822886736529\n",
       "2017-11-29 22:00:00 -0.00000000812801825845"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final generated ouput\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('SA1_OMEGA_dot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
